\newpage

# Part III: Scheduling in RTOS

## 7. Scheduling Algorithms

In the realm of Real-Time Operating Systems (RTOS), the efficiency and predictability of task execution are paramount. Scheduling algorithms lie at the heart of this challenge, determining the order and timing with which tasks are dispatched to the processor. This chapter delves into the intricacies of various scheduling algorithms used in RTOS. We begin with Fixed-Priority Scheduling, a straightforward yet potent method that assigns static priorities to tasks. Following this, we explore Rate Monotonic Scheduling (RMS), which optimizes the priority assignment based on task periodicity, ensuring optimal performance under specific conditions. Lastly, we investigate Earliest Deadline First (EDF) Scheduling, a dynamic approach that prioritizes tasks based on their imminent deadlines, often leading to higher system utilization. Through examining these foundational algorithms, we will uncover the principles, advantages, and limitations that govern real-time task scheduling in complex systems.

### Fixed-Priority Scheduling

#### Introduction

Fixed-Priority Scheduling (FPS) is a pivotal concept in the domain of Real-Time Operating Systems (RTOS), where determinism and responsiveness are crucial. In FPS, each task is assigned a static, immutable priority, and the scheduler always selects the highest-priority task that is ready to run. This simplicity in priority assignment and task selection makes FPS a widely adopted strategy in many real-time systems. It offers predictability in task behaviors, crucial for systems requiring stringent timing correctness.

#### Fundamental Concepts

1. **Priority Assignment:**
   In Fixed-Priority Scheduling, each task in the system is assigned a unique, fixed priority number before execution begins. These priorities do not change throughout the task's lifecycle. The priority is often assigned based on the task's importance or urgency, with lower numerical values typically denoting higher priorities.

2. **Priority Inversion:**
   One critical phenomenon to understand in FPS is priority inversion. Priority inversion occurs when a lower-priority task holds a resource needed by a higher-priority task, preventing the higher-priority task from executing. This situation can degrade the system’s performance and predictability. Priority inheritance and priority ceiling protocols are commonly employed to mitigate priority inversion.
      - **Priority Inheritance:** When a lower-priority task holds a resource required by a higher-priority task, its priority is temporarily elevated to match the higher-priority task until the resource is released.
      - **Priority Ceiling:** Each resource is assigned a priority ceiling, the highest priority of tasks that may lock it. When a task acquires a resource, its priority is temporarily raised to the ceiling of that resource, preventing it from being preempted by any medium-priority tasks.

3. **Rate Monotonic Scheduling (RMS):**
   RMS is a specific instance of FPS where priorities are assigned based on task periodicity: the shorter the period, the higher the priority. RMS is optimal under certain assumptions, such as tasks being periodic, deadlines equal to periods, and independent execution. Under these conditions, RMS can guarantee task scheduling up to approximately 69% CPU utilization (Liu and Layland, 1973).

4. **Deadlines and Jitter:**
   In systems employing FPS, tasks may have soft or hard deadlines. If a task’s execution time extends beyond its deadline, it has implications on the real-time guarantees of the system. Jitter, or variation in task start times, is another critical aspect, with FPS minimizing jitter for high-priority tasks.

#### Detailed Operation

Let's delve deeper into the mechanics of Fixed-Priority Scheduling within an RTOS, examining key operations such as task dispatch, context switches, and handling of periodic and aperiodic tasks.

1. **Task Dispatching:**
   The dispatcher in an FPS-oriented RTOS continuously scans through the ready queue to select the ready task with the highest priority. This operation is typically O(1) in sophisticated implementations, involving a priority vector or bitmap for quick access.

2. **Context Switching:**
   Context switching between tasks in FPS involves saving the state of the current task and loading the state of the next task. This process should be swift to minimize overhead. In preemptive FPS, the system must preempt the currently running lower-priority task if a higher-priority task becomes ready, necessitating a context switch.

3. **Handling Periodic Tasks:**
   Periodic tasks have known inter-arrival times, and in FPS, these tasks are assigned static priorities based on their criticality. Timer interrupts often trigger the periodic tasks, which are queued in the ready queue for the dispatcher to select.

4. **Handling Aperiodic Tasks:**
   Aperiodic tasks have unpredictable inter-arrival times. They can be handled in FPS through polling servers or priority exchange algorithms, ensuring that they do not unduly affect the system's responsiveness to higher-priority periodic tasks.

#### Analysis of Feasibility and Schedulability

Analyzing whether a set of tasks can be feasibly scheduled under FPS is crucial for system designers. The primary metric here is the Worst-Case Response Time (WCRT) analysis and utilization-based tests.

1. **Utilization-Based Analysis:**
   For tasks $\tau_1, \tau_2, ..., \tau_n$ with computation times $C_i$ and periods $T_i$ (where tasks are indexed in order of fixed priorities), a basic feasibility check under FPS is:
   $$
   \sum_{i=1}^{n} \frac{C_i}{T_i} \leq n(2^{1/n} - 1)
   $$
   This bound, derived from Liu and Layland's work, provides a quick check but is optimistic for many practical scenarios.

2. **Response Time Analysis:**
   More rigorous analysis involves calculating the Worst-Case Response Time (WCRT) $R_i$ of each task $\tau_i$ considering the possible interference from higher-priority tasks.
   $$
   R_i = C_i + \sum_{j \in hp(i)} \left\lceil \frac{R_i}{T_j}\right\rceil C_j
   $$
   Here, $hp(i)$ represents the set of tasks with higher priority than $\tau_i$. This iterative equation requires fixed-point convergence to derive the response time.

#### Implementing Fixed-Priority Scheduling in C++
Implementing FPS in C++ involves defining task structures, managing the ready queue, and the dispatcher logic. While actual RTOS implementations are more intricate, a simplified version can illustrate the fundamental principles.

```cpp
#include <iostream>
#include <queue>
#include <vector>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <chrono>

struct Task {
    int priority;
    std::function<void()> taskFunc;
    int computeTime;  // Simplified execution time for simulation
};

struct CompareTask {
    bool operator()(Task const& t1, Task const& t2) {
        return t1.priority > t2.priority;  // Lower number means higher priority
    }
};

class FixedPriorityScheduler {
public:
    FixedPriorityScheduler();
    void addTask(Task task);
    void run();

private:
    std::priority_queue<Task, std::vector<Task>, CompareTask> readyQueue;
    std::mutex queueMutex;
    std::condition_variable cv;
    bool running;
};

FixedPriorityScheduler::FixedPriorityScheduler() : running(true) {}

void FixedPriorityScheduler::addTask(Task task) {
    std::unique_lock<std::mutex> lock(queueMutex);
    readyQueue.push(task);
    cv.notify_one();
}

void FixedPriorityScheduler::run() {
    while (running) {
        std::unique_lock<std::mutex> lock(queueMutex);
        cv.wait(lock, [this]() { return !readyQueue.empty(); });

        Task nextTask = readyQueue.top();
        readyQueue.pop();

        lock.unlock();
        // Simulate task execution
        std::cout << "Executing task with priority: " << nextTask.priority << std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(nextTask.computeTime));

        lock.lock();
        if (readyQueue.empty() && !running) {
            cv.notify_all();
        }
    }
}

int main() {
    FixedPriorityScheduler scheduler;

    // Simulate adding tasks from various threads
    std::thread producer([&scheduler]() {
        for (int i = 10; i >= 1; --i) {
            scheduler.addTask({i, [i]() { std::cout << "Task " << i << " is running.\n"; }, 100 * i});
        }
    });

    // Run the scheduler on a separate thread
    std::thread consumer(&FixedPriorityScheduler::run, &scheduler);

    producer.join();
    consumer.join();

    return 0;
}
```

#### Evaluation and Conclusion

Fixed-Priority Scheduling offers a comprehensive strategy for managing real-time tasks with pre-defined importance. Its simplicity makes it a highly favored technique in embedded systems and applications requiring predictable behavior. When implementing FPS, careful attention must be given to potential priority inversion issues and the feasibility of meeting deadlines, particularly in systems with mixed periodic and aperiodic task sets. By understanding the intricacies and applying robust analysis methods, practitioners can leverage FPS to build reliable and efficient real-time systems.

### Rate Monotonic Scheduling (RMS)

#### Introduction

Rate Monotonic Scheduling (RMS) is a fundamental real-time scheduling algorithm explicitly designed for periodic tasks. It stands as the most universally applicable fixed-priority algorithm for periodic task sets and serves as a cornerstone in real-time system theory. RMS was first presented by Liu and Layland in their seminal 1973 paper, which established foundational principles for real-time task scheduling. With RMS, tasks are assigned priorities based on their periodicity: the shorter the task's period, the higher its priority. This deterministic strategy enables RMS to provide predictable behavior essential for systems with stringent timing constraints.

#### Fundamental Principles

1. **Priority Assignment:**
   In RMS, priorities are statically assigned based on the period of the tasks. Specifically, the task with the shortest period is given the highest priority, and the task with the longest period is given the lowest priority. If `T1`, `T2`, `...`, `Tn` denote the periods of tasks $\tau_1, \tau_2, ..., \tau_n$` respectively, and `T1 < T2 < ... < Tn`, then the priority assignment follows $Priority(\tau_1) > Priority(\tau_2) > ... > Priority(\tau_n)$.

2. **Pre-emptive Nature:**
   RMS is inherently pre-emptive, meaning a higher-priority task will interrupt and preempt the execution of any currently running lower-priority task. This ensures that critical tasks receive immediate attention upon activation.

3. **Optimality for Periodic Tasks:**
   Under specific assumptions (such as tasks being independent and the deadline of each task being equal to its period), RMS is proven to be optimal among fixed-priority algorithms. This implies that if a task set cannot be scheduled by RMS, it cannot be feasibly scheduled by any other fixed-priority method.

#### Assumptions and Constraints

To use RMS effectively, the following assumptions are generally made:

1. **Periodicity:** Tasks are strictly periodic, activating at fixed intervals.
2. **Independence:** Tasks are independent, with no inter-task dependencies that could influence their execution order.
3. **Worst-Case Execution Time (WCET):** WCET for each task is known and constant.
4. **Deadlines:** The deadline of each task equals its period.
5. **No Jitter:** Task activation and completion times are deterministic, with no variability or jitter.

#### Schedulability Analysis

RMS provides specific tools and bounds for determining whether a given set of tasks can be feasibly scheduled.

1. **Utilization-Based Test:**
   The utilization $U$ for a task set $\tau_1, \tau_2, ..., \tau_n$ is given by:
   $$
   U = \sum_{i=1}^{n} \frac{C_i}{T_i}
   $$
   where $C_i$ is the computation time and $T_i$ is the period of task $\tau_i$.

   For RMS, Liu and Layland provided the following necessary and sufficient condition for schedulability:
   $$
   U \leq n(2^{1/n} - 1)
   $$
   This bound, known as the Liu-Layland bound, tends to the natural logarithm value ($ln(2) \approx 0.693$) as $n$ approaches infinity. Thus, for large number of tasks:
   $$
   U \approx 0.693 \quad \text{(approximately 69.3\% CPU utilization)}
   $$
   If the total utilization $U$ is less than or equal to this bound, the task set is guaranteed to be schedulable under RMS.

2. **Exact Analysis via Response Time:**
   For more precise schedulability analysis, especially for systems where the utilization might be near the Liu-Layland bound, response time analysis is used. The worst-case response time $R_i$ of a task $\tau_i$ can be calculated iteratively:
   $$
   R_i^{(0)} = C_i
   $$
   $$
   R_i^{(k+1)} = C_i + \sum_{j \in hp(i)} \left\lceil \frac{R_i^{(k)}}{T_j} \right\rceil C_j
   $$
   Here, $hp(i)$ denotes the set of tasks with higher priority than $\tau_i$. The process repeats until $R_i$ converges or exceeds its period $T_i$. If $R_i \leq T_i$, the task $\tau_i$ is schedulable.

#### Implementation of RMS in RTOS

Let's explore a simplified implementation of RMS in C++, focusing on task structures, priority assignment, and the scheduling algorithm.

```cpp
#include <iostream>
#include <queue>
#include <vector>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <chrono>
#include <cmath>

struct Task {
    int id;
    int priority;
    int computeTime;  // Simplified execution time
    int period;
    std::function<void()> taskFunc;
};

class RMSScheduler {
public:
    RMSScheduler();
    void addTask(Task task);
    void startScheduling();

private:
    struct CompareTask {
        bool operator()(Task const& t1, Task const& t2) {
            if (t1.priority == t2.priority)
                return t1.id > t2.id;  // Tie-breaking by task ID
            return t1.priority < t2.priority;  // Higher priority goes first
        }
    };

    std::priority_queue<Task, std::vector<Task>, CompareTask> readyQueue;
    std::mutex queueMutex;
    std::condition_variable cv;
    bool running;
    int idCounter;

    void runTask(Task task);
};

RMSScheduler::RMSScheduler() : running(true), idCounter(0) {}

void RMSScheduler::addTask(Task task) {
    task.id = idCounter++;
    std::unique_lock<std::mutex> lock(queueMutex);
    readyQueue.push(task);
    cv.notify_one();
}

void RMSScheduler::startScheduling() {
    while (running) {
        std::unique_lock<std::mutex> lock(queueMutex);
        cv.wait(lock, [this]() { return !readyQueue.empty(); });

        while (!readyQueue.empty()) {
            Task nextTask = readyQueue.top();
            readyQueue.pop();
            lock.unlock();
            runTask(nextTask);
            lock.lock();
        }
    }
}

void RMSScheduler::runTask(Task task) {
    std::cout << "Executing task with priority: " << task.priority << std::endl;
    std::this_thread::sleep_for(std::chrono::milliseconds(task.computeTime));
    task.taskFunc();
    // Requeue the task for its next period
    task.priority += task.period;
    addTask(task);
}

int main() {
    RMSScheduler scheduler;

    // Example task functions
    auto taskFunc1 = []() { std::cout << "Task 1 is running.\n"; };
    auto taskFunc2 = []() { std::cout << "Task 2 is running.\n"; };

    // Define tasks with periods and computation times
    Task task1 = {0, 1, 200, 1000, taskFunc1};  // Higher priority (shorter period)
    Task task2 = {0, 2, 300, 2000, taskFunc2};  // Lower priority (longer period)

    // Add tasks to scheduler
    scheduler.addTask(task1);
    scheduler.addTask(task2);

    // Start the scheduler
    std::thread schedulerThread(&RMSScheduler::startScheduling, &scheduler);

    schedulerThread.join();

    return 0;
}
```

#### Advanced Topics in RMS

1. **Harmonic Task Sets:**
   Task sets with harmonic relationships (where each period is an integer multiple of shorter periods) possess favorable properties under RMS. Harmonic sets often yield higher utilization bounds closer to 100%.

2. **Mixed Task Sets and Aperiodic Tasks:**
   Integrating aperiodic tasks into an RMS framework requires careful consideration. Server-based approaches like Deferrable, Sporadic, or Priority Exchange servers are often employed to handle aperiodic tasks without severely impacting the RMS guarantees for periodic tasks.

3. **Response-Time Analysis for Mixed Priority Systems:**
   In systems with mixed periods and deadlines, response-time analysis must account for intricate interactions between tasks. The schedulability test involves detailed iterative computation to check whether tasks' deadlines are met, factoring in both periodic and aperiodic components.

#### Real-World Applications of RMS

1. **Embedded Systems:**
   RMS is widely used in embedded systems for automotive, aerospace, and consumer electronics, where periodic sensor readings, control actions, and signal processing tasks are common.

2. **Industrial Control:**
   In industrial automation, RMS helps ensure that critical control tasks are performed with timely precision, maintaining system stability and predictability.

3. **Communication Systems:**
   Protocol handling and signal processing tasks in communication systems benefit from RMS by guaranteeing timely data processing and minimizing latency.

#### Conclusion

Rate Monotonic Scheduling (RMS) stands as a robust and reliable strategy for managing periodic tasks in real-time systems through its fixed-priority allocation based on task periodicity. With optimality under specific conditions, RMS serves as a foundational algorithm in real-time theory, providing predictable and deterministic scheduling essential for time-sensitive applications. While RMS has stringent assumptions, advanced variations and combination with other scheduling strategies enable broader applicability. Through rigorous mathematical analysis, implementation techniques, and real-world applications, RMS continues to be a cornerstone in the design and deployment of real-time systems.

### Earliest Deadline First (EDF) Scheduling

#### Introduction

Earliest Deadline First (EDF) Scheduling is a dynamic priority scheduling algorithm that plays a critical role in real-time systems. Unlike fixed-priority scheduling schemes such as Rate Monotonic Scheduling (RMS), EDF assigns priorities to tasks based on their absolute deadlines, meaning that the task with the closest (earliest) deadline is given the highest priority. This approach ensures that tasks are executed in order of urgency, providing optimal scheduling utility under certain conditions. EDF is widely regarded as an optimal algorithm for uniprocessor systems, capable of achieving full CPU utilization up to 100% under ideal conditions.

#### Fundamental Principles

1. **Dynamic Priority Assignment:**
   In EDF scheduling, priorities are dynamically assigned and can change with each scheduling decision. The task with the earliest imminent deadline is always given the highest priority. As tasks arrive or complete, the scheduler re-evaluates the deadlines to determine which task should run next.

2. **Preemptive Nature:**
   EDF is inherently preemptive. When a new task arrives with an earlier deadline than the currently running task, it preempts the current task, ensuring that more urgent tasks always run first.

3. **Optimality:**
   EDF is considered optimal for uniprocessor systems in that if a set of tasks can be scheduled to meet all deadlines by any algorithm, EDF can also schedule them to meet all deadlines. This optimality holds under the assumption that tasks are independent, have known execution times, and deadlines are equal to their periods.

#### Assumptions and Constraints

To reap the benefits of EDF scheduling, the following assumptions are typically made:

1. **Independence:** Tasks are independent, meaning they do not share resources or require synchronization.
2. **Deterministic Deadlines:** Each task has a well-defined deadline by which it must complete its execution.
3. **Known Execution Times:** The worst-case execution time (WCET) for each task is known and constant.
4. **Periodic or Aperiodic Tasks:** EDF can handle both periodic and aperiodic tasks more flexibly than fixed-priority algorithms like RMS.

#### Schedulability Analysis

Schedulability analysis under EDF determines whether all tasks in a set can meet their deadlines. The key metrics for this analysis include utilization and response time.

1. **Utilization-Based Analysis:**
   For a set of $n$ periodic tasks $\tau_1, \tau_2, ..., \tau_n$ with execution times $C_i$ and periods $T_i$, the total utilization $U$ is:
   $$
   U = \sum_{i=1}^{n} \frac{C_i}{T_i}
   $$
   Under EDF, a set of tasks is schedulable if:
   $$
   U \leq 1
   $$
   This implies that EDF can efficiently utilize up to 100% of the CPU, making it more theoretically robust in terms of CPU utilization compared to fixed-priority algorithms.

2. **Exact Schedulability Analysis:**
   While the utilization test offers a quick check, exact schedulability analysis involves evaluating the worst-case response times and ensuring all tasks meet their deadlines. This analysis is more complex and typically involves computational methods to trace the feasibility of task execution within specified deadlines.

#### Implementation of EDF Scheduling

Implementing EDF scheduling necessitates handling dynamic priorities, managing the ready queue, and processing preemptions. Here, we present a simplified C++ implementation that captures the essence of EDF scheduling.

```cpp
#include <iostream>
#include <queue>
#include <vector>
#include <functional>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <chrono>

struct Task {
    int id;
    int absoluteDeadline;
    int computeTime;
    std::function<void()> taskFunc;
    
    Task(int id, int deadline, int compute, std::function<void()> func)
        : id(id), absoluteDeadline(deadline), computeTime(compute), taskFunc(func) {}
};

struct CompareTaskDeadline {
    bool operator()(Task const& t1, Task const& t2) {
        return t1.absoluteDeadline > t2.absoluteDeadline;  // Earlier deadline gets higher priority
    }
};

class EDFScheduler {
public:
    EDFScheduler();
    void addTask(Task task);
    void startScheduling();

private:
    std::priority_queue<Task, std::vector<Task>, CompareTaskDeadline> readyQueue;
    std::mutex queueMutex;
    std::condition_variable cv;
    bool running;
    int time;  // Simulated time for the scheduler

    void runTask(Task task);
};

EDFScheduler::EDFScheduler() : running(true), time(0) {}

void EDFScheduler::addTask(Task task) {
    std::unique_lock<std::mutex> lock(queueMutex);
    readyQueue.push(task);
    cv.notify_one();
}

void EDFScheduler::startScheduling() {
    while (running) {
        std::unique_lock<std::mutex> lock(queueMutex);
        cv.wait(lock, [this]() { return !readyQueue.empty(); });

        while (!readyQueue.empty()) {
            Task nextTask = readyQueue.top();
            readyQueue.pop();
            lock.unlock();
            runTask(nextTask);
            lock.lock();
        }
    }
}

void EDFScheduler::runTask(Task task) {
    std::cout << "Executing task " << task.id << " with deadline: " << task.absoluteDeadline << std::endl;
    std::this_thread::sleep_for(std::chrono::milliseconds(task.computeTime));
    task.taskFunc();
    time += task.computeTime;

    if (time >= task.absoluteDeadline) {
        std::cout << "Task " << task.id << " missed its deadline!" << std::endl;
    }
}

int main() {
    EDFScheduler scheduler;

    // Example task functions
    auto taskFunc1 = []() { std::cout << "Task 1 is running.\n"; };
    auto taskFunc2 = []() { std::cout << "Task 2 is running.\n"; };

    // Define tasks with compute times and deadlines
    Task task1(1, 1000, 200, taskFunc1);  // Higher priority due to earlier deadline
    Task task2(2, 1500, 300, taskFunc2);  // Lower priority

    // Add tasks to scheduler
    scheduler.addTask(task1);
    scheduler.addTask(task2);

    // Start the scheduler
    std::thread schedulerThread(&EDFScheduler::startScheduling, &scheduler);

    schedulerThread.join();

    return 0;
}
```

#### Advanced Topics in EDF Scheduling

1. **Handling Overloads:**
   In practical systems, the combined task execution demand may occasionally exceed the CPU capacity, leading to overload situations. EDF employs several strategies to handle such overloads, including task re-planning, migrations (in multiprocessor systems), and graceful degradation.

2. **Multiprocessor EDF Scheduling:**
   Extending EDF to multiprocessor systems introduces additional complexity. Global EDF (G-EDF) treats all processors and tasks globally rather than partitioning, whereas Partitioned EDF (P-EDF) statically assigns tasks to specific processors. Both approaches have trade-offs in terms of overhead, complexity, and scheduling feasibility.

3. **Mixed Criticality Systems:**
   EDF's flexibility allows it to efficiently manage mixed-criticality systems where tasks of different criticality levels coexist. By adjusting relative deadlines dynamically based on criticality mode changes, EDF can prioritize essential tasks during system stress or errors.

4. **EDF with Resource Constraints:**
   Integrating EDF with resource management protocols, such as Priority Ceiling Protocol (PCP) or Stack Resource Policy (SRP), enables handling shared resource contention among tasks without undermining timing guarantees.

5. **Soft Real-Time Applications:**
   For soft real-time systems, EDF can be extended to account for less stringent deadline constraints and jitter tolerance. This broader application scope allows EDF to function across diverse real-time and near real-time scenarios.

#### Real-World Applications of EDF

1. **Telecommunication Systems:**
   EDF's dynamic prioritization is instrumental in managing fluctuating data packet arrivals, ensuring real-time data processing and reducing latency.

2. **Multimedia Systems:**
   Multimedia applications, such as video streaming and audio processing, benefit from EDF's ability to adhere to strict timing and deadline requirements, optimizing playback quality and synchronization.

3. **Automotive and Aerospace:**
   In automotive embedded control and aerospace avionics, EDF ensures critical sensor inputs and actuator commands are timely, maintaining system safety and performance.

4. **Healthcare Systems:**
   Real-time patient monitoring and response systems leverage EDF to prioritize vital signal analysis and notify healthcare providers promptly.

#### Conclusion

Earliest Deadline First (EDF) Scheduling stands as a robust and highly effective scheduling algorithm in real-time systems. Its dynamic priority allocation based on task deadlines ensures a theoretically optimal solution for meeting all timing constraints in uniprocessor systems. Although implementing EDF involves handling dynamic priorities and preemptions, its benefits in achieving high CPU utilization and accommodating both periodic and aperiodic tasks make it unparalleled in many real-time applications. Advanced EDF techniques, including multiprocessor extensions and mixed-criticality management, broaden its applicability, reinforcing EDF's position as a cornerstone algorithm in the domain of real-time system scheduling.

