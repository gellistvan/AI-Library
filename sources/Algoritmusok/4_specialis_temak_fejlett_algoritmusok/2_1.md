\newpage

# 2. Közelítő algoritmusok

## 2.1. Alapelvek és definíciók

A közelítő algoritmusok világa tele van izgalmas kihívásokkal és megoldásokkal, különösen akkor, ha az optimalizálás nehézségeivel állunk szemben. Ebben a fejezetben bemutatjuk a közelítő algoritmusok alapelveit és definícióit, és megvizsgáljuk, hogyan viszonyulnak ezek a klasszikus, pontos algoritmusokhoz. Megismerjük a közelítő arány koncepcióját, amely kulcsfontosságú eszköz a közelítő algoritmusok teljesítményének értékelésében. Továbbá, mélyebben belemegyünk a teljesítmény elemzés módszereibe, amelyek lehetővé teszik számunkra, hogy hatékonyan kiválasszuk a megfelelő algoritmusokat a gyakorlati problémák megoldására. Az elméleti alapok lefektetésével felkészítjük magunkat arra, hogy mélyebb megértést nyerjünk a közelítő algoritmusok szerkezetéről és viselkedéséről, és feltárjuk, hogyan lehet ezekkel a módszerekkel hatékonyan kezelni a valós világ komplex feladatait.

### Pontos vs. közelítő algoritmusok

A számítástechnika és az algoritmuselmélet területén az algoritmusokat általában két nagy kategóriába soroljuk: pontos algoritmusok és közelítő algoritmusok. Ez a fejezet részletesen bemutatja ezen algoritmusok belső működését, előnyeit, hátrányait, alkalmazási területeit és azokat a módszereket, amelyekkel teljesítményüket értékelhetjük.

#### Pontos algoritmusok

A pontos algoritmusok (exact algorithms) célja, hogy egy adott probléma optimális megoldását találják meg. Ezek az algoritmusok biztosítják, hogy a legjobb lehetséges megoldást kapjuk, amely gyakran egyértelműen meghatározható és ellenőrizhető. 

##### Előnyök
1. **Optimális megoldás**: Mindig a legjobban teljesítő megoldást biztosítják.
2. **Determináltság**: Az algoritmus minden futásakor ugyanazt az eredményt nyújtja adott bemenetre.
3. **Valósságnak megfelelő adatok elemzésére alkalmas**: Ideális az olyan problémákra, ahol az optimális döntés alapvető fontosságú, például a banki kockázatelemzésben vagy hálózattervezésben.

##### Hátrányok
1. **Magas számítási költségek**: A pontos algoritmusok gyakran exponenciális idő- és memóriaigényesek, különösen NP-teljes problémáknál.
2. **Skálázódási problémák**: Nagy bemeneti méretek esetén nehézkesé válhat a használatuk, mivel a számítási erőforrások gyorsan kimerülnek.

#### Példák
1. **Dijkstra algoritmusa**: Ez egy pontos algoritmus a legkisebb súlyú út megtalálására egy gráf kezdő csúcsából a többi csúcsba.
2. **Ford-Fulkerson algoritmus**: Egy algoritmus a maximális átbocsátóképesség meghatározására hálózati átviteli problémákban.

#### Közelítő algoritmusok

A közelítő algoritmusok (approximation algorithms) olyan algoritmusok, amelyek nem feltétlenül biztosítják az optimális megoldást, de egy olyan megoldást nyújtanak, amely közel van az optimálishoz egy előre meghatározott közelítési arányon belül. Ezek az algoritmusok különösen hasznosak olyan problémák esetében, ahol a pontos megoldás megtalálása túl időigényes vagy erőforrás-igényes lenne.

##### Előnyök
1. **Gyors számítási idő**: Általában hatékonyabbak idő- és memóriahasználat szempontjából a pontos algoritmusokhoz képest.
2. **Skálázhatóság**: Nagyobb adatállományok esetén jobban használhatóak, mivel kevésbé terhelik a rendszer erőforrásait.
3. **Könnyű implementáció**: Bizonyos közelítő algoritmusok egyszerűbben implementálhatóak és érthetőek.

##### Hátrányok
1. **Nem garantált optimális megoldás**: A kapott megoldás nem feltétlenül az optimális, hanem csak egy adott határon belül van az optimálishoz képest.
2. **Bizonyos esetekben nem elfogadható pontosság**: Közelítő algoritmusok nem minden probléma esetére alkalmazhatóak, ahol a pontosság elengedhetetlen.

#### Példák
1. **Greedy algoritmusok**: Olyan heurisztikus módszerek, amelyek minden lépésben a lokálisan optimális döntést hozzák, reménykedve, hogy az eredmény globálisan is optimális lesz.
2. **Travelling Salesman Problem (TSP) méhecske algoritmus**: Egy példa arra, hogyan lehet heurisztikus módszert használni egy közel optimális út megtalálására.

#### Közelítési arány és teljesítmény elemzés

A közelítés minőségét általában a közelítési arány (approximation ratio) segítségével mérjük. Ez a mutató azt fejezi ki, hogy egy közelítő algoritmus milyen arányban tér el az optimális megoldástól.

##### Definíció
A közelítési arány, $\rho(n)$, egy adott $A$ közelítési algoritmusra egy probléma $P$ esetében a következőképpen definiálható:
$$ \rho(n) = \max \left( \frac{A(I)}{OPT(I)}, \frac{OPT(I)}{A(I)} \right) $$
ahol $A(I)$ a közelítő algoritmus által adott megoldás értéke és $OPT(I)$ az optimális megoldás értéke. Az $n$ a probléma bemeneti méretét jelzi.

##### Példa
Egy $2$-közelítő algoritmus garantálja, hogy a megtalált megoldás legfeljebb kétszerese az optimális megoldásnak vagy legfeljebb fele az optimális megoldás értékének.

#### Jakobson-féle 2-közelítő algoritmus: Kereszthelysín probléma

Consider a simplified example of the Traveling Salesman Problem (TSP) where we aim to find a near-optimal solution using a 2-approximation algorithm.

```cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <limits.h>

using namespace std;

int tsp(vector<vector<int>>& graph, vector<int>& tour, int pos, int n, int count, int cost, int& ans) {
    if (count == n && graph[pos][0]) {
        ans = min(ans, cost + graph[pos][0]);
        return ans;
    }
    
    for (int i = 0; i < n; i++) {
        if (!tour[i] && graph[pos][i]) {
            tour[i] = 1;
            tsp(graph, tour, i, n, count + 1, cost + graph[pos][i], ans);
            tour[i] = 0;
        }
    }
    
    return ans;
}

int main() {
    vector<vector<int>> graph = { { 0, 10, 15, 20 },
                                  { 10, 0, 35, 25 },
                                  { 15, 35, 0, 30 },
                                  { 20, 25, 30, 0 } };
    int n = graph.size();
    vector<int> tour(n, 0);
    tour[0] = 1;
    int ans = INT_MAX;
    
    cout << "The cost of the minimum Hamiltonian cycle is: "
         << tsp(graph, tour, 0, n, 1, 0, ans) << endl;

    return 0;
}
```

The above C++ example demonstrates a naive approach to the TSP problem using a backtracking solution, which illustrates how challenging it can be to achieve exact solutions and motivates the need for approximation algorithms.

Összefoglalva, a pontos és közelítő algoritmusok mindkettő fontos szerepet játszanak az algoritmuselméletben és a gyakorlati alkalmazásokban. Míg a pontos algoritmusok garantálják az optimális megoldást, addig a közelítő algoritmusok idő és erőforrás tekintetében hatékonyabb megoldásokat kínálnak, amelyek a gyakorlatban gyakran megfelelően közelítik az optimális megoldást. A közelítési arány és a teljesítmény elemzés segítenek abban, hogy értékeljük és azonosítsuk a legmegfelelőbb algoritmusokat a különböző problémák megoldására. Ahogy a következő fejezetben továbblépünk, mélyebben megvizsgáljuk a közelítő algoritmusok specifikus technikáit és alkalmazásait.

### Közelítő arány és teljesítmény elemzés

A közelítő algoritmusok világában az egyik legfontosabb mérőszám a közelítő arány, amely segít megérteni, hogy egy adott algoritmus mennyire közelíti meg az optimális megoldást. Emellett a teljesítmény elemzés az a folyamat, amelyben az algoritmus futási idejét és memóriaigényét vizsgáljuk annak megértése érdekében, hogy mennyire hatékonyan képes megoldani a problémát nagy méretű bemenetek esetén. Ebben a fejezetben részletesen megvitatjuk mindkét koncepciót, és megmutatjuk, hogyan használhatóak ezek az eszközök az algoritmusok értékelésére és kiválasztására.

#### Közelítő arány (Approximation Ratio)

##### Definíció
A közelítési arány egy olyan mérőszám, amely a közelítő algoritmus által nyújtott megoldás minőségét jelzi az optimális megoldáshoz képest. Formálisan a közelítési arány, $\rho(n)$, egy adott $A$ közelítési algoritmusra egy probléma $P$ esetében a következőképpen definiálható:

$$ \rho(n) = \max \left( \frac{A(I)}{OPT(I)}, \frac{OPT(I)}{A(I)} \right) $$

ahol $A(I)$ a közelítő algoritmus által adott megoldás értéke, $OPT(I)$ az optimális megoldás értéke, és $n$ a probléma bemeneti mérete.

##### Boltzmann egyenlet és közelítő arány
A közelítési arány fordított arányban áll annak az esélyével, hogy az algoritmust használják kritikus alkalmazásokban, ahol az optimális megoldás elengedhetetlen. A közelítési arány használható a következőképpen:

$$ \text{Boltzmann faktor} = \exp\left( -\frac{\Delta E}{k_BT} \right) $$

Ezáltal egy közelítési arány értékelhető a valós idejű rendszerekben is, ahol a megfelelő hatékonyság kulcsfontosságú.

##### Közelítő arány osztályok
1. **PTAS (Polynomial Time Approximation Scheme)**: Egy algoritmus, amely adott $\epsilon$ értékre $(1+\epsilon)$-közelítő megoldást ad polinomiális időben a probléma bemeneti méretének függvényében. 
2. **FPTAS (Fully Polynomial Time Approximation Scheme)**: PTAS, amely polinomiális időben fut mind a bemeneti méretben, mind pedig $\epsilon$-ban.

#### Példa: Knapsack Problem

Consider the 0/1 Knapsack problem where we have to maximize the total value of items in a knapsack without exceeding its weight capacity. A common approximation technique is the greedy algorithm, which achieves a (1-1/e)-approximation ratio.

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

using namespace std;

struct Item {
    int value, weight;
};

// Function to perform the knapsack greedy approach
double knapsackGreedy(vector<Item>& items, int W) {
    // Sort items by value/weight ratio
    sort(items.begin(), items.end(), [](Item &a, Item &b) {
        double r1 = (double)a.value / a.weight;
        double r2 = (double)b.value / b.weight;
        return r1 > r2;
    });

    int currentWeight = 0; // Current weight in knapsack
    double finalValue = 0.0; // Resultant value

    for (auto &item : items) {
        if (currentWeight + item.weight <= W) {
            currentWeight += item.weight;
            finalValue += item.value;
        } else {
            int remain = W - currentWeight;
            finalValue += item.value * ((double) remain / item.weight);
            break;
        }
    }

    return finalValue;
}

int main() {
    int W = 50; // Knapsack capacity
    vector<Item> items = {{60, 10}, {100, 20}, {120, 30}}; // Items (value, weight)

    cout << "The maximum value in Knapsack = "
         << knapsackGreedy(items, W) << endl;

    return 0;
}
```

This C++ example demonstrates a greedy approximation for the Knapsack problem, where items are sorted by their value-to-weight ratio, and the solution is constructed incrementally.

#### Teljesítmény elemzés (Performance Analysis)

A teljesítmény elemzés magában foglalja az algoritmusok idő- és térbeli komplexitásának vizsgálatát. Ez lehetővé teszi számunkra, hogy megértsük, milyen erőforrásokat igényel egy algoritmus egy adott probléma megoldásához.

#### Időkomplexitás

Az időkomplexitás az algoritmus végrehajtásának idejét határozza meg a bemenet méretének függvényében. Általában a következő jelölésekkel szoktuk meghatározni:
- **Big-O notation ($O$)**: A legrosszabb esetbeli komplexitás.
- **Omega notation ($\Omega$)**: A legjobb esetbeli komplexitás.
- **Theta notation ($\Theta$)**: Az átlagos esetbeli komplexitás.

##### Példa: QuickSort Időkomplexitása

- **Worst-case**: $O(n^2)$, amikor a pivot minden lépésben a legkisebb vagy legnagyobb elem.
- **Average-case**: $O(n log n)$, amikor a pivot véletlenszerűen választott.

```cpp
#include <iostream>
using namespace std;

// A utility function to swap two elements
void swap(int* a, int* b) {
    int t = *a;
    *a = *b;
    *b = t;
}

/* This function takes last element as pivot, places
   the pivot element at its correct position in the array
   and places all smaller elements to the left of pivot
   and all greater elements to the right of pivot */
int partition(int arr[], int low, int high) {
    int pivot = arr[high]; // pivot
    int i = (low - 1); // Index of smaller element

    for (int j = low; j <= high - 1; j++) {
        // If current element is smaller than or
        // equal to pivot
        if (arr[j] <= pivot) {
            i++; // increment index of smaller element
            swap(&arr[i], &arr[j]);
        }
    }
    swap(&arr[i + 1], &arr[high]);
    return (i + 1);
}

/* The main function that implements QuickSort
 arr[] --> Array to be sorted,
 low  --> Starting index,
 high  --> Ending index */
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        // pi is partitioning index, arr[p] is now
        // at right place
        int pi = partition(arr, low, high);

        // Separately sort elements before
        // partition and after partition
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}

// Function to print an array
void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++)
        cout << arr[i] << " ";
    cout << endl;
}

int main() {
    int arr[] = {10, 7, 8, 9, 1, 5};
    int n = sizeof(arr) / sizeof(arr[0]);
    quickSort(arr, 0, n - 1);
    cout << "Sorted array: \n";
    printArray(arr, n);
    return 0;
}
```

#### Térbeli komplexitás

A térbeli komplexitás az algoritmus által igényelt memória mennyiségét méri a bemenet méretének függvényében. Ez különösen fontos a nagy adatkészletek kezelésénél.

##### Példa: MergeSort Térbeli Komplexitása

- **Worst-case**: O(n), mivel az algoritmusnak szüksége van egy kiegészítő tömbre, amely a teljes bemeneti mérettel megegyezik.

```cpp
#include <iostream>
using namespace std;

// Merges two subarrays of arr[].
// First subarray is arr[l..m]
// Second subarray is arr[m+1..r]
void merge(int arr[], int l, int m, int r) {
    int n1 = m - l + 1;
    int n2 = r - m;

    // Create temp arrays
    int L[n1], R[n2];

    // Copy data to temp arrays L[] and R[]
    for(int i = 0; i < n1; i++)
        L[i] = arr[l + i];
    for(int j = 0; j < n2; j++)
        R[j] = arr[m + 1 + j];

    // Merge the temp arrays back into arr[l..r]
    int i = 0; // Initial index of first subarray
    int j = 0; // Initial index of second subarray
    int k = l; // Initial index of merged subarray
    while(i < n1 && j < n2) {
       	if(L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        }
        else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }

    // Copy the remaining elements of L[], if any
    while(i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }

    // Copy the remaining elements of R[], if any
    while(j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
}

/* l is for left index and r is right index of the
sub-array of arr to be sorted */
void mergeSort(int arr[], int l, int r) {
    if(l >= r)
        return; //returns recursively

    int m = l + (r - l) / 2;
    mergeSort(arr, l, m);
    mergeSort(arr, m + 1, r);
    merge(arr, l, m, r);
}

// Function to print an array
void printArray(int A[], int size) {
    for(int i = 0; i < size; i++)
        cout << A[i] << " ";
    cout << endl;
}

int main() {
    int arr[] = {12, 11, 13, 5, 6, 7};
    int arr_size = sizeof(arr) / sizeof(arr[0]);

    cout << "Given array is \n";
    printArray(arr, arr_size);

    mergeSort(arr, 0, arr_size - 1);

    cout << "\nSorted array is \n";
    printArray(arr, arr_size);
    return 0;
}
```

#### Módszerek a közelítő arány és teljesítmény elemzésére

#### Aszimptotikus elemzés

Az aszimptotikus elemzés segítségével a futási időt és memóriahasználatot a bemenet méretének növekedésével vizsgáljuk.

- **Amortizált analízis**: Az algoritmus futási időt az összes művelet átlagára bontja.

#### Empirikus elemzés

Ez a módszer konkrét implementációk futtatásával és méréseivel történik.

- **Benchmarking**: Az algoritmus futási idő és memóriahasználatának mérése különböző bemeneti méretekkel.

#### Védekező elemzés

A legrosszabb eset (worst-case) és az átlagos eset (average-case) elemzésének kombinációja.

#### Következtetés

A közelítő arány és teljesítmény elemzés a közelítő algoritmusok egyik legfontosabb értékelési eszköze. Annak megértése, hogy hogyan működnek ezek az algoritmusok és hogyan mérhető teljesítményük, elengedhetetlen ahhoz, hogy hatékony döntéseket hozzunk a valós világ problémáinak megoldásában. A következő fejezetekben további mélyreható technikákat és példákat mutatunk be arra, hogyan lehet ezeket az eszközöket optimálisan alkalmazni.

