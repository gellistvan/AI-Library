\newpage

# 3. Adatbányászat és gépi tanulás algoritmusai

Az adatbányászat és a gépi tanulás az informatika és mesterséges intelligencia olyan területei, amelyek hatalmas jelentőséggel bírnak a modern adatvezérelt világban. Ezen technológiák segítségével a nagy mennyiségű adatban rejlő minták és összefüggések automatizált módon tárhatók fel, amely alapvetően új lehetőségeket nyit meg az üzleti döntéshozatal, a tudományos kutatás, és a mindennapi élet számos területén. Ebben a fejezetben áttekintjük az adatbányászat és a gépi tanulás alapelveit és definícióit, melyek elengedhetetlenek a későbbi módszerek és algoritmusok megértéséhez. Különös hangsúlyt fektetünk a felügyelt és felügyelet nélküli tanulás fogalmának tisztázására, amelyek az adatbányászat és gépi tanulás két alapvető paradigmáját képviselik. Ezek az alapok biztosítják majd azokat az eszközöket és szemléletmódot, amelyekkel hatékonyan tudjuk alkalmazni az algoritmusokat különféle adathalmazokon és problémakörökben.

### Adatbányászat és gépi tanulás alapjai

**Bevezetés**

Az adatbányászat és gépi tanulás két olyan terület, amelyek az utóbbi évtizedekben jelentős fejlődésen mentek keresztül. Mindkét terület az adatok feldolgozására, elemzésére és az adatokból való hasznos információk kinyerésére koncentrál, de eltérő megközelítéseket alkalmaznak. Az adatbányászat célja rejtett minták, kapcsolatok és anomáliák felderítése nagy mennyiségű adatból, míg a gépi tanulás az tanulási algoritmusok fejlesztésére fókuszál, amelyek lehetővé teszik a gépek számára a tanulást és döntéshozást emberi beavatkozás nélkül.

#### Adatbányászat alapjai

Az adatbányászat a múltbeli adatokat használja összefüggések és minták felfedezésére, amelyeket később különböző területeken alkalmazhatunk, mint például az üzleti intelligencia, a marketing és az orvostudomány. A sikeres adatbányászat néhány alapelve a következő:

**1. Adat-előkészítés:**
Az adatok előkészítése kritikus lépés az adatbányászat folyamatában. Az előkészítési folyamat magában foglalja az adatgyűjtést, a tisztítást, az integrálást és a transzformációt. Az adatminőség közvetlenül befolyásolja az adatbányászat eredményeit, ezért az előkészítési fázis gondos végrehajtása elengedhetetlen.

**2. Minta- és modellezés:** 
Az adatbányászat kulcsfontosságú része a különböző algoritmusok és modellek használata az adatokban rejlő minták és kapcsolatok feltárására. Ilyen modellek közé tartoznak a klaszterezés, az asszociációs szabálybányászat és a döntési fák.

**3. Klaszterezés:** 
Ez egy olyan eljárás, amely az adatokat csoportokba osztja aszerint, hogy milyen mértékben hasonlítanak egymásra. Például a K-means algoritmus széles körben használt a klaszterezéshez. A K-means megpróbálja minimalizálni a pontok és a hozzájuk rendelhető klaszterközéppontok közötti távolságot.

**4. Döntési fák:** 
A döntési fák olyan matematikai struktúrák, amelyek használhatók prediktív modellépítésre, amelyben a gyökércsomópontból kiindulva, egyes ágakon keresztül követve elérünk a levelekhez, ahol a végső döntés található.

```cpp
// Example of decision tree node structure in C++
class DecisionTreeNode {
public:
    bool isLeaf;
    int featureIndex;
    double threshold;
    double prediction;
    DecisionTreeNode* left;
    DecisionTreeNode* right;

    DecisionTreeNode(bool leaf = false, int index = -1, double thresh = 0.0, double pred = 0.0)
        : isLeaf(leaf), featureIndex(index), threshold(thresh), prediction(pred), left(nullptr), right(nullptr) {}
};
```

#### Gépi Tanulás alapjai

A gépi tanulás célja az, hogy számítógépes rendszerek képesek legyenek tanulni adatokból, és ezen tanulási tapasztalatok alapján következtetéseket levonni vagy döntéseket hozni. A gépi tanulás két fő típusa van: felügyelt (supervised) és felügyelet nélküli (unsupervised) tanulás.

**1. Felügyelt tanulás:**
Felügyelt tanulás során a modelleket egy címkézett adathalmazon tanítják. A cél az, hogy a modell képes legyen pontosan előre jelezni a kimeneti változókat új, ismeretlen adatok esetén. A felügyelt tanulási algoritmusok két fő kategóriába sorolhatók: 
- Regresszió
- Klasszifikáció

**1.1 Regresszió:**
A regresszió egy felügyelt tanulási technika, amely folyamatos kimeneti változó előrejelzésére szolgál. A lineáris regresszió az egyik legegyszerűbb és leggyakrabban használt módszer.

```cpp
#include <vector>

class LinearRegression {
private:
    std::vector<double> coefficients;

public:
    void fit(const std::vector<std::vector<double>>& X, const std::vector<double>& y);
    double predict(const std::vector<double>& x);
};

void LinearRegression::fit(const std::vector<std::vector<double>>& X, const std::vector<double>& y) {
    // Fitting logic here (e.g., using the normal equation or gradient descent)
}

double LinearRegression::predict(const std::vector<double>& x) {
    double prediction = coefficients[0];
    for (size_t i = 0; i < x.size(); ++i) {
        prediction += coefficients[i + 1] * x[i];
    }
    return prediction;
}
```

**1.2 Klasszifikáció:**
A klasszifikációs algoritmusok célja a kategóriákba történő besorolás. A döntési fák és a támogatott vektorgépek (SVM) gyakran használt módszerek.

**2. Felügyelet nélküli tanulás:**
Felügyelet nélküli tanulás során a modellnek címkézetlen adatokból kell felfedeznie a struktúrát. A felügyelet nélküli tanulás főbb kategóriái:
- Csoportosítás (clustering)
- Dimenziócsökkentés

**2.1 Csoportosítás:**
Amint korábban említettük, a csoportosítás (pl. K-means) az adatokat csoportokba osztja.

**2.2 Dimenziócsökkentés:**
Olyan technikák, mint a Főkomponens-analízis (PCA), arra szolgálnak, hogy az adatok komplexitását csökkentsék, miközben a lehető legtöbb információt megőrzik.

**Példa: PCA Algoritmus C++-ban**

```cpp
#include <Eigen/Dense>
using Eigen::MatrixXd;

class PCA {
private:
    MatrixXd components;

public:
    PCA(int n_components);
    void fit(const MatrixXd& X);
    MatrixXd transform(const MatrixXd& X);
};

PCA::PCA(int n_components) {
    components = MatrixXd(n_components, n_components);
}

void PCA::fit(const MatrixXd& X) {
    // Calculate the covariance matrix
    MatrixXd covarianceMatrix = (X.transpose() * X) / double(X.rows() - 1);

    // Eigenvalue decomposition
    Eigen::SelfAdjointEigenSolver<MatrixXd> eigenSolver(covarianceMatrix);
    components = eigenSolver.eigenvectors().rightCols(components.rows());
}

MatrixXd PCA::transform(const MatrixXd& X) {
    return X * components;
}
```

#### Következtetések és Alkalmazási Területek

Az adatbányászat és a gépi tanulás mindennapi alkalmazásai közé tartoznak például a pénzügyi előrejelzések, a piaci trendek azonosítása, az egészségügyi diagnosztika és a személyre szabott ajánlási rendszerek. A modern technológiák és az egyre növekvő mennyiségű adat révén ezek a területek folyamatosan fejlődnek, új algoritmusok és módszerek jelennek meg, amelyek egyre pontosabb előrejelzéseket és elemzéseket tesznek lehetővé.

Ez a fejezet csak egy bevezetés az adatbányászat és a gépi tanulás világába. Ahogy haladunk előre, részletesebben is megismerkedünk specifikus algoritmusokkal, technikákkal és azok matematikai hátterével, amelyek lehetővé teszik a különböző alkalmazási területek hatékony kezelését.

**Összefoglalás**

Az adatbányászat és a gépi tanulás alapjainak megértése elengedhetetlen a modern adatvezérelt döntéshozatal szempontjából. Míg az adatbányászat az adatok rejtett mintáinak felfedezésére összpontosít, a gépi tanulás az adatokból történő tanulásra és predikciókra specializálódott. Mindkét terület különböző megközelítéseket és algoritmusokat kínál, amelyek lehetővé teszik a hatékony adatfeldolgozást és elemzést számos alkalmazási területen.

### Felügyelt és felügyelet nélküli tanulás

**Bevezetés**

A gépi tanulás világában a felügyelt és felügyelet nélküli tanulás két alapvető paradigma, amelyek alapvetően különböző megközelítéseket alkalmaznak a tanulási folyamatban. Ezek a kategóriák meghatározzák, hogyan használjuk a rendelkezésre álló adatokat a modellek betanítására, valamint milyen típusú problémákat tudunk megoldani. Ebben a fejezetben részletesen megismerkedünk mindkét tanulási paradigmával, a kapcsolódó algoritmusokkal és a gyakorlati alkalmazási területeikkel.

#### Felügyelt tanulás

**1. Alapelvek:**
A felügyelt tanulás lényege, hogy a modell címkézett adatokon tanul, ahol minden bemeneti adatponthoz egy ismert kimeneti címke tartozik. A cél az, hogy a modell megtanulja a bemeneti adatok és a kimeneti címkék közötti kapcsolatot, és ezt a tudást felhasználva pontos előrejelzéseket vagy döntéseket hozzon új, ismeretlen adatokon.

**2. Módszerek és Algoritmusok:**

**2.1 Regresszió:**
- **Lineáris regresszió:** Egyszerű, de hatékony módszer a folytonos kimeneti változók előrejelzésére. A lineáris regresszió alapötlete, hogy egy legjobb illeszkedésű egyenest találjunk az adatok között.
  
```cpp
#include <vector>
#include <iostream>
#include <Eigen/Dense>

class LinearRegression {
private:
    Eigen::VectorXd coefficients;

public:
    void fit(const Eigen::MatrixXd& X, const Eigen::VectorXd& y);
    double predict(const Eigen::VectorXd& x);
};

void LinearRegression::fit(const Eigen::MatrixXd& X, const Eigen::VectorXd& y) {
    Eigen::MatrixXd X_b = Eigen::MatrixXd::Constant(X.rows(), X.cols() + 1, 1.0);
    X_b.rightCols(X.cols()) = X;
    coefficients = (X_b.transpose() * X_b).ldlt().solve(X_b.transpose() * y);
}

double LinearRegression::predict(const Eigen::VectorXd& x) {
    return coefficients(0) + x.dot(coefficients.tail(coefficients.size() - 1));
}
```

- **Logisztikus regresszió:** Kategóriákba történő besorolást végző algoritmus, amely valószínűségi modellezést használ. A sigmoid függvény segítségével transzformálja a bemeneti értékeket valószínűségekké.

**2.2 Klasszifikáció:**
- **Döntési fák:** A döntési fák alapelve, hogy a döntési folyamatot egy fa szerkezetben ábrázoljuk, ahol minden belső csomópont egy döntést, illetve a levél csomópontok a végső besorolást képviselik.

```cpp
#include <vector>
#include <iostream>

class TreeNode {
public:
    int featureIndex;
    double threshold;
    double value;
    TreeNode* left;
    TreeNode* right;
    bool isLeaf;

    TreeNode() : featureIndex(-1), threshold(0.0), value(0.0), left(nullptr), right(nullptr), isLeaf(false) {}
};

class DecisionTree {
private:
    TreeNode* root;

public:
    DecisionTree() : root(nullptr) {}
    void fit(const std::vector<std::vector<double>>& X, const std::vector<int>& y);
    int predict(const std::vector<double>& x);

private:
    TreeNode* buildTree(const std::vector<std::vector<double>>& X, const std::vector<int>& y);
    int majorityClass(const std::vector<int>& y);
};

void DecisionTree::fit(const std::vector<std::vector<double>>& X, const std::vector<int>& y) {
    root = buildTree(X, y);
}

int DecisionTree::predict(const std::vector<double>& x) {
    TreeNode* node = root;
    while (!node->isLeaf) {
        if (x[node->featureIndex] < node->threshold) {
            node = node->left;
        } else {
            node = node->right;
        }
    }
    return static_cast<int>(node->value);
}

TreeNode* DecisionTree::buildTree(const std::vector<std::vector<double>>& X, const std::vector<int>& y) {
    // Placeholder logic for building tree
    TreeNode* node = new TreeNode();
    if (/* stopping criteria */) {
        node->isLeaf = true;
        node->value = majorityClass(y);
    } else {
        node->featureIndex = /* best feature */;
        node->threshold = /* best threshold */;
        node->left = buildTree(/* left partition X */, /* left partition y */);
        node->right = buildTree(/* right partition X */, /* right partition y */);
    }
    return node;
}

int DecisionTree::majorityClass(const std::vector<int>& y) {
    // Placeholder for finding majority class
    return y[0];
}
```

- **Support Vector Machine (SVM):** Az SVM egy olyan határozó vonalat keres az n-dimenziós térben, amely maximalizálja a különböző osztályok közötti távolságot. Nagyon hatékony a lineárisan elválasztható adatok esetében.

- **Neurális hálók:** A mély tanulás egyik alapköve, amely bonyolultabb minták és viselkedések modellezésére képes. A több rétegű perceptron egyszerű formája az ideghálóknak, míg a konvolúciós és rekurzus neuronhálók a mélyebb, komplex minták felismerésére alkalmasak.

**3. Alkalmazási területek:**
A felügyelt tanulást különféle alkalmazási területeken használják, beleértve:
- Kép- és hangfelismerés
- Orvosi diagnosztika
- Pénzügyi előrejelzések
- Szövegelemzés és nyelvfeldolgozás

#### Felügyelet nélküli tanulás

**1. Alapelvek:**
A felügyelet nélküli tanulásban a modellnek nincsenek címkézett adatpontok, és feladata, hogy az adatok belső struktúráját fedezze fel. Az adataink csupán bemeneti jellemzőkkel rendelkeznek, és a modellnek önállóan kell megtalálnia a releváns mintákat és csoportosításokat.

**2. Módszerek és Algoritmusok:**

**2.1 Klaszterezés:**
- **K-means:** Az egyik leggyakoribb klaszterezési algoritmus, amely a megadott k számú klaszter középpontot optimalizálja az ismételt hozzárendelés és klasszifikáció révén.

```cpp
#include <vector>
#include <Eigen/Dense>
using Eigen::MatrixXd;
using Eigen::VectorXd;

class KMeans {
private:
    int k;
    std::vector<VectorXd> centroids;

public:
    KMeans(int k_clusters) : k(k_clusters) {}
    void fit(const MatrixXd& X);
    VectorXd predict(const VectorXd& x);
};

void KMeans::fit(const MatrixXd& X) {
    // Initialization logic
    // Lloyd's algorithm for cluster assignment and centroid updates
}

VectorXd KMeans::predict(const VectorXd& x) {
    // Find the nearest centroid and return its index
    return VectorXd::Zero(1);
}
```

- **Hierarchikus klaszterezés:** Ez az eljárás egy hierarchiát épít az adatok között, amely lehet agglomeratív vagy divisive. Az agglomeratív módszer esetén az egyes pontok összekapcsolása hierarchikus struktúrát hoz létre.

**2.2 Dimenziócsökkentés:**
- **Főkomponens-analízis (PCA):** Olyan módszer, amely az adatminták közötti varianciát maximálisan megőrizve csökkenti az adatok dimenzióit.
  
```cpp
#include <Eigen/Dense>
using Eigen::MatrixXd;

class PCA {
private:
    MatrixXd components;

public:
    PCA(int n_components);
    void fit(const MatrixXd& X);
    MatrixXd transform(const MatrixXd& X);
};

PCA::PCA(int n_components) {
    components = MatrixXd(n_components, n_components);
}

void PCA::fit(const MatrixXd& X) {
    // Calculate the covariance matrix
    MatrixXd covarianceMatrix = (X.transpose() * X) / double(X.rows() - 1);

    // Eigenvalue decomposition
    Eigen::SelfAdjointEigenSolver<MatrixXd> eigenSolver(covarianceMatrix);
    components = eigenSolver.eigenvectors().rightCols(components.rows());
}

MatrixXd PCA::transform(const MatrixXd& X) {
    return X * components;
}
```

- **t-SNE:** Nem-lineáris dimenziócsökkentő technika, amely kiválóan alkalmas adatok vizualizálására.

**3. Alkalmazási területek:**
A felügyelet nélküli tanulás széles körben alkalmazható, beleértve:
- Klaszterelemzés
- Adatvizualizáció
- Anomáliadetektálás
- Ajánlórendszerek

**Összegzés**

A felügyelt és felügyelet nélküli tanulás alapvető különbségei abból adódnak, hogyan használjuk az adatokat a modellek betanítására. A felügyelt tanulás címkézett adatokat használ a kiindulási pont elemek és célértékek közötti kapcsolat megtalálásához, míg a felügyelet nélküli tanulás címkézetlen adatokra épít, hogy felfedezze az adatok szerkezetét és mintáit. Mindkét megközelítés rendelkezik saját előnyökkel és alkalmazási területekkel, és bizonyos esetekben a két módszer kombinációját is alkalmazhatjuk a legjobb teljesítmény elérése érdekében. Ahogy a gépi tanulás tovább fejlődik, újabb és még hatékonyabb algoritmusok és technikák jelennek meg, amelyek tovább bővítik a tanulás lehetőségeit és alkalmazási területeit.

