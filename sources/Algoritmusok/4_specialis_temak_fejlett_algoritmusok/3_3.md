\newpage

## 3.3. Gépi tanulási algoritmusok

A gépi tanulás a mesterséges intelligencia egy ága, amely lehetővé teszi számítógépes rendszerek számára, hogy tanuljanak és fejlődjenek tapasztalataik alapján anélkül, hogy kifejezetten programoznánk őket. A gépi tanulási algoritmusok segítségével rendszerek képesek felismerni mintázatokat, előrejelezni jövőbeli eseményeket és meghozni komplex döntéseket. Ebben a fejezetben négy alapvető gépi tanulási algoritmust mutatunk be: a lineáris regressziót, a logisztikus regressziót, a döntési fákat és a neurális hálókat. Ezek az algoritmusok széles körben használtak különböző iparágakban, és elengedhetetlen tudást képviselnek minden adatkutató és gépi tanulás iránt érdeklődő számára. Részletesen megvizsgáljuk, hogyan működnek, milyen előnyeik és korlátaik vannak, valamint gyakorlati példákon keresztül szemléltetjük alkalmazásukat. Ezek az ismeretek alapot nyújtanak a bonyolultabb gépi tanulási módszerek és technikák megértéséhez is.

### Lineáris regresszió

A lineáris regresszió a statisztikában és a gépi tanulásban széles körben használt módszer, amelynek célja, hogy megértsük és modellezzük a két vagy több változó közötti lineáris kapcsolatot. Ez az egyszerű, ám hatékony technika alapvető fontosságú számos tudományterületen, beleértve a gazdaságot, a fiziológiát, a szociológiát és az informatikát. Ebben az alfejezetben részletesen bemutatjuk a lineáris regresszió működési elvét, matematikai hátterét, alkalmazási lehetőségeit, valamint előnyeit és korlátait.

#### Alapfogalmak és előfeltevések

A lineáris regresszió módszerének megértéséhez elengedhetetlen a következő alapfogalmak tisztázása:

- **Függő változó (y)**: Az a változó, amelyet meg szeretnénk magyarázni vagy előre jelezni.
- **Független változó (x)**: Az a változó, amely alapján a függő változót próbáljuk megmagyarázni.
- **Paraméterek ($\beta_0, \beta_1$)**: A függő és független változók közötti kapcsolatot leíró együtthatók, ahol $\beta_0$ az y tengelymetszet (intercept), $\beta_1$ pedig a meredekség (slope).
- **Hiba/sztochasztikus zavar ($\epsilon$)**: Az eltérés mértéke az adott modell és a valós adatok között, amelyet a modell által nem magyarázott változók okoznak.

A lineáris regresszió alapvető modellje az alábbi formában írható fel:

$$ y = \beta_0 + \beta_1 \cdot x + \epsilon $$

A modell legfontosabb előfeltevései a következők:
1. **Lineáris kapcsolat**: A függő és független változók közötti kapcsolat lineáris.
2. **Homoszkedaszticitás**: A hibák varianciája állandó az összes megfigyelésre.
3. **Normális eloszlású hibák**: A hibák normális eloszlást követnek, $\epsilon \sim N(0, \sigma^2)$.
4. **Független hibák**: Az egyes megfigyelések hibái egymástól függetlenek.

#### Modellezési technikák

##### Egyszerű lineáris regresszió

Az egyszerű lineáris regresszió egy függő és egy független változó közötti kapcsolat elemzésére szolgál. A modell célja, hogy minimalizálja az eltérést az alábbiak alapján:

$$ \min_{\beta_0, \beta_1} \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2 $$

Ez a legkisebb négyzetek módszere (OLS, Ordinary Least Squares), melynek segítségével a lineáris egyenest úgy illesztjük az adatokhoz, hogy az a négyzetes eltérések összegét minimalizálja.

##### Többszörös lineáris regresszió

A többszörös lineáris regresszió lehetőséget ad arra, hogy több független változót is figyelembe vegyünk a modellben:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon $$

Ebben az esetben az együtthatók optimalizálása egy többváltozós térben történik, és a megoldáshoz mátrixalgebrai módszereket alkalmazunk.

##### Mátrixos forma

A többszörös lineáris regresszió mátrixos formában is felírható, ami megkönnyíti a számításokat. A modell ekkor az alábbi módon írható fel:

$$ \mathbf{Y} = \mathbf{X} \mathbf{\beta} + \mathbf{\epsilon} $$

ahol:

- $\mathbf{Y}$ az n x 1 méretű célváltozók vektora,
- $\mathbf{X}$ az n x (p+1) méretű független változók mátrixa (minden oszlop egy független változót, minden sor egy megfigyelést reprezentál, és az első oszlop a konstans 1-eket tartalmazza),
- $\mathbf{\beta}$ a p+1 x 1 méretű paraméter vektor,
- $\mathbf{\epsilon}$ az n x 1 méretű hiba vektor.

Az optimális $\mathbf{\beta}$ megoldása:

$$ \mathbf{\beta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} $$

#### Modellezés C++ nyelven

Az alábbi egy egyszerű példa a lineáris regresszió megvalósítására C++ nyelven. Ahhoz, hogy a program működjön, a standard könyvtárak mellett a `<vector>` és `<cmath>` könyvtárakat is használni fogjuk.

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <cmath>

struct LinearRegression {
    double alpha;  // Intercept
    double beta;   // Slope

    void fit(const std::vector<double>& x, const std::vector<double>& y) {
        if (x.size() != y.size()) {
            throw std::runtime_error("The size of x and y must be equal.");
        }

        double x_mean = std::accumulate(x.begin(), x.end(), 0.0) / x.size();
        double y_mean = std::accumulate(y.begin(), y.end(), 0.0) / y.size();
        
        double num = 0.0;
        double den = 0.0;

        for (size_t i = 0; i < x.size(); ++i) {
            num += (x[i] - x_mean) * (y[i] - y_mean);
            den += (x[i] - x_mean) * (x[i] - x_mean);
        }

        beta = num / den;
        alpha = y_mean - beta * x_mean;
    }

    double predict(double x) const {
        return alpha + beta * x;
    }
};

int main() {
    std::vector<double> x = {1, 2, 4, 3, 5};
    std::vector<double> y = {1, 3, 3, 2, 5};

    LinearRegression lr;
    lr.fit(x, y);

    std::cout << "Intercept (alpha): " << lr.alpha << "\n";
    std::cout << "Slope (beta): " << lr.beta << "\n";

    double pred = lr.predict(6);
    std::cout << "Prediction for x=6: " << pred << "\n";

    return 0;
}
``` 
#### Előnyök és korlátok

A lineáris regresszió egy sor előnyt kínál:
- **Egyszerűség**: Könnyen érthető és implementálható.
- **Interpretelhetőség**: Az eredmények könnyen értelmezhetők; az együtthatók közvetlen hatást mutatnak.
- **Hatékonyság**: Gyorsan fut nagy adathalmazok esetén is.

Azonban számos korlátja is van:
- **Linearitás feltétele**: Nem képes nemlineáris összefüggések modellezésére.
- **Érzékenység az outlierekre**: Az outlierek jelentősen torzíthatják az eredményeket.
- **Multikollinearitás**: Több független változó közötti korreláció problémákat okozhat.

#### Alternatívák és bővítmények

Számos alternatíva és bővítmény létezik a lineáris regresszió modellhez, amelyek különböző típusú adatokhoz való illesztést tesznek lehetővé:
- **Ridge regresszió**: Penalizálja a nagyobb együtthatókat, csökkentve ezzel a multikollinearitás problémáját.
- **Lasso regresszió**: Tömör modellválasztást végez, az irreleváns változók asszociálásával.
- **Polynomial regresszió**: Lehetőséget biztosít a nemlineáris kapcsolatok modellezésére polinomiális tagok hozzáadása révén.
- **Robusztus regresszió**: Kevésbé érzékeny az outlierek befolyására.

#### Összefoglalás

A lineáris regresszió az egyik legegyszerűbb és legismertebb gépi tanulási algoritmus, amely erőteljes eszköz a függő és független változók közötti lineáris kapcsolatok feltárásában. Bár számos előnnyel rendelkezik, a használata előtt fontos megvizsgálni a módszer alapvető feltételezéseit és korlátait annak érdekében, hogy megbízható eredményeket kapjunk. Az elméleti és gyakorlati ismeretek elmélyítése segíthet abban, hogy optimálisan alkalmazzuk ezt a módszert különféle problémák megoldására.

### Logisztikus regresszió

A logisztikus regresszió egy alapvető, de nagyon fontos gépi tanulási algoritmus, amelyet főként bináris osztályozási problémák megoldására használnak. A módszer nevét onnan kapta, hogy egy logisztikus függvényt (szigmoid függvényt) alkalmaz a célváltozó becslésére. Ebben az alfejezetben részletesen bemutatjuk a logisztikus regresszió működését, matematikai hátterét, előfeltevéseit, tanítási módszereit és alkalmazási példáit, valamint annak korlátait és elterjedt bővítményeit.

#### Alapfogalmak és matematikai háttér

A logisztikus regresszió célja annak modellezése, hogy egy adott változó (vagy változók halmaza) alapján milyen valószínűséggel tartozik egy megfigyelés egy adott osztályba. Legyen a célváltozó (függő változó) $y$, amely bináris (0 vagy 1 értékű). A logisztikus regresszióban a következő kapcsolatot modellezzük:

$$ \text{logit}(P(y=1|x)) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p $$

ahol $P(y=1|x)$ az esemény (y = 1) valószínűsége az x kondíciójára. A logit függvény pedig a valószínűség (p) log-odds formája:

$$ \text{logit}(p) = \log\left(\frac{p}{1-p}\right) $$

A logit függvény inverze a szigmoid függvény, amely a következőképpen transformálja a lineáris predikciót valószínűséggé:

$$ P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p)}} $$

#### Paraméterbecslés

A logisztikus regresszió paramétereinek becslését általában a maximum likelihood mesthod segítségével végezzük. A valószínűségfüggvény:

$$ L(\beta_0, \beta_1, \dots, \beta_p) = \prod_{i=1}^{n} P(y_i|x_i)^{y_i} (1 - P(y_i|x_i))^{1 - y_i} $$

A maximum likelihood becslés (MLE) célja ennek a függvénynek a maximalizálása. Gyakorlati okokból általában a log-valószínűségfüggvényt használjuk, amely konvex és könnyebben kezelhető a numerikus optimalizáló algoritmusok számára:

$$ \ell(\beta) = \sum_{i=1}^{n} \left[ y_i \log(P(y_i|x_i)) + (1 - y_i) \log(1 - P(y_i|x_i)) \right] $$

Az optimalizáció leggyakrabban alkalmazott módszere a Gradiens Descent, különös tekintettel a Stochastic Gradient Descent (SGD) és újabban az Adaptive Moment Estimation (Adam) algoritmusokra.

#### Modellezés C++ nyelven

Az alábbi kód egy egyszerű példát mutat be a logisztikus regresszió megvalósítására C++ nyelven, gradiens descent alkalmazásával.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <numeric>
#include <algorithm>

class LogisticRegression {
public:
    LogisticRegression(double learning_rate, int epochs) : learning_rate(learning_rate), epochs(epochs) {}

    void fit(const std::vector<std::vector<double>>& X, const std::vector<int>& y) {
        int n_samples = X.size();
        int n_features = X[0].size();
        weights = std::vector<double>(n_features, 0.0);

        for (int epoch = 0; epoch < epochs; ++epoch) {
            for (int i = 0; i < n_samples; ++i) {
                double linear_model = std::inner_product(X[i].begin(), X[i].end(), weights.begin(), 0.0);
                double y_pred = sigmoid(linear_model);
                double error = y[i] - y_pred;

                for (int j = 0; j < n_features; ++j) {
                    weights[j] += learning_rate * error * X[i][j];
                }
            }
        }
    }

    int predict(const std::vector<double>& X) const {
        double linear_model = std::inner_product(X.begin(), X.end(), weights.begin(), 0.0);
        double y_pred = sigmoid(linear_model);
        return y_pred >= 0.5 ? 1 : 0;
    }

private:
    double sigmoid(double z) const {
        return 1.0 / (1.0 + std::exp(-z));
    }

    std::vector<double> weights;
    double learning_rate;
    int epochs;
};

int main() {
    // Example dataset: OR gate
    std::vector<std::vector<double>> X = {{0, 0}, {0, 1}, {1, 0}, {1, 1}};
    std::vector<int> y = {0, 0, 0, 1};

    LogisticRegression lr(0.1, 1000);
    lr.fit(X, y);

    for (const auto& sample : X) {
        std::cout << "Prediction for (" << sample[0] << ", " << sample[1] << "): "
                  << lr.predict(sample) << "\n";
    }

    return 0;
}
```

#### Előnyök és korlátok

A logisztikus regresszió számos előnnyel rendelkezik:

- **Egyszerűség**: Könnyen implementálható és értelmezhető.
- **Gyorsaság**: Hatékonyan működik nagy adathalmazokkal is.
- **Bináris és multinomiális osztályozás**: Nemcsak kettő, hanem több osztály esetén is alkalmazható (multinomiális logisztikus regresszió).

Azonban a logisztikus regresszió használatának vannak korlátai is:

- **Nemalkalmas nemlineáris kapcsolatokra**: Csak lineáris kapcsolatokat tud modellezni a független változók és a log-odds között.
- **Multikollinearitási probléma**: Ha a független változók erősen korreláltak, csekély stabilitást nyújt.
- **Outlierek hatása**: Az outlierek jelentősen befolyásolhatják a modell teljesítményét.

#### Alternatívák és bővítmények

Számos módosítás és alternatíva létezik a logisztikus regresszióhoz:

- **Ridge és Lasso logisztikus regresszió**: Hasonlóan a lineáris regresszióhoz, ezek a módszerek büntetik a túl nagy együtthatókat, hogy elkerüljék a túlilleszkedést (overfitting).
- **Bayes-féle logisztikus regresszió**: Priori eloszlást használ az együtthatók becslésére.
- **Nemlineáris logisztikus regresszió**: Adott esetekben lehetőség van nemlineáris transzformációk alkalmazására.
- **Multinomiális logisztikus regresszió**: Több osztály esetén alkalmazható kiterjesztés.

#### Alkalmazási területek

A logisztikus regresszió számos gyakorlati alkalmazással rendelkezik különböző iparágakban és tudományterületeken:

- **Egészségügy**: Betegségek előrejelzése, mint például a diabétesz vagy a szívbetegség jelenlétének modellezése.
- **Pénzügy**: Hitelkockázat becslése, ügyfélviselkedés vizsgálata.
- **Marketing**: Vásárlói magatartás előrejelzése, e-mail kampányok sikerességének modellezése.
- **Szociológia**: Felmérések és tanulmányok eredményeinek statisztikai elemzése.

#### Összefoglalás

A logisztikus regresszió az egyik leggyakrabban alkalmazott bináris osztályozási módszer, amely a gépi tanulás és a statisztika egyik alappillére. Bár egyszerűsége mellett hatékony, használata előtt fontos megérteni annak feltételezéseit és korlátait, valamint az esetleges komplexebb modellek előnyeit is mérlegelni. Alkalmazásának sok helyen van létjogosultsága, különösen akkor, ha a cél egy könnyen értelmezhető, gyorsan tanítható és robusztus modell létrehozása.

### Döntési fák (Decision Trees)

A döntési fák egy hatékony és könnyen érthető módszer, amelyet széles körben alkalmaznak a gépi tanulásban mind osztályozási, mind regressziós feladatokhoz. Ebben az alfejezetben részletesen bemutatjuk a döntési fák működését, felépítését, algoritmusait, előnyeit és hátrányait, valamint gyakorlati alkalmazásukat és bővítményeiket.

#### Alapfogalmak és felépítés

A döntési fa egy hierarchikus modell, amely fastruktúraként ábrázolja a döntési szabályokat. A modell alapkomponensei a következők:

- **Gyökér csomópont (Root Node)**: A fa kiindulási pontja, amely tartalmazza az összes adatot, és innen indulnak a döntési folyamatok.
- **Belső csomópontok (Internal Nodes)**: Olyan csomópontok, ahol döntési szabályokat alkalmazunk és az adatot részekre osztjuk.
- **Ágak (Branches)**: Az a struktúra, ami a gyökér csomópontból és belső csomópontokból indul ki.
- **Levél csomópontok (Leaf Nodes)**: A fa végső csomópontjai, amelyek az osztályozási vagy predikciós eredményeket tartalmazzák.

A döntési fa egy adott tulajdonság alapján osztja fel az adatokat. Minden belső csomópont egy tesztet jelent egy adott változóra, az ágakon keresztül pedig tovább vezeti a megfigyelést.

#### Algoritmusok a döntési fák építésére

A döntési fa építése során általában a következő algoritmusokat alkalmazzák:

##### ID3 (Iterative Dichotomiser 3)

Az ID3 algoritmus a döntési fa létrehozásának egyik első módszere. Az információelmélet fogalmain alapul és az alábbi lépésekkel építi fel a döntési fát:

1. **Entropia kiszámítása**: Az entropia mérőszám a bizonytalanság mértékére egy adott adathalmazban. Egy $S$ adathalmaz entropiája, ha a $c$ osztályok aránya $p_i$, a következő formában írható fel:

   $$ H(S) = - \sum_{i=1}^c p_i \log_2(p_i) $$

2. **Információnyereség kiszámítása**: Az információnyereség egy adott változó alapján kifejezi, hogy mennyit csökkent az entropia, ha ezt a változót használjuk a felosztásra:

   $$ IG(S, A) = H(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} H(S_v) $$

3. **A legjobb osztó kiválasztása**: Az a változó lesz a legjobb osztó, amely maximális információnyereséget eredményez.

##### C4.5 és C5.0

A C4.5 az ID3 utódja, amely továbbfejlesztéseket tartalmaz, mint például a folytonos változók kezelése és a prúnálás (metszés) módszere. A C5.0 még tovább fejlesztett verzió, ami gyorsabb és kevesebb memóriát használ.

##### CART (Classification and Regression Trees)

A CART algoritmus a faépítés során két alapvető szempont szerint dolgozik: osztályozás esetén a Gini-indexet, regressziós esetben pedig az átlagos négyzetes hiba (MSE) csökkentését veszi figyelembe.

- **Gini-index**: Az egyensúlyhiány mérésére használják osztályozási feladatoknál:

   $$ Gini(S) = 1 - \sum_{i=1}^c p_i^2 $$

#### Fa pruning (Metszés)

A faépítés során előfordulhat, hogy a döntési fa túlillik (overfitting) az adathalmazra, ami gyenge általánosítóképességet eredményez. A fa méretének csökkentése érdekében metszeni kell a fát, azaz eltávolítani azokat az ágakat, amelyek kevés információnyereséget hoznak. Két fő metszési technika létezik:

- **Előzetes metszés (Pre-pruning)**: A faépítés során megállítják a növekedést bizonyos kritériumok teljesülése esetén, mint például a minimális információnyereség vagy a minimális példányszám csomópontonként.
- **Utpólagos metszés (Post-pruning)**: A teljes fa felépítése után visszametszik azokat az ágakat, amelyek nem javítják a modell teljesítményét.

#### Példa döntési fa algoritmusra C++ nyelven

Itt egy egyszerű példa egy döntési fa osztályozó megvalósítására C++ nyelven.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <limits>
#include <algorithm>

struct Node {
    bool is_leaf;
    int feature_index;
    double threshold;
    int prediction;
    Node* left;
    Node* right;

    Node() : is_leaf(false), feature_index(-1), threshold(0), prediction(-1), left(nullptr), right(nullptr) {}
};

class DecisionTree {
public:
    DecisionTree(int max_depth) : max_depth(max_depth), root(nullptr) {}

    void fit(const std::vector<std::vector<double>>& X, const std::vector<int>& y) {
        root = new Node();
        build_tree(root, X, y, 0);
    }

    int predict(const std::vector<double>& x) const {
        Node* node = root;
        while (!node->is_leaf) {
            if (x[node->feature_index] <= node->threshold) {
                node = node->left;
            } else {
                node = node->right;
            }
        }
        return node->prediction;
    }

private:
    void build_tree(Node* node, const std::vector<std::vector<double>>& X, const std::vector<int>& y, int depth) {
        if (depth >= max_depth || is_pure(y)) {
            node->is_leaf = true;
            node->prediction = majority_class(y);
            return;
        }

        int best_feature;
        double best_threshold;
        double best_impurity = std::numeric_limits<double>::max();
        std::vector<int> left_indices, right_indices;

        for (size_t i = 0; i < X[0].size(); ++i) {
            std::vector<double> thresholds = get_thresholds(X, i);
            for (double threshold : thresholds) {
                auto [left, right] = split(X, y, i, threshold);

                double impurity = (left.second.size() * gini_impurity(left.second) +
                                  right.second.size() * gini_impurity(right.second)) / y.size();

                if (impurity < best_impurity) {
                    best_feature = i;
                    best_threshold = threshold;
                    best_impurity = impurity;
                    left_indices = left.first;
                    right_indices = right.first;
                }
            }
        }

        if (left_indices.empty() || right_indices.empty()) {
            node->is_leaf = true;
            node->prediction = majority_class(y);
            return;
        }

        node->feature_index = best_feature;
        node->threshold = best_threshold;
        node->left = new Node();
        node->right = new Node();

        std::vector<std::vector<double>> left_X, right_X;
        std::vector<int> left_y, right_y;

        for (int idx : left_indices) {
            left_X.push_back(X[idx]);
            left_y.push_back(y[idx]);
        }
        for (int idx : right_indices) {
            right_X.push_back(X[idx]);
            right_y.push_back(y[idx]);
        }

        build_tree(node->left, left_X, left_y, depth + 1);
        build_tree(node->right, right_X, right_y, depth + 1);
    }

    std::pair<std::vector<int>, std::vector<int>> split(const std::vector<std::vector<double>>& X,
                                                        const std::vector<int>& y, int feature_index,
                                                        double threshold) const {
        std::vector<int> left_indices, right_indices;

        for (size_t i = 0; i < X.size(); ++i) {
            if (X[i][feature_index] <= threshold) {
                left_indices.push_back(i);
            } else {
                right_indices.push_back(i);
            }
        }

        return {left_indices, right_indices};
    }

    double gini_impurity(const std::vector<int>& labels) const {
        std::vector<int> counts(*std::max_element(labels.begin(), labels.end()) + 1, 0);
        for (int label : labels) {
            counts[label]++;
        }

        double impurity = 1.0;
        for (int count : counts) {
            double prob = count / static_cast<double>(labels.size());
            impurity -= prob * prob;
        }

        return impurity;
    }

    bool is_pure(const std::vector<int>& y) const {
        return std::all_of(y.begin(), y.end(), [label = y[0]](int v) { return v == label; });
    }

    int majority_class(const std::vector<int>& y) const {
        std::unordered_map<int, int> counts;
        for (int label : y) {
            counts[label]++;
        }

        return std::max_element(counts.begin(), counts.end(),
                               [](const auto& a, const auto& b) { return a.second < b.second; })->first;
    }

    std::vector<double> get_thresholds(const std::vector<std::vector<double>>& X, int feature_index) const {
        std::vector<double> thresholds;
        for (const auto& row : X) {
            thresholds.push_back(row[feature_index]);
        }
        std::sort(thresholds.begin(), thresholds.end());
        thresholds.erase(std::unique(thresholds.begin(), thresholds.end()), thresholds.end());
        return thresholds;
    }

    int max_depth;
    Node* root;
};

int main() {
    // Example dataset: AND gate
    std::vector<std::vector<double>> X = {{0, 0}, {0, 1}, {1, 0}, {1, 1}};
    std::vector<int> y = {0, 0, 0, 1};

    DecisionTree dt(3);
    dt.fit(X, y);

    for (const auto& sample : X) {
        std::cout << "Prediction for (" << sample[0] << ", " << sample[1] << "): "
                  << dt.predict(sample) << "\n";
    }

    return 0;
}
```

#### Előnyök és hátrányok

A döntési fák számos előnyt kínálnak:

- **Érthetőség**: A fák vizuálisan ábrázolhatók és könnyen értelmezhetők.
- **Rugalmas előfeldolgozás**: Nincs szükség különleges mérmértéki átalakításokra.
- **Nemlineáris kapcsolatok modellezése**: Különböző változók közötti nemlineáris kapcsolatok modellezésére is alkalmas.
- **Kategóriák és numerikus változók**: Kezelni tudja mindkét típusú változót.

Ugyanakkor van néhány hátránya is:

- **Túlilleszkedés**: Nagy mélységű fák hajlamosak a túlilleszkedésre.
- **Ingyen változó választás**: Az összes változó közötti döntési faépítési idő néha nagy, különösen nagyszámú változó esetén.
- **Stabilitási probléma**: Kis változások az adatokban jelentősen módosíthatják a fastruktúrát.

#### Bővítmények és alternatívák

Számos módosítás és bővítmény létezik a döntési fákhoz:

- **Random Forest**: Több döntési fa használata, ami csökkenti a túlilleszkedés kockázatát és növeli a pontosságot.
- **Gradient Boosting Machines (GBM)**: Több gyenge modell összegzése a jobb predikciós teljesítmény érdekében.
- **XGBoost**: Optimalizált implementáció, amely javítja a számítási hatékonyságot.

#### Alkalmazási területek

A döntési fák alkalmazási területei nagyon széleskörűek:

- **Orvostudomány**: Diagnosztikai rendszerek fejlesztése.
- **Pénzügyi elemzés**: Kockázatelemzés, adósságelőrejelzés.
- **Marketing**: Vásárlói magatartás előrejelzése, szegmentálás.
- **Telekommunikáció**: Ügyfél-elégedettség és ügyfélvesztés modellezése.

#### Összefoglalás

A döntési fák egyszerűségük és hatékonyságuk révén rendkívül népszerűek a gépi tanulásban. A modellezési folyamat érthető és könnyen követhető, így gyakran használják előzetes elemzésekhez és döntéshozatal támogatásához. Bár vannak korlátai, a megfelelő bővítményekkel és alternatívákkal a döntési fák rendkívül erőteljes eszközökké válhatnak mind osztályozási, mind regressziós feladatok esetén.

### Neurális hálók (Neural Networks)

A neurális hálók a gépi tanulás és a mesterséges intelligencia egyik legfontosabb és legdinamikusabban fejlődő területe. Inspirációjuk a biológiai idegrendszerek felépítéséből származik, bár jelentősen egyszerűsített és matematikai formában megvalósított modellekként használatosak. Ebben az alfejezetben részletesen bemutatjuk a neurális hálók működését, matematikai hátterét, különböző architektúrákat, tanítási algoritmusokat, alkalmazási területeiket, valamint azok előnyeit és korlátait.

#### Alapfogalmak és matematikai háttér

A neurális hálókat alapvetően három fő komponensből állítják össze:

1. **Neuronok (Perceptronok)**: Az alapegységek, amelyek adott bemeneteket feldolgoznak és egy kimenetet generálnak.
2. **Rétegek**: Az egyes neuronok csoportosan kerülnek elrendezése, lehetnek bemeneti, kimeneti vagy rejtett rétegek.
3. **Kapcsolatok és súlyok**: A neuronokat összekötő kapcsolatok, melyekhez súlyok (weights) rendelődnek. Ezek határozzák meg, hogy egy bemenet mennyire fontos.

##### Egyetlen neuron (Perceptron)

Egy egyszerű neuront a következő matematikai modell alapján ábrázolhatjuk:

$$ y = f\left( \sum_{i=1}^{n} w_i x_i + b \right) $$

ahol:
- $x_i$ az $i$-edik bemenet,
- $w_i$ az $i$-edik bemenethez tartozó súly,
- $b$ az alkalmazott eltolás (bias),
- $f$ egy aktivációs függvény.

##### Aktivációs függvények

Az aktivációs függvény a neuron kimenetét nemlineárisan transzformálja, ami lehetővé teszi, hogy a háló komplex kapcsolatokat modelláljon. A leggyakrabban alkalmazott aktivációs függvények a következők:

- **Szigmoid függvény**:

  $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

- **ReLU (Rectified Linear Unit)**:

  $$ \text{ReLU}(z) = \max(0, z) $$

- **Tanh (Hyperbolic Tangent)**:

  $$ \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} $$

- **Softmax**: Általában az utolsó kimeneti réteghez alkalmazzák többosztályos osztályozási problémák esetén:

  $$ \sigma(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}} $$

##### Teljesen összekapcsolt rétegek (Fully Connected Layers)

A neurális hálók esetén a legelterjedtebb réteg architektúra a teljesen összekapcsolt réteg (dense layer), ahol minden neuron a következő réteg minden neuronjával kapcsolatban áll. 

#### Tanítási algoritmusok

A neurális hálók tanítása általában felügyelt tanulás (supervised learning) formájában történik, amely során ismert input-output párokat használnak.

##### Backpropagation (Visszaterjesztés)

A visszaterjesztés a neurális hálók alapvető tanítási algoritmusa, amely a hiba visszaterjesztésén és a súlyok aktualizálásán alapul. A következő lépések sorrendjében zajlik:

1. **Előrecsatolás (Feedforward Pass)**: Számítsuk ki az első becslést a hálón keresztül a bemenetek alapján.
2. **Hibaszámítás (Loss Calculation)**: Határozzuk meg a háló becslésének hibáját egy célfüggvény (pl. MSE, Cross-Entropy loss) alapján.
3. **Hiba visszaterjesztése (Backward Pass)**: Számoljuk ki a hibát a háló minden rétegében a levezetési láncszabály szerint.
4. **Súlyfrissítés (Weight Update)**: Frissítsük a súlyokat a tanulási ráta (learning rate) felhasználásával a gradiens információk alapján.

##### Gradiens Descent Variációk

Többféle gradiens descent algoritmus létezik, amelyek különböznek abban, hogyan kezelik a gradiens információkat és milyen optimalizálási trükköket alkalmaznak:

- **Stochastic Gradient Descent (SGD)**: Minden egyes lépésben egyetlen adatpont alapján frissítjük a súlyokat.
- **Mini-batch Gradient Descent**: Az adatokat kis csomagokra bontjuk, és minden csomagra külön-külön frissítünk.
- **Momentum**: A gradiens frissítéseket egy előző gradiens súlyozott átlagával kombinálja.
- **Adam (Adaptive Moment Estimation)**: Kombinálja az RMSprop és momentum módszereket, a súlyok adaptív frissítése érdekében.

#### Különböző neurális háló architektúrák

A neurális hálók különböző architektúrái különféle típusú adatok és feladatok kezelésére alkalmazhatók:

##### Feedforward Neural Networks (Előrecsatolt Neurális Hálók)

Ez a leggyakrabban használt hálótípus, amelyben az információ minden rétegen keresztül előrefelé áramlik a bemenettől a kimenetig. Alkalmazható osztályozási és regressziós feladatokhoz is.

##### Convolutional Neural Networks (CNN)

A CNN-ek speciálisan képfeldolgozási feladatokra tervezettek, ahol konvolúciós rétegeket alkalmaznak a megfigyelések lokális mintázatainak azonosítására. Jellemző rétegek közé tartoznak a konvolúciós, pooling és teljesen összekapcsolt rétegek.

##### Recurrent Neural Networks (RNN)

Az RNN-ek időbeli vagy soros adatokhoz használatosak, ahol az adatok időben egymásra épülnek. Az alapötlet, hogy a háló belső állapota visszacsatoltan kapcsolódik az előző időlépés kimenetéhez.

##### Long Short-Term Memory Networks (LSTM)

Az LSTM egy RNN variáció, amelyet úgy terveztek, hogy hosszú távú függőségek kezelésére alkalmas legyen. Speciális kapukat és cella állapotokat használ, hogy minimalizálják a gradiens eltűnésének problémáját.

##### Generative Adversarial Networks (GAN)

A GAN-ek két neurális háló (egy generátor és egy diszkriminátor) kombinációját tartalmazzák, amelyek egymással szemben tanulnak. Ez a struktúra különösen hatékony a generatív feladatokban, mint például képgenerálás vagy adattakarítás.

#### Alkalmazási területek

A neurális hálók rendkívül sokféle gyakorlati alkalmazási területtel rendelkeznek:

- **Képfelismerés és számítógépes látás**: Arcfelismerés, objektum detekció, orvosi képalkotás.
- **Természetes nyelv feldolgozás (NLP)**: Szövegértelmezés, gépi fordítás, szentimentelemzés.
- **Hang- és beszédfelismerés**: Automatikus beszédátírás, hangszóró azonosítás, zeneelemzés.
- **Játékok és szimulációk**: AI fejlesztés játékokban, autonóm járművek irányítása.
- **Pénzügyi elemzés**: Részvényárfolyam előrejelzés, hitelminősítés, csalás detektálása.

#### Példa neurális háló megvalósítására C++ nyelven

Itt van egy egyszerű példa egy neurális háló feedforward pass és visszaterjesztés megvalósítására C++ nyelven.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <random>

class NeuralNetwork {
public:
    NeuralNetwork(int input_size, int hidden_size, int output_size)
        : input_size(input_size), hidden_size(hidden_size), output_size(output_size) {
        init_weights();
    }

    void train(const std::vector<std::vector<double>>& X, const std::vector<std::vector<double>>& y, int epochs, double lr) {
        for (int i = 0; i < epochs; ++i) {
            for (size_t j = 0; j < X.size(); ++j) {
                forward(X[j]);
                backward(X[j], y[j], lr);
            }
        }
    }

    std::vector<double> predict(const std::vector<double>& X) {
        forward(X);
        return output;
    }

private:
    int input_size;
    int hidden_size;
    int output_size;
    std::vector<std::vector<double>> W1;
    std::vector<std::vector<double>> W2;
    std::vector<double> hidden;
    std::vector<double> output;

    void init_weights() {
        W1.resize(input_size, std::vector<double>(hidden_size));
        W2.resize(hidden_size, std::vector<double>(output_size));
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<> dis(-1.0, 1.0);

        for (auto& row : W1) {
            for (auto& val : row) {
                val = dis(gen);
            }
        }

        for (auto& row : W2) {
            for (auto& val : row) {
                val = dis(gen);
            }
        }
    }

    void forward(const std::vector<double>& X) {
        hidden.resize(hidden_size);
        output.resize(output_size);

        for (int i = 0; i < hidden_size; ++i) {
            hidden[i] = 0.0;
            for (int j = 0; j < input_size; ++j) {
                hidden[i] += X[j] * W1[j][i];
            }
            hidden[i] = sigmoid(hidden[i]);
        }

        for (int i = 0; i < output_size; ++i) {
            output[i] = 0.0;
            for (int j = 0; j < hidden_size; ++j) {
                output[i] += hidden[j] * W2[j][i];
            }
            output[i] = sigmoid(output[i]);
        }
    }

    void backward(const std::vector<double>& X, const std::vector<double>& y, double lr) {
        std::vector<double> output_error(output_size);
        for (int i = 0; i < output_size; ++i) {
            output_error[i] = (output[i] - y[i]) * sigmoid_derivative(output[i]);
        }

        std::vector<double> hidden_error(hidden_size);
        for (int i = 0; i < hidden_size; ++i) {
            hidden_error[i] = 0.0;
            for (int j = 0; j < output_size; ++j) {
                hidden_error[i] += output_error[j] * W2[i][j];
            }
            hidden_error[i] *= sigmoid_derivative(hidden[i]);
        }

        for (int i = 0; i < hidden_size; ++i) {
            for (int j = 0; j < output_size; ++j) {
                W2[i][j] -= lr * hidden[i] * output_error[j];
            }
        }

        for (int i = 0; i < input_size; ++i) {
            for (int j = 0; j < hidden_size; ++j) {
                W1[i][j] -= lr * X[i] * hidden_error[j];
            }
        }
    }

    double sigmoid(double z) const {
        return 1.0 / (1.0 + std::exp(-z));
    }

    double sigmoid_derivative(double z) const {
        return z * (1.0 - z);
    }
};

int main() {
    std::vector<std::vector<double>> X = {{0, 0}, {0, 1}, {1, 0}, {1, 1}};
    std::vector<std::vector<double>> y = {{0}, {1}, {1}, {0}};

    NeuralNetwork nn(2, 2, 1);
    nn.train(X, y, 10000, 0.1);

    for (const auto& sample : X) {
        auto prediction = nn.predict(sample);
        std::cout << "Prediction for (" << sample[0] << ", " << sample[1] << "): " << prediction[0] << "\n";
    }

    return 0;
}
```

#### Előnyök és korlátok

A neurális hálók számos kiemelkedő előnnyel rendelkeznek:

- **Nemlineáris modellezés**: Komplex, nemlineáris függőségek és mintázatok felismerése.
- **Általánosítási képesség**: Ha jól tanították őket, általánosíthatók új adatpontokra.
- **Autodidakta tanulás**: Megfelelően nagy és változatos adathalmazból képesek önállóan tanulni.

Azonban vannak korlátaik is:

- **Adatigény**: Nagy mennyiségű adat szükséges a hatékony tanuláshoz.
- **Számítási költség**: Nagy hálók tanítása idő- és számításigényes.
- **Értelmezhetőség**: Az állapotok és döntések értelmezési nehézsége "fekete doboz" jellegű modellként.

#### Összefoglalás

A neurális hálók a mesterséges intelligencia egyik legdinamikusabban fejlődő területei, amelyek képesek komplex adatokból tanulni és nemlineáris kapcsolatokat modellezni. A különböző architektúrák és tanítási algoritmusok lehetővé teszik, hogy szinte bármilyen gépi tanulási feladatot rendkívüli pontossággal és hatékonysággal oldjanak meg. Bár kihívásokkal és korlátokkal is szembesülnek, a neurális hálók alkalmazási lehetőségei és előnyei rendkívül sokrétűek, ezzel korunk egyik legfontosabb technológiai eszközévé téve őket.

