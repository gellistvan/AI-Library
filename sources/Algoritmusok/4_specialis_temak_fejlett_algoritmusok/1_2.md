\newpage

## 1.2. Klasszikus randomizált algoritmusok

A számítástudomány területén a randomizált algoritmusok olyan algoritmusok, melyek véletlenszerűséget alkalmaznak annak érdekében, hogy hatékonyabb és gyakran egyszerűbb megoldásokat nyújtsanak különböző problémákra. Ezek az algoritmusok nem determinisztikusak, vagyis ugyanazon bemenetre különböző futtatások során eltérő kimenetet adhatnak, ami számos gyakorlati előnnyel jár. Ebben a fejezetben két klasszikus randomizált algoritmust mutatunk be: a randomizált gyorsrendezést (Randomized Quick Sort) és a randomizált keresést (Randomized Search). Ezek az algoritmusok nemcsak hatékonyságuk miatt figyelemre méltóak, hanem azért is, mert rávilágítanak a véletlenszerűség erejére és hasznosságára az algoritmusok tervezésében és elemzésében. Ismerjük meg, hogyan használhatjuk a véletlenszerűséget a probléma megoldási folyamatának javítására!

### Randomizált gyorsrendezés (Randomized Quick Sort)

A gyorsrendezés, angolul Quick Sort, az egyik legismertebb és leggyakrabban használt rendezési algoritmus, mely különösen hatékonyan alkalmazható nagy tömbök rendezésére. A klasszikus Quick Sort algoritmus a "oszd meg és uralkodj" (divide and conquer) elvet követi, mely során a bemeneti tömböt kisebb részekre bontja, majd azokat rekurzívan rendezi. Az algoritmus központi eleme a pivot elem kiválasztása, amely meghatározza a felosztási pontot. Azonban a pivot elem okos megválasztása rendkívül fontos, mivel ez befolyásolja az algoritmus futási idejét. A randomizált gyorsrendezés (Randomized Quick Sort) ezen a ponton hoz újítást azáltal, hogy véletlenszerűen választja ki a pivot elemet, így csökkentve a legrosszabb eset bekövetkeztének valószínűségét.

#### Algoritmus leírása

**Lépések:**

1. **Véletlenszerű Pivot Kiválasztása:** A randomizált gyorsrendezés egyik legfontosabb lépése a pivot véletlenszerű kiválasztása. Ahelyett, hogy egy fix helyről (például az első vagy az utolsó elemtől) választanánk pivotot, egy véletlenszám-generátort használunk, hogy egy tetszőleges indexet válasszunk a tömbön belül. Ez a lépés biztosítja, hogy a pivot választás kevésbé legyen kiszámítható, és elkerüljük a legrosszabb esetet, ahol a pivot mindig a legkisebb vagy legnagyobb elem.

2. **Elrendezés a Pivot Körül (Partition):** A következő lépésben a tömböt két részre osztjuk: az egyik részen a pivotnál kisebb értékek, a másikon a pivotnál nagyobb értékek lesznek. Ezt a lépést partition néven ismerjük.

3. **Rekurzív Rendezés:** Miután a tömböt két részre bontottuk, mindkét részre ugyanazt az eljárást alkalmazzuk rekurzívan. 

Az alábbiakban részletesen bemutatjuk a Randomized Quick Sort algoritmust:

#### Pseudo-kód

```
Randomized-QuickSort(A, p, r)
    if p < r
        q <- Randomized-Partition(A, p, r)
        Randomized-QuickSort(A, p, q - 1)
        Randomized-QuickSort(A, q + 1, r)

Randomized-Partition(A, p, r)
    i <- Random(p, r)
    swap A[r] with A[i]
    return Partition(A, p, r)

Partition(A, p, r)
    x <- A[r]
    i <- p - 1
    for j <- p to r - 1
        if A[j] <= x
            i <- i + 1
            swap A[i] with A[j]
    swap A[i + 1] with A[r]
    return i + 1
```

#### C++ Implementáció

```cpp
#include <iostream>
#include <vector>
#include <cstdlib>
#include <ctime>

using namespace std;

int Partition(vector<int>& A, int p, int r) {
    int x = A[r];
    int i = p - 1;
    for (int j = p; j <= r - 1; j++) {
        if (A[j] <= x) {
            i++;
            swap(A[i], A[j]);
        }
    }
    swap(A[i + 1], A[r]);
    return i + 1;
}

int RandomizedPartition(vector<int>& A, int p, int r) {
    int i = p + rand() % (r - p + 1);
    swap(A[r], A[i]);
    return Partition(A, p, r);
}

void RandomizedQuickSort(vector<int>& A, int p, int r) {
    if (p < r) {
        int q = RandomizedPartition(A, p, r);
        RandomizedQuickSort(A, p, q - 1);
        RandomizedQuickSort(A, q + 1, r);
    }
}

int main() {
    srand(time(0));
    vector<int> A = {3, 6, 8, 10, 1, 2, 1};
    RandomizedQuickSort(A, 0, A.size() - 1);
    for (int i = 0; i < A.size(); i++) {
        cout << A[i] << " ";
    }
    return 0;
}
```

#### Részletes magyarázat

1. **Véletlenszerű Pivot Kiválasztása:**
   A véletlenszerű pivot kiválasztása megnöveli a valószínűséget, hogy az algoritmus közel optimális időben fut le. Determinális pivotválasztás esetén, például mindig az első vagy az utolsó elemet választva, a legrosszabb eset (O(n²) időkomplexitás) gyakrabban fordulhat elő, különösen ha a bemeneti tömb már majdnem rendezett vagy teljesen rendezett. A véletlenszerű pivot azonban eloszlatja ezt a valószínűséget, mivel minden futás során a pivot választása független.

2. **Elrendezés a Pivot Körül (Partition):**
   Amikor a véletlenszerűen kiválasztott pivotot a tömb végére helyezzük, a Partition algoritmus a pivot körül rendezi a tömb elemeit úgy, hogy a pivotnál kisebb elemek a bal oldalra, a nagyobb elemek a jobb oldalra kerülnek. Ez a típusú elrendezés biztosítja, hogy minden rekurzív hívásban a tömb feloszlik és végül teljesen rendezetté válik.

3. **Rekurzív Rendezés:**
   A rendezést rekurzívan hajtjuk végre a tömb bal és jobb oldalán a pivot előtti és utáni elemekre vonatkozóan. Az alap eset az, amikor a tömb mérete egy vagy nulla, ekkor nem szükséges további rendezés.

#### Futási idő és komplexitási elemzés

A Randomized Quick Sort várható futási ideje O(n log n), amely hasonló a determinisztikus Quick Sort legjobb és átlagos esetéhez. Ennek oka, hogy a véletlenszerű pivot kiválasztásának köszönhetően a tömb általában egyensúlyban van, azaz a pivot elem nagyjából középen van, így a felosztások száma log n, és minden szinten a teljes tömböt egyszer végigolvassuk, ami n. Ez együttesen O(n log n) komplexitást eredményez.

A legrosszabb eset futási ideje O(n²), amely akkor fordulhat elő, ha a pivot mindig a legkisebb vagy legnagyobb elem, így a partíciók nagyon kiegyensúlyozatlanok. Azonban a véletlenszerű választás ezt a legrosszabb esetet kevésbé valószínűvé teszi, így a gyakorlatban a Randomized Quick Sort szinte mindig O(n log n) futási idővel fut le.

#### Előnyök és hátrányok

**Előnyök:**
1. **Hatékonyság:** Átlagosan O(n log n) futási idővel rendelkezik, ami nagyon kedvező a nagy adatkészletek rendezésekor.
2. **Egyszerű implementáció:** A bevezetett véletlenszerűség viszonylag egyszerűen hozzáadható a klasszikus gyorsrendezés algoritmusához.
3. **Gyorsulás gyakorlatban:** A Randomized Quick Sort gyakran gyorsabb, mint a determinisztikus verzió, mivel ritkábban fordul elő a legrosszabb eset.

**Hátrányok:**
1. **Legrosszabb eset:** Bár ritka, de még mindig lehetséges, hogy a legrosszabb esetben O(n²) futási idejű.
2. **Randomizálás költsége:** A véletlenszerű pivot kiválasztásának költsége csekély, de nem elhanyagolható.
3. **Nem stabil:** A rendezési algoritmus nem stabil, azaz nem őrzi meg a hasonló értékű elemek eredeti sorrendjét.

Összegzésként elmondható, hogy a Randomized Quick Sort egy hatékony és gyakorlati megoldás a rendezési feladatokra, mely képes kihasználni a véletlenszerűség előnyeit a futási idő optimalizálása érdekében, és széles körben alkalmazott algoritmussá vált a számítástudományban és az iparban egyaránt.

### Randomizált keresés (Randomized Search)

A randomizált keresés (Randomized Search) olyan algoritmus, amely véletlenszerűséget alkalmaz a keresési folyamat hatékonyságának növelése érdekében. Ez a megközelítés különösen hasznos lehet olyan problémáknál, ahol a keresési tér nagy vagy bonyolult, és a determinisztikus keresési algoritmusok elfogadhatatlanul hosszú ideig futnának. A randomizált keresési algoritmusok célja, hogy a véletlenszerűséget kihasználva gyorsabban és nagyobb valószínűséggel találják meg a keresett elemet vagy optimális megoldást.

#### Alapelvek és motiváció

A randomizált keresés számos alkalmazási területen jelenik meg, mint például az optimalizálás, játékelmélet, adatbázis-keresés és a mesterséges intelligencia. A véletlenszerűség bevezetése több előnyt is biztosít:
1. **Javított teljesítmény:** A véletlenszerűséget alkalmazva az algoritmus képes lehet elkerülni a determinisztikus algoritmusok által gyakran tapasztalt legrosszabb eseteket.
2. **Egyszerűség:** A randomizáció gyakran egyszerűbb megvalósítást eredményezhet, mivel nem szükséges bonyolult adatstruktúrákat használni.
3. **Flexibilitás:** A randomizált algoritmusok gyakran könnyen adaptálhatóak különböző keresési terekhez és problémákhoz.

Az alábbiakban bemutatunk néhány klasszikus randomizált keresési algoritmust és technikát:

#### Randomizált Lineáris Keresés

A lineáris keresés (Linear Search) egy egyszerű algoritmus, mely sorban ellenőrzi egy tömb vagy lista minden elemét, amíg meg nem találja a keresett elemet, vagy végig nem ér a listán. A randomizált változat egy véletlenszerű sorrendben keres a listában. Míg a determinisztikus lineáris keresés legrosszabb esetben O(n) időkomplexitású, a randomizált változat átlagosan hasonló időkomplexitással rendelkezik, de bizonyos helyzetekben elkerülheti a legrosszabb esetet.

**Algoritmus leírása:**

1. **Inicializáció:** Vegyünk egy listát, amelyben keresni szeretnénk egy adott elemet.
2. **Véletlenszerű Permutáció:** Alkalmazzunk egy véletlenszerű permutációt a lista elemeire. Ezt megtehetjük például a Fischer-Yates algoritmus segítségével.
3. **Keresés:** Végezzen el egy lineáris keresést a véletlenszerűen permutált listában.

#### Pseudo-kód

```
Randomized-Linear-Search(A, target)
    P <- Random-Permutation(A)
    for i <- 0 to length(P) - 1
        if P[i] == target
            return i
    return -1

Random-Permutation(A)
    n <- length(A)
    for i <- 0 to n - 2
        j <- Random(i, n - 1)
        swap A[i] with A[j]
    return A
```

#### C++ Implementáció:

```cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <ctime>
#include <cstdlib>

using namespace std;

vector<int> randomPermutation(vector<int> A) {
    int n = A.size();
    for (int i = 0; i < n - 1; i++) {
        int j = i + rand() / (RAND_MAX / (n - i) + 1);
        swap(A[i], A[j]);
    }
    return A;
}

int randomizedLinearSearch(vector<int> A, int target) {
    vector<int> P = randomPermutation(A);
    for (int i = 0; i < P.size(); i++) {
        if (P[i] == target) return i;
    }
    return -1;
}

int main() {
    srand(time(0));
    vector<int> A = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};
    int target = 7;
    int result = randomizedLinearSearch(A, target);
    if (result != -1) {
        cout << "Element found at index: " << result << endl;
    } else {
        cout << "Element not found." << endl;
    }
    return 0;
}
```

#### Sztochasztikus Gázi keresés (Stochastic Gradient Descent - SGD)

Az optimalizálási problémák egyik legismertebb randomizált keresési algoritmusa a sztochasztikus gradient descent (SGD). Az SGD az optimalizálási problémák megoldására szolgál, ahol egy célfüggvényt minimálni vagy maximalizálni kell. Az SGD a klasszikus gradient descent randomizált változata, amely véletlenszerűen választja ki a célfüggvény egy-egy mintáját minden iterációban, így gyorsabban konvergálhat.

**Algoritmus leírása:**

1. **Inicializáció:** Kezdj egy véletlenül választott kezdőponttal a keresési térben.
2. **Iteráció:** Minden iterációban véletlenszerűen válassz egy mintát az adathalmazból, és számítsd ki a gradientet az adott minta alapján.
3. **Frissítés:** Az aktuális pozíció frissítése a gradient iránya mentén egy kis lépésben.
4. **Konvergencia:** Az algoritmus iterál addig, amíg a gradient elég kicsi lesz, jelezve, hogy a lokális minimumhoz konvergált.

#### Pseudo-kód

```
SGD(f, grad_f, theta_0, eta, max_iter)
    theta <- theta_0
    for i <- 1 to max_iter
        x_i <- Random-Sample(data)
        gradient <- grad_f(theta, x_i)
        theta <- theta - eta * gradient
    return theta
```

#### C++ Implementáció

Ebben az esetben a konkrét implementáció függ a célfüggvénytől és annak gradientjétől, ezért egy általános példa következik az SGD használatára egy egyszerű kvadratikus függvény optimalizálására.

```cpp
#include <iostream>
#include <vector>
#include <cstdlib>
#include <ctime>
#include <cmath>

using namespace std;

// Example function: f(theta) = (theta - 3)^2
double f(double theta) {
    return pow(theta - 3, 2);
}

// Gradient of the example function: grad_f(theta) = 2 * (theta - 3)
double grad_f(double theta) {
    return 2 * (theta - 3);
}

double stochasticGradientDescent(double theta_0, double eta, int max_iter) {
    double theta = theta_0;
    for (int i = 0; i < max_iter; i++) {
        double gradient = grad_f(theta);
        theta = theta - eta * gradient;
    }
    return theta;
}

int main() {
    srand(time(0));
    double initial_theta = 0;
    double learning_rate = 0.1;
    int iterations = 1000;
    
    double result = stochasticGradientDescent(initial_theta, learning_rate, iterations);
    
    cout << "Optimal theta: " << result << endl;
    cout << "Minimum value of f(theta): " << f(result) << endl;
    
    return 0;
}
```

#### Futási idő és komplexitási elemzés

A randomizált keresési algoritmusok időkomplexitása változó, és nagyban függ az adott problémától és a randomizáció alkalmazási módjától. A klasszikus lineáris keresés legrosszabb esetben O(n) időkomplexitású, és ugyanez vonatkozik a randomizált verzióra is, bár a véletlenszerűség miatt bizonyos esetekben hatékonyabb lehet.

Az SGD algorithmus komplexitása gyakran a gradient számításának bonyolultságától függ, ami mintánként O(d) lehet, ahol d a dimenziók száma. Az implementációk számos iterációra futnak, így az összkomplexitás O(kd),  ahol k az iterációk száma.

#### Előnyök és hátrányok

**Előnyök:**
1. **Hatékonyság:** A randomizált keresési algoritmusok gyakran gyorsabban találják meg az optimális vagy majdnem optimális megoldást.
2. **Egyszerűség:** A véletlenszerűség bevezetése gyakran egyszerűbbé teheti az algoritmus implementációját és alkalmazását.
3. **Globális optimalizáció:** Különösen hasznosak olyan problémáknál, ahol több lokális minimum/máximum létezik, mivel a randomizáció segíthet elkerülni a helyi optimumok csapdáját.

**Hátrányok:**
1. **Legrosszabb eset:** Bár a várható futási idő általában kedvező, a legrosszabb eset időkomplexitása gyakran nem javul jelentősen a determinisztikus változathoz képest.
2. **Determinálhatóság:** A véletlenszerűséget alkalmazó algoritmusok esetében az eredmények nem reprodukálhatóak ugyanúgy minden futásától függően.
3. **Paraméter érzékenység:** Az optimalizálási algoritmusok, mint például az SGD esetében, a paraméterek, mint például a tanulási ráta, nagyban befolyásolják a konvergencia sebességét és minőségét.

Összegzésként elmondható, hogy a randomizált keresés hatékony és rugalmas eszköztárat kínál a különböző keresési és optimalizálási problémákra. A randomizáció bevezetésével a keresési folyamatok gyakran hatékonyabbá és robusztusabbá tehetők, különösen nagy és komplex keresési terek esetén.

