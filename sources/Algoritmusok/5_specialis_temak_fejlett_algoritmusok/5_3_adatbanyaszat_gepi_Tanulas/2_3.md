A gépi tanulás napjaink egyik legdinamikusabban fejlődő területe, amely forradalmasította számos iparág működését és lehetőséget adott korábban elképzelhetetlen problémák megoldására. Ezen fejezet célja, hogy bemutassa a gépi tanulásban leggyakrabban használt algoritmusok alapjait és alkalmazásait. Kezdetnek a lineáris és logisztikus regresszióval ismerkedünk meg, amelyek egyszerűségük ellenére robusztus megoldásokat kínálnak különböző predikciós feladatokban. Ezt követően a döntési fák mélyére ásunk, amelyek átlátható és intuitív módon kezelik az összetett döntési problémákat. Végül az idegrendszer mintájára épülő neurális hálókat tárgyaljuk, amelyek képességei messze túlmutatnak a hagyományos algoritmusokén, így az önvezető autók és a szövegértés területén is kulcsszerepet töltenek be. Ezen algoritmusok bemutatása mellett konkrét alkalmazásokra és példákra is kitérünk, hogy megérthessük, miként formálják át mindennapi életünket és hogyan használhatók fel konkrét üzleti vagy tudományos célokra.

### 3. Gépi tanulási algoritmusok

#### Lineáris Regresszió

A lineáris regresszió az egyik legegyszerűbb és legszélesebb körben használt gépi tanulási algoritmus, amely összefüggést keres egy független változó (vagy több független változó) és egy függő változó között. A lineáris regresszió célja egy egyenes (vagy egy többdimenziós sík) illesztése az adatponthalmazhoz, hogy minimalizálja az átlépési hibát.

##### Alapok

A lineáris regresszió alapját az alábbi egyszerű egyenlet képezi:

$$ y = \beta_0 + \beta_1x + \epsilon $$

ahol:
- $y$ a függő változó,
- $\beta_0$ az y-tengely metszéspontja (intercept),
- $\beta_1$ a független változó meredekségi (slope) együtthatója,
- $x$ a független változó,
- $\epsilon$ a modell hibájának (residual) véletlen komponense.

A lineáris regresszió célja a paraméterek ($\beta_0$, $\beta_1$) becslése, hogy az adott értékek ($x$-ek) mellett a legjobb predikciókat adja $y$-ra. A leggyakrabban használt módszer a paraméterek becslésére az Ordinary Least Squares (OLS) módszer, amely minimalizálja a négyzetes hibát:

$$ \min_{\beta_0, \beta_1} \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_i))^2 $$

##### Algoritmus

1. **Adatgyűjtés és előkészítés**:
   A szükséges adatok gyűjtése és előkészítése, beleértve a különféle előfeldolgozási lépéseket (pl. normalizálás, standardizálás, outlierek kezelése).

2. **Model Selection**:
   A modell létrehozása alatt egy vagy több független változó és egy függő változó kiválasztása.

3. **Parameter Estimation via OLS**:
   Az OLS módszer alkalmazása a paraméterek becslésére:

   $$
   \hat{\beta} = (X^TX)^{-1}X^Ty
   $$

   ahol $X$ az adatmátrix, amely az összes megfigyelést tartalmazza (beleértve $x_1, x_2, \ldots, x_n$), és $y$ a függő változók vektorja.

4. **Model Validation**:
   A modell validálása teszt adatokon, amely lehetővé teszi a modell teljesítményének értékelését különféle metrikák segítségével (pl. Mean Squared Error, R-squared).

5. **Prediction**:
   Az új adatpontokra vonatkozó predikciók meghatározása az illesztett modell segítségével.

##### Alkalmazások
A lineáris regresszió széles körben alkalmazható számtalan területen, beleértve a közgazdaságtant, az orvostudományt, az agrártudományt és a társadalomtudományokat. Például:

1. **Ház árának becslése**:
   Az ingatlan piacon a ház árának becslése különböző jellemzők, mint például a helyszín, a ház mérete, az építés éve stb. alapján egy gyakran használt alkalmazása a lineáris regressziónak.

2. **Epidemiológiai kutatások**:
   Epidemiológiai tanulmányok során egy adott betegség előfordulásának gyakoriságát gyakran előre jelezhetjük a különböző demográfiai és életmódbeli tényezők alapján.

3. **Gazdasági előrejelzések**:
   A lineáris regresszió gyakran alkalmazott a gazdasági indikátorok előrejelzésére, mint például az infláció, munkanélküliség, GDP növekedés stb.

4. **Marketing**:
   A lineáris regresszió használható a marketing költések és az eladások közötti kapcsolat elemzésére, ezáltal optimalizálva a marketing költségkereteket.

##### Példakód C++ nyelven

Íme egy egyszerű példakód C++ nyelven a lineáris regresszió implementálására. Ez a kód bemutatja a paraméterek becslését az OLS módszerrel.

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <cmath>

class LinearRegression {
public:
    void fit(const std::vector<double>& x, const std::vector<double>& y) {
        double n = x.size();
        double x_mean = std::accumulate(x.begin(), x.end(), 0.0) / n;
        double y_mean = std::accumulate(y.begin(), y.end(), 0.0) / n;

        double xy_sum = 0.0, xx_sum = 0.0;
        for (size_t i = 0; i < n; ++i) {
            xy_sum += (x[i] - x_mean) * (y[i] - y_mean);
            xx_sum += (x[i] - x_mean) * (x[i] - x_mean);
        }

        beta_1 = xy_sum / xx_sum;
        beta_0 = y_mean - beta_1 * x_mean;
    }

    double predict(double x) const {
        return beta_0 + beta_1 * x;
    }

private:
    double beta_0 = 0.0;
    double beta_1 = 0.0;
};

int main() {
    // Example data
    std::vector<double> x = {1, 2, 3, 4, 5};
    std::vector<double> y = {2, 3, 5, 7, 11};

    LinearRegression model;
    model.fit(x, y);

    double x_new = 6;
    double y_pred = model.predict(x_new);

    std::cout << "Predicted y for x = " << x_new << " is " << y_pred << std::endl;

    return 0;
}
```

Ez a kód bemutat egy egyszerű lineáris regressziós modellt, amely két fő részből áll: a `fit` és a `predict` metódusokból. A `fit` metódus becsli a paramétereket az OLS módszerrel, míg a `predict` metódus használható új adatpontokra való predikciók készítésére.

##### Összegzés

Összegzésképpen, a lineáris regresszió egy univerzális és hatékony eszköz a különböző típusú adatok elemzésére és előrejelzések készítésére. Az OLS módszer felhasználásával a lineáris regresszió képes optimális paramétereket becsülni, amelyek minimalizálják a prediktív hibát. Számos valós életbeli alkalmazási területen használt, rugalmas és hatékony eszköz, amely nélkülözhetetlen a gépi tanulásban és az adatbányászatban.

# 3. Gépi tanulási algoritmusok

## Lineáris regresszió

### Algoritmus és alkalmazások

Lineáris regresszió az egyik legismertebb és leggyakrabban használt gépi tanulási módszer, amely célja a függő változó értékeinek előrejelzése a független változók értékei alapján. A lineáris regresszió algoritmusa az adatok közötti lineáris kapcsolatot modellezi.

### Algoritmus

Az egyszerű lineáris regresszió esetében az előrejelzendő változót (célt) egyetlen független változó segítségével jósoljuk meg. Ez a kapcsolat egyenlete a következő:

$$ y = \beta_0 + \beta_1 x + \epsilon $$

ahol:
- $y$ a célváltozó,
- $x$ a független változó,
- $\beta_0$ az y-tengely metszéspontja vagy elfogási érték,
- $\beta_1$ a regressziós együttható vagy lejtés,
- $\epsilon$ a hibaterm.

Többszörös lineáris regresszió esetén több független változó is lehet, az egyenlet alakja így:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon $$

Az algoritmus célja a legjobb illeszkedésű paraméterek ($\beta$k) megtalálása a mechanizmushoz, amely a legkisebb hibát okozza a valós és a predikált értékek között. A leggyakrabban használt módszer erre az OLS (Ordinary Least Squares - Általános Legkisebb Négyzetek) módszer, amely minimalizálja az összes hibaterm négyzetes összegét:

$$ \min_{\beta} \sum_{i=1}^{N} (y_i - (\beta_0 + \beta_1 x_{i1} + \ldots + \beta_n x_{in}))^2 $$

Az optimalizálási probléma megoldására több megközelítést is alkalmazhatunk. Ezek egyike a gradiens csökkenés (Gradient Descent):

```cpp
#include <vector>
#include <cmath>

struct LinearRegression {
    std::vector<double> weights;
    double learning_rate;
    int epochs;

    LinearRegression(double lr, int ep) : learning_rate(lr), epochs(ep) {}

    void fit(const std::vector<std::vector<double>>& X, const std::vector<double>& y) {
        int m = X.size();
        int n = X[0].size();
        weights.resize(n+1, 0.0); // Initialize weights

        for (int epoch = 0; epoch < epochs; ++epoch) {
            std::vector<double> predictions = predict(X);
            for (int j = 0; j <= n; ++j) {
                double gradient = 0.0;
                for (int i = 0; i < m; ++i) {
                    double error = predictions[i] - y[i];
                    gradient += (j == 0) ? error : error * X[i][j-1];
                }
                weights[j] -= (learning_rate * gradient / m);
            }
        }
    }

    std::vector<double> predict(const std::vector<std::vector<double>>& X) const {
        int m = X.size();
        std::vector<double> predictions(m, weights[0]);
        for (int i = 0; i < m; ++i) {
            for (int j = 0; j < X[0].size(); ++j) {
                predictions[i] += X[i][j] * weights[j+1];
            }
        }
        return predictions;
    }
};
```

### Alkalmazások

A lineáris regressziót széles körben alkalmazzák különféle területeken, mint például:

1. **Gazdaság és pénzügyek**: Részvényárfolyamok előrejelzése, piaci trendek modellezése.
2. **Egészségügyi vizsgálatok**: Páciensek adatai alapján kimeneti változók előrejelzése, például vérnyomás, cukorszint.
3. **Szociológiai kutatások**: Demográfiai adatok elemzése.
4. **Marketing**: Reklámok hatékonyságának elemzése, értékesítési előrejelzések.

## Logisztikus regresszió

### Algoritmus és alkalmazások

A logisztikus regresszió egy másik fontos gépi tanulási algoritmus, amelyet főként bináris besorolási feladatokra használnak. Ez az algoritmus megpróbálja modellezni a függő változó és a független változók közötti kapcsolatot a logisztikus függvény segítségével, amely az eredményt egy valószínűségi értékként adja meg.

### Algoritmus

A logisztikus regresszió bináris kimenet esetén egy logisztikus vagy sigmoid függvényt használ, amely az alábbi formában írható le:

$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

ahol $z$ az alábbi egyenlet szerint definiálható:

$$ z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n $$

A cél az, hogy a modellezéssel kapott valószínűségi értéket $0$ és $1$ között adja meg, amelyből bináris döntést lehet hozni (pl. denormalizálás $0$ és $1$ között).

A logaritmikus veszteségfüggvény használatos az optimalizálás során, amely minimalizálja a predikált és a valós érték közötti különbséget:

$$ \text{Loss} = - \frac{1}{N} \left[ \sum_{i=1}^{N} y_i \log(\hat{y_i}) + (1 - y_i) \log(1 - \hat{y_i}) \right] $$

A gradiens csökkenés szintén alkalmazható ennek a veszteségfüggvénynek az optimalizálására.

```cpp
#include <vector>
#include <cmath>

struct LogisticRegression {
    std::vector<double> weights;
    double learning_rate;
    int epochs;

    LogisticRegression(double lr, int ep) : learning_rate(lr), epochs(ep) {}

    double sigmoid(double z) const {
        return 1.0 / (1.0 + std::exp(-z));
    }

    void fit(const std::vector<std::vector<double>>& X, const std::vector<double>& y) {
        int m = X.size();
        int n = X[0].size();
        weights.resize(n+1, 0.0); // Initialize weights

        for (int epoch = 0; epoch < epochs; ++epoch) {
            std::vector<double> predictions = predict_prob(X);
            for (int j = 0; j <= n; ++j) {
                double gradient = 0.0;
                for (int i = 0; i < m; ++i) {
                    double error = predictions[i] - y[i];
                    gradient += (j == 0) ? error : error * X[i][j-1];
                }
                weights[j] -= (learning_rate * gradient / m);
            }
        }
    }

    std::vector<double> predict_prob(const std::vector<std::vector<double>>& X) const {
        int m = X.size();
        std::vector<double> predictions(m, weights[0]);
        for (int i = 0; i < m; ++i) {
            for (int j = 0; j < X[0].size(); ++j) {
                predictions[i] += X[i][j] * weights[j+1];
            }
            predictions[i] = sigmoid(predictions[i]);
        }
        return predictions;
    }

    std::vector<int> predict(const std::vector<std::vector<double>>& X) const {
        std::vector<double> probs = predict_prob(X);
        std::vector<int> predictions(probs.size());
        for (size_t i = 0; i < probs.size(); ++i) {
            predictions[i] = probs[i] >= 0.5 ? 1 : 0;
        }
        return predictions;
    }
};
```

### Alkalmazások

A logisztikus regressziót gyakran alkalmazzák a következő területeken:

1. **Orvosi diagnosztika**: Betegségek előrejelzése (pl. diabétesz, szívbetegségek).
2. **Pénzügyi szektor**: Hitelfelvétel jóváhagyásának előrejelzése, csalások észlelése.
3. **Marketing**: Vásárlók csoportosítása és viselkedésének előrejelzése.
4. **Szociológia**: Különböző társadalmi jelenségek modellezése és előrejelzése.

## Döntési fák (Decision Trees)

### Algoritmus és alkalmazások

A döntési fák olyan algoritmusok, amelyek szerkezetük miatt természetes úton modellezik a döntéshozási folyamatokat. A döntési fa egy hierarchikus felépítés, amely csomópontokból áll, ahol minden csomópont egy tesztet vagy kérdést képvisel, amelyet a betanulási adat pontokkal kapcsolatban helyeznek el.

### Algoritmus

A döntési fák algoritmusa többféle változatban és módszerrel kerülhet megvalósításra, azon belül is a legtöbb ismert az ID3, C4.5, CART és a C5.0.

#### Algoritmus lépései:

1. **Tesztesetek kiválasztása**: Válasszuk ki a legjobb kérdést vagy osztályozási feltételt az összes rendelkezésre álló teszt alapján. A tesztelő adatpontonként a lehetséges hasadások listáját vizsgáljuk, minden egyes változó különböző értékeivel összhangban.
2. **Információnyereség kiszámítása**: Számítsuk ki minden osztályozás előnyére vonatkozó információs nyereséget vagy más hasonló értéket. Az ID3 algoritmus döntési fánál például az entrópia csökkenése az információs nyereség.
3. **Legjobb hasadtat kiválasztás**: Válasszuk ki a legjobb osztályozás a teszt esetek és az információnyereségek alapján.
4. **Fa felépítése**: Ismételjük meg a folyamatot minden egyes, a teszt esetek alapján osztályozott részhalmazára, amíg minden részhalmaz homogén nem lesz (i.e., minden adatpont azonos osztályba tartozik) vagy elérünk egy megállító feltételhez (például bizonyos mélység).

Az alábbiakban egy egyszerű döntési fa algoritmus íródott le C++ nyelven:

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <algorithm>

struct Node {
    bool is_leaf;
    int feature_index{-1};
    double threshold{0.0};
    int class_label{0};
    Node* left{nullptr};
    Node* right{nullptr};

    Node(bool leaf = false) : is_leaf(leaf) {}
};

class DecisionTree {
public:
    DecisionTree(int max_depth) : max_depth(max_depth), root(nullptr) {}
    ~DecisionTree() { delete_tree(root); }

    void fit(const std::vector<std::vector<double>>& X, const std::vector<int>& y) {
        root = build_tree(X, y, 0);
    }

    int predict(const std::vector<double>& x) const {
        return predict_node(root, x);
    }

private:
    int max_depth;
    Node* root;

    Node* build_tree(const std::vector<std::vector<double>>& X, const std::vector<int>& y, int depth) {
        if (depth == max_depth || pure_class(y)) {
            return create_leaf(y);
        }

        int best_feature = 0;
        double best_threshold = 0.0;
        double best_gain = -1;
        for (int i = 0; i < X[0].size(); ++i) {
            std::vector<double> thresholds = find_thresholds(X, i);
            for (double threshold : thresholds) {
                double gain = information_gain(X, y, i, threshold);
                if (gain > best_gain) {
                    best_gain = gain;
                    best_feature = i;
                    best_threshold = threshold;
                }
            }
        }
        if (best_gain == -1) {
            return create_leaf(y);
        }

        auto [X_left, y_left, X_right, y_right] = split_data(X, y, best_feature, best_threshold);

        Node* node = new Node();
        node->feature_index = best_feature;
        node->threshold = best_threshold;
        node->left = build_tree(X_left, y_left, depth + 1);
        node->right = build_tree(X_right, y_right, depth + 1);
        return node;
    }

    bool pure_class(const std::vector<int>& y) const {
        return std::equal(y.begin() + 1, y.end(), y.begin());
    }

    Node* create_leaf(const std::vector<int>& y) const {
        Node* leaf = new Node(true);
        leaf->class_label = std::round(std::accumulate(y.begin(), y.end(), 0.0) / y.size());
        return leaf;
    }

    double entropy(const std::vector<int>& y) const {
        std::map<int, int> class_counts;
        for (int label : y) {
            class_counts[label]++;
        }
        double entropy = 0.0;
        for (const auto& pair : class_counts) {
            double p = double(pair.second) / y.size();
            entropy -= p * std::log2(p);
        }
        return entropy;
    }

    double information_gain(const std::vector<std::vector<double>>& X, const std::vector<int>& y, int feature, double threshold) const {
        std::vector<int> y_left, y_right;
        for (int i = 0; i < X.size(); ++i) {
            if (X[i][feature] <= threshold) {
                y_left.push_back(y[i]);
            } else {
                y_right.push_back(y[i]);
            }
        }
        double p_left = double(y_left.size()) / y.size();
        double p_right = 1.0 - p_left;
        return entropy(y) - (p_left * entropy(y_left) + p_right * entropy(y_right));
    }

    std::tuple<std::vector<std::vector<double>>, std::vector<int>, std::vector<std::vector<double>>, std::vector<int>>
    split_data(const std::vector<std::vector<double>>& X, const std::vector<int>& y, int feature, double threshold) const {
        std::vector<std::vector<double>> X_left, X_right;
        std::vector<int> y_left, y_right;
        for (int i = 0; i < X.size(); ++i) {
            if (X[i][feature] <= threshold) {
                X_left.push_back(X[i]);
                y_left.push_back(y[i]);
            } else {
                X_right.push_back(X[i]);
                y_right.push_back(y[i]);
            }
        }
        return {X_left, y_left, X_right, y_right};
    }

    int predict_node(Node* node, const std::vector<double>& x) const {
        if (node->is_leaf) {
            return node->class_label;
        }
        if (x[node->feature_index] <= node->threshold) {
            return predict_node(node->left, x);
        } else {
            return predict_node(node->right, x);
        }
    }

    std::vector<double> find_thresholds(const std::vector<std::vector<double>>& X, int feature) const {
        std::vector<double> unique_values;
        for (const auto& x : X) {
            unique_values.push_back(x[feature]);
        }
        std::sort(unique_values.begin(), unique_values.end());
        unique_values.erase(std::unique(unique_values.begin(), unique_values.end()), unique_values.end());
        return unique_values;
    }
  
    void delete_tree(Node* node) {
        if (node != nullptr) {
            delete_tree(node->left);
            delete_tree(node->right);
            delete node;
        }
    }
};
```

### Alkalmazások

A döntési fák széles körben alkalmazottak különböző területeken, beleértve:

1. **Orvostudomány**: Klinikai döntések támogatása, diagnosztikai eszközök.
2. **Pénzügy**: Hitelkártya csalások felderítése, hitelfelvételek jóváhagyásának megjósolása.
3. **Gyártás**: Kohort analízis, minőség ellenőrzés.
4. **Marketing**: Vásárlási preferenciák elemzése, szegmentálás.

## Neurális hálók (Neural Networks)

### Alapok, algoritmusok és alkalmazások

A neurális hálók az inspirációt az emberi agyból nyerik, és egy olyan gépi tanulási modell, amely összekapcsolja az egymásra épülő "neurális rétegeket". A mélytanulás (deep learning) a neurális hálók egy speciális típusa, amely nagy számú réteggel dolgozik.

### Alapok

A neurális hálózatok elemi egységei a neuronok. Minden neuron egy súlyozott összegzéssel rendelkezik, amelyhez hozzáadunk egy eltolást, majd alkalmazunk egy aktivációs függvényt. Az egyes neurális rétegek

### 3.2 Logisztikus regresszió

#### Bevezetés

A logisztikus regresszió az egyik legelterjedtebb és legfontosabb gépi tanulási algoritmus, különösen a bináris klaszterezési problémák esetében. Képes az egyedi megfigyelési pontokat két különböző kategóriába (osztályba) sorolni, amelyeket általában 0 és 1 jelöl. Jelentőségét elsősorban egyszerűsége, hatékonysága és interpretálhatósága adja.

#### Alapelvek

A logisztikus regresszió egy lineáris modellre épül, de a lineáris regresszióval ellentétben az eredményeket nem folyamatos skálán, hanem egy logit függvény segítségével a valószínűségi tartományban [0,1] leképezi.

A logit függvény meghatározása:
$$ \text{logit}(p) = \log\left(\frac{p}{1-p}\right) $$

ahol $p$ a bekövetkezési valószínűség. A logit függvény inverze a sigmoid függvény:
$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

A logisztikus regresszió predikciós egyenlete a következő lesz:
$$ p = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \ldots + \beta_n x_n)}} $$

ahol $\beta_i$-k a model paraméterei (koefficiensei), és $x_i$-k a független változók.

#### Algoritmus részletezése

A logisztikus regresszió jellemzően maximum likelihood becslési módszert használ a paraméterek optimalizálásához. Az alábbi lépéseken keresztül vezet az algoritmus:

1. **Adatok előkészítése**:
   - A bemeneti adatot normalizálni vagy standardizálni szükséges a hatékonyabb konvergencia érdekében.
   - Az adatot szét kell osztani tréning és teszt halmazokra az érvényesítési folyamat érdekében.

2. **Model komponensek meghatározása**:
   - Kezdeti paraméterek meghatározása, jellemzően 0 vagy kis véletlenszerű értékek.

3. **Likelihood funkció és hiba függvény definiálása**:
   - A log-likelihood funkció megadása:
     $$ \mathcal{L}(\beta) = \sum_{i=1}^{m} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right] $$
     ahol $y_i$ a tényleges kimeneti érték, $\hat{y}_i$ a becsült érték, és $m$ a megfigyelések száma.

4. **Optimalizáció**:
   - Az optimalizálásra jellemzően a gradient descent módszert használják.
   - A gradient descent algoritmus iteratív folyamat, amely a következő update szabályt követi:
     $$ \beta_j := \beta_j + \alpha \sum_{i=1}^{m} (y_i - \hat{y}_i)x_{ij} $$
     ahol $\alpha$ a tanulási ráta (learning rate), és $x_{ij}$ az $i$-edik minta $j$-dik jellemzője.

5. **Konvergencia és evaluáció**:
   - Az optimalizálási folyamat addig folytatódik, amíg a paraméterek változása minimális lesz, vagy amíg el nem éri a meghatározott iterációs számot.

#### Alkalmazások

A logisztikus regresszió széleskörűen alkalmazható, mivel egyszerű mégis erős eszköz különböző bináris klaszterezési problémák megoldására.

1. **Orvosi diagnózis**:
   - A logisztikus regresszió használható egy adott betegség előfordulási valószínűségének előrejelzésére az alapján, hogy egy beteg különböző tünetekkel rendelkezik.

2. **Pénzügyi előrejelzések**:
   - Kockázatértékelési modellekben, például egy adott ügyfél hitelkockázatának becslésében.

3. **Marketing elemzések**:
   - Például egy vásárló adott termékre való válaszának valószínűségét becsülve egy kampány során.

4. **Bűnmegelőzés és bűnügyi elemzések**:
   - Profilozás és rizikóbecslés a bűncselekmények előfordulási valószínűségének meghatározására.

#### Implementációs példa C++ nyelven

Az alábbi kód egy egyszerű logisztikus regresszió implementációját mutatja be C++ nyelven.

```cpp
#include <iostream>
#include <vector>
#include <cmath>

// Sigmoid function
double sigmoid(double z) {
    return 1.0 / (1.0 + std::exp(-z));
}

// Calculate logistic regression cost
double compute_cost(const std::vector<double>& y, const std::vector<double>& h) {
    double cost = 0;
    for (size_t i = 0; i < y.size(); ++i) {
        cost += -y[i] * std::log(h[i]) - (1 - y[i]) * std::log(1 - h[i]);
    }
    return cost / y.size();
}

// Logistic Regression using Gradient Descent
void logistic_regression(std::vector<std::vector<double>>& X, std::vector<double>& y, 
                         std::vector<double>& theta, double alpha, int iterations) {
    size_t m = y.size();
    size_t n = X[0].size();
    
    for (int iter = 0; iter < iterations; ++iter) {
        std::vector<double> h(m, 0);
        std::vector<double> gradient(n, 0);
        
        // Calculate hypothesis
        for (size_t i = 0; i < m; ++i) {
            double z = 0;
            for (size_t j = 0; j < n; ++j) {
                z += X[i][j] * theta[j];
            }
            h[i] = sigmoid(z);
        }
        
        // Compute Gradient
        for (size_t j = 0; j < n; ++j) {
            double sum_error = 0;
            for (size_t i = 0; i < m; ++i) {
                sum_error += (h[i] - y[i]) * X[i][j];
            }
            gradient[j] = sum_error / m;
        }
        
        // Update the coefficients
        for (size_t j = 0; j < n; ++j) {
            theta[j] -= alpha * gradient[j];
        }
        
        // Optional: Print cost for monitoring convergence
        if (iter % 100 == 0) {
            double cost = compute_cost(y, h);
            std::cout << "Iteration " << iter << ", Cost: " << cost << std::endl;
        }
    }
}

int main() {
    // Example usage of logistic_regression function.
    
    // Training data: X is 2D vector (m x n), y is 1D vector (m)
    std::vector<std::vector<double>> X = {
        {1, 50, 85},
        {1, 55, 83},
        {1, 45, 78},
        {1, 60, 90},
        {1, 65, 95},
        {1, 40, 70}
    };
    std::vector<double> y = {1, 1, 0, 1, 1, 0};
    
    // Initial coefficients
    std::vector<double> theta = {0, 0, 0};
    
    // Learning rate and iterations
    double alpha = 0.01;
    int iterations = 1000;
    
    logistic_regression(X, y, theta, alpha, iterations);
    
    // Output the coefficients
    std::cout << "Coefficients: ";
    for (double coeff : theta) {
        std::cout << coeff << " ";
    }
    std::cout << std::endl;
    
    return 0;
}
```

Ez a program egy egyszerű logisztikus regressziós modellt implikál, amelyhez a gradient descent módszert használja az iteratív paraméterfrissítésekhez.

#### Összegzés

A logisztikus regresszió rendkívül fontos eszköz a gépi tanulás területén, amely bináris vagy multinomiális klaszterezési problémák megoldására használható. A modell egyszerűsége, gyorsasága és könnyű interpretálhatósága miatt széleskörben alkalmazzák különböző iparágakban, az orvoslástól a pénzügyi szektorig. Az algoritmus pontos megértése és implementálása tehát alapvető fontosságú a gépi tanulási alkalmazások sikeréhez.

### 3. Gépi tanulási algoritmusok

#### Lineáris regresszió
##### Algoritmus és alkalmazások

**Bevezetés**

A lineáris regresszió az egyik leggyakrabban használt és legegyszerűbb gépi tanulási algoritmus, amely két változó közötti lineáris kapcsolatot modellez. A cél a prediktív modellek létrehozása, ahol előre meg tudjuk jósolni egy célváltozó (függő változó) értékét más változók (független változók) alapján.

**Algoritmus**

A lineáris regresszió egy egyszerű lineáris egyenletet használ a prediktív modell megalkotására:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n $$

Ahol:
- $y$ a célváltozó értéke
- $x_1, x_2, ..., x_n$ a független változók
- $\beta_0$ az egyenlet konstans tagja (intercept)
- $\beta_1, \beta_2, ..., \beta_n$ a független változókhoz tartozó együtthatók (slope)

**MSE (Mean Squared Error)**

A lineáris regresszió célja az együtthatók ($\beta_k$) optimalizálása úgy, hogy a predikciók hibája minimális legyen. Ehhez leggyakrabban a négyzetes hiba (Mean Squared Error, MSE) minimalizálása használatos:

$$ MSE = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}_i - y_i)^2 $$

Ahol:
- $m$ az adatpontok száma
- $\hat{y}_i$ a modell által prediktált érték
- $y_i$ a valódi érték

**Gradient Descent** 

Az együtthatók optimalizálására szokásos eljárás a gradiens csökkentés (Gradient Descent):

1. **Initialize** $\beta$ randomly
2. **Compute** the cost function $J(\beta)$ — typically using MSE
3. **Update** the parameters using:
$$ \beta_j := \beta_j - \alpha \frac{\partial J(\beta)}{\partial \beta_j} $$
   ahol $\alpha$ a tanulási ráta
4. **Repeat** steps 2-3 until convergence

**Példa kód C++ nyelven**

```cpp
#include <iostream>
#include <vector>
#include <cmath>

// Function to compute mean squared error
double computeMSE(const std::vector<double>& y, const std::vector<double>& y_pred) {
    double mse = 0;
    for (int i = 0; i < y.size(); ++i) {
        mse += pow(y_pred[i] - y[i], 2);
    }
    return mse / y.size();
}

// Function to perform gradient descent
void gradientDescent(std::vector<double>& x, std::vector<double>& y,
                     double& beta0, double& beta1, double alpha, int iterations) {
    int n = x.size();
    for (int i = 0; i < iterations; ++i) {
        double grad0 = 0.0;
        double grad1 = 0.0;
        for (int j = 0; j < n; ++j) {
            double pred = beta0 + beta1 * x[j];
            grad0 += pred - y[j];
            grad1 += (pred - y[j]) * x[j];
        }
        beta0 -= alpha * (grad0 / n);
        beta1 -= alpha * (grad1 / n);
    }
}

int main() {
    std::vector<double> x = {1, 2, 3, 4, 5};
    std::vector<double> y = {1, 3, 2, 5, 4};
    double beta0 = 0, beta1 = 0, alpha = 0.01;
    int iterations = 1000;

    gradientDescent(x, y, beta0, beta1, alpha, iterations);

    std::cout << "Optimized coefficients: beta0 = " << beta0 << ", beta1 = " << beta1 << std::endl;

    std::vector<double> y_pred;
    for (auto val : x) {
        double pred = beta0 + beta1 * val;
        y_pred.push_back(pred);
    }

    double mse = computeMSE(y, y_pred);
    std::cout << "Mean Squared Error: " << mse << std::endl;

    return 0;
}
```

**Alkalmazások**

A lineáris regresszió széles körben alkalmazható különböző területeken:

1. **Gazdaság:** Árfolyam előrejelzés, piaci trendek azonosítása.
2. **Egészségügy:** Betegségek előrejelzése különböző tényezők (például életkor, testtömeg-index) alapján.
3. **Szociológia:** Kutatások, pl. jövedelem és oktatás közötti összefüggés vizsgálata.

#### Logisztikus regresszió
##### Algoritmus és alkalmazások

**Bevezetés**

A logisztikus regresszió egy bináris osztályozási algoritmus, amely a célváltozót két kategóriába sorolja. Tipikus felhasználási területei közé tartozik például a betegség diagnosztizálása (igen / nem), vagy a vásárlói viselkedés előrejelzése (vásárol-e vagy nem).

**Algoritmus**

A logisztikus regresszió logit függvényét használja:

$$ \text{logit}(p) = \log\left(\frac{p}{1-p}\right) $$

Ahol $p$ az osztályvalószínűség:

$$ p = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n)}} $$

A logit függvény lehetővé teszi a lineáris egyenlet átformálását úgy, hogy a predikciós kimenetek a [0, 1] intervallumra esnek.

**Költségfüggvény**

A logisztikus regresszióhoz az ún. log-loss vagy cross-entropy loss költségfüggvényt használjuk:

$$ L(y, \hat{y}) = -\frac{1}{m} \sum_{i=1}^{m} [ y_i \log(\hat{y}_i) + (1-y_i) \log(1 - \hat{y}_i) ] $$

**Gradient Descent**

Az együtthatók optimalizálására itt is a gradiens csökkentés (Gradient Descent) technikát alkalmazhatjuk.

**Alkalmazások**

A logisztikus regresszió széles körben elterjedt, többek között a következő területeken:

1. **Orvosi diagnózis:** Betegségek kockázatának előrejelzése.
2. **Pénzügy:** Csalás felderítése hitelkártya-tranzakciók során.
3. **Marketing:** Vásárlói viselkedés elemzése és előrejelzése.

#### Döntési fák (Decision Trees)
##### Algoritmus és alkalmazások

**Bevezetés**

A döntési fák egy fa szerkezetű modell, amely iteratívan választja szét az adatot egy célváltozó alapján. A modell különböző döntési útvonalakat tartalmaz, amelyek elágazási kérdések és azok válaszai alapján vezetnek a végső döntésekhez vagy osztályozásokhoz.

**Algoritmus**

1. **Építés:** Az adatkészlet szétválasztása az előre meghatározott kritériumok alapján (pl. Gini index, információs nyereség).
2. **Szegmentálás:** A legjobban szétválasztó változó kiválasztása.
3. **Levelek:** Az ismétlést addig folytatjuk, amíg a levelek tiszták, azaz egyetlen osztályt képviselnek.

**Tisztasági Mérőszámok**

- **Gini Index:**
$$ Gini(D) = 1 - \sum_{i=1}^{c} p_i^2 $$

- **Entropy (Információs nyereség):**
$$ Entropy(D) = - \sum_{i=1}^{c} p_i \log(p_i) $$

**CART (Classification and Regression Tree)**

A CART algoritmus általában Gini indexet használ, és a kialakult fa alapján valósítja meg a predikciókat.

**Alkalmazások**

A döntési fák alkalmazási lehetőségei szerteágazóak:

1. **Orvosi döntéshozatal:** Diagnózis és kezelési utak modellezése.
2. **Kockázatkezelés:** Kockázatbecslés például hitelkérelmek esetén.
3. **Marketing előrejelzések:** Ügyfél szegmentáció és célzott marketing kampányok.

#### Neurális hálók (Neural Networks)
##### Alapok, algoritmusok és alkalmazások

**Bevezetés**

A neurális hálók az emberi agy idegsejtjeit utánzó, összetett algoritmusok, amelyek rendkívül hatékonyak a nagy mennyiségű és bonyolult adatok kezelésében. A neurális hálók felépítése rétegekre oszlik, amelyeken keresztül az információ feldolgozása iteratív módon történik.

**Alapok**

1. **Bemeneti réteg:** Az adatokat fogadja be.
2. **Rejtett rétegek:** Az adatok transzformálása és feldolgozása.
3. **Kimeneti réteg:** A predikciós eredmények előállítása.

**Aktivációs Függvények**

A különböző rétegek közötti kapcsolatokat aktivációs függvények szabályozzák, például:
- **Sigmoid:** $$ \sigma(x) = \frac{1}{1 + e^{-x}} $$
- **ReLU (Rectified Linear Unit):** $$ \text{ReLU}(x) = \max(0, x) $$

**Veszteségfüggvény és Optimalizálás**

A hálózat célja a veszteség (loss) minimalizálása, gyakran használt függvények között van a kereszt-entrópia, illetve a négyzetes hiba. Az optimalizáláshoz leggyakrabban a gradienscsökkentés különböző változatai használatosak (pl. stochastic gradient descent, Adam).

**Példa kód C++ nyelven (egyszerű neurális háló)**

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <cstdlib>

double sigmoid(double x) {
    return 1 / (1 + exp(-x));
}

class NeuralNetwork {
public:
    NeuralNetwork(int inputSize, int hiddenSize, int outputSize);
    std::vector<double> feedforward(const std::vector<double>& input);
    void train(const std::vector<std::vector<double>>& data, const std::vector<std::vector<double>>& labels,
               int epochs, double learningRate);

private:
    std::vector<double> weightsIH; // weights between input and hidden
    std::vector<double> weightsHO; // weights between hidden and output
    std::vector<double> hiddenLayer;
    std::vector<double> outputLayer;

    double learningRate;
};

NeuralNetwork::NeuralNetwork(int inputSize, int hiddenSize, int outputSize) {
    weightsIH.resize(inputSize * hiddenSize);
    weightsHO.resize(hiddenSize * outputSize);
    hiddenLayer.resize(hiddenSize);
    outputLayer.resize(outputSize);

    // Initialize weights randomly
    for (double &weight : weightsIH) {
        weight = (static_cast<double>(rand()) / RAND_MAX) * 2 - 1;
    }
    for (double &weight : weightsHO) {
        weight = (static_cast<double>(rand()) / RAND_MAX) * 2 - 1;
    }
}

std::vector<double> NeuralNetwork::feedforward(const std::vector<double>& input) {
    // Input to Hidden
    for (int i = 0; i < hiddenLayer.size(); ++i) {
        double sum = 0.0;
        for (int j = 0; j < input.size(); ++j) {
            sum += input[j] * weightsIH[j * hiddenLayer.size() + i];
        }
        hiddenLayer[i] = sigmoid(sum);
    }

    // Hidden to Output
    for (int i = 0; i < outputLayer.size(); ++i) {
        double sum = 0.0;
        for (int j = 0; j < hiddenLayer.size(); ++j) {
            sum += hiddenLayer[j] * weightsHO[j * outputLayer.size() + i];
        }
        outputLayer[i] = sigmoid(sum);
    }

    return outputLayer;
}

void NeuralNetwork::train(const std::vector<std::vector<double>>& data, const std::vector<std::vector<double>>& labels,
           int epochs, double learningRate) {
   this->learningRate = learningRate;
   // Training process would be implemented here
   // This is a simplified example, full implementation would include backpropagation steps
}

int main() {
    NeuralNetwork nn(3, 3, 1);

    std::vector<std::vector<double>> data = {
        {0, 0, 1},
        {1, 1, 1},
        {1, 0, 1},
        {0, 1, 1},
    };
    std::vector<std::vector<double>> labels = {
        {0}, {1}, {1}, {0}
    };

    nn.train(data, labels, 10000, 0.1);

    for (const auto &input : data) {
        std::vector<double> output = nn.feedforward(input);
        std::cout << "Output: " << output[0] << std::endl;
    }

    return 0;
}
```

**Alkalmazások**

A neurális hálók elképesztően sokrétűen alkalmazhatók:

1. **Képfelismerés:** Object detection, facial recognition.
2. **Természetes nyelv feldolgozása:** Szövegfordítás, chatbotok.
3. **Játék:** Stratégiai döntések meghozatala, például AlphaGo.

Mindegyik gépi tanulási algoritmus különböző előnyökkel és hátrányokkal rendelkezik, és az alkalmazási kontextushoz és adatkonstrukcióhoz legjobban illeszthetők kiválasztása kritikus a sikeres gépi tanulási projekt számára.

### 3. Gépi tanulási algoritmusok

#### 3.3 Döntési fák (Decision Trees)

Döntési fák egyike a leggyakrabban használt és legérthetőbb gépi tanulási algoritmusoknak. Egyszerűségük és egyben intuíció miatt széles körben alkalmazzák őket különféle klaszterezési és regressziós feladatokban. Ebben az alfejezetben mélyrehatóan bemutatjuk a döntési fák működését, algoritmusát és alkalmazási területeit.

##### 3.3.1 Bevezetés a Döntési Fákba

A döntési fa egy fa-struktúrán alapuló modell, ahol minden belső csomópont egy attribútumot reprezentál, minden ág egy döntési szabályt, és minden levélcsomópont egy kimenetet (címkét). A döntési fákat két fő feladatkörben használják:

1. **Klaszterezés (Classification)**: Ahol a cél az, hogy egy elemet egy előre meghatározott osztályba soroljunk.
2. **Regresszió (Regression)**: Ahol a cél egy folytonos kimeneti érték becslése.

##### 3.3.2 Algoritmus

A döntési fa algoritmus lépései a következők:

1. **Feltételes Felosztás**: Kiválasztjuk a legjobb attribútumot, amely a leghatékonyabban osztja fel az adatokat különböző csoportokba. Ezt gyakran különféle mérőszámokkal végzik, mint például az információnyereség (Information Gain) vagy Gini-index.

2. **Rekurzív Felosztás**: Az adatokat az előző lépésben választott attribútum alapján két vagy több alcsoportra osztjuk, mindegyik alcsoportra külön-külön alkalmazva ugyanezt a folyamatot.

3. **Levélcsomópont Képzése**: Az adatbázisban már nem lehet további hasznos felosztásokat végezni, vagy elértük a kívánt fa mélységet, akkor egy "levél" keletkezik, amely meghatározza az eredeti adatcsoport kimeneti értékét vagy osztályát.

4. **Pruning (Metszés)**: A fákat gyakran túltanítják az adatbázisra, ami miatt rosszul általánosítanak új adatokra. Ezt a problémát úgynevezett "pruning" technikákkal orvosolják, amelyek csökkentik a fa méretét és egyszerűsítik a modellt.

Az algoritmus egyszerűsége ellenére bizonyos technikai részletek külön figyelmet érdemelnek, mint például a megfelelő felosztási kritérium választása és a fa méretének optimalizálása.

##### 3.3.3 Felosztási Kritériumok

1. **Információnyereség (Information Gain)**: Az információelméletből származó mérőszám, amely a rendszer entrópiájának csökkentésén alapul. A felosztás, amely a legnagyobb információnyereséget eredményezi, lesz kiválasztva.
   
2. **Gini-index**: A Gini-index egy másik felosztási kritérium, amely a halmaz heterogenitását méri. A felosztás, amely a legalacsonyabb Gini-indexet eredményezi, lesz kiválasztva.

3. **Chi-squared**: A Chi-négyzet tesztet gyakran használják diszkrét adatok esetében, hogy a felosztások statisztikai szignifikanciáját meghatározzák.

##### 3.3.4 Döntési Fák Metszése

A fák méretének korlátozása nélkül az algoritmus hajlamos túlzottan alkalmazkodni a tanulási adatokhoz, ami a túltanulás jól ismert problémáját okozza. A metszési technikák két fő típusra oszthatók:

1. **Előmetszés (Pre-pruning)**: A fát még a növekedés közben megállítják, amikor bizonyos feltételek teljesülnek, például ha egy minimális csomópontméretet nem érünk el, vagy ha az információnyereség nem halad meg egy bizonyos küszöbértéket.

2. **Utómetszés (Post-pruning)**: A fát teljesen megnövesztik, majd visszametszik a nem hasznos csomópontokat valamilyen validációs kritérium alapján.

##### 3.3.5 Algoritmus Implementálása C++ Nyelven

Mielőtt mélyebb matematikai elemzésbe mennénk, nézzünk egy alapvető implementációt C++ nyelven.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <limits>
#include <algorithm>

// Define a structure for tree nodes
struct TreeNode {
    double value;
    int feature;
    TreeNode* left;
    TreeNode* right;

    TreeNode(double val) : value(val), feature(-1), left(nullptr), right(nullptr) {}
};

class DecisionTree {
public:
    TreeNode* root;

    DecisionTree() : root(nullptr) {}

    // Function to train the decision tree
    void train(const std::vector<std::vector<double>>& data, const std::vector<double>& labels) {
        root = buildTree(data, labels);
    }

private:
    // Function to build the decision tree recursively
    TreeNode* buildTree(const std::vector<std::vector<double>>& data, const std::vector<double>& labels) {
        if (data.empty()) return nullptr;

        int bestFeature = -1;
        double bestThreshold = std::numeric_limits<double>::max();
        double bestGini = std::numeric_limits<double>::max();
        std::vector<std::vector<double>> leftData, rightData;
        std::vector<double> leftLabels, rightLabels;

        // Choose the best feature to split on
        for (size_t feature = 0; feature < data[0].size(); ++feature) {
            for (size_t i = 0; i < data.size(); ++i) {
                double threshold = data[i][feature];
                auto [lData, lLabels, rData, rLabels] = splitData(data, labels, feature, threshold);

                double gini = computeGini(lLabels) * lData.size() + computeGini(rLabels) * rData.size();
                if (gini < bestGini) {
                    bestGini = gini;
                    bestFeature = feature;
                    bestThreshold = threshold;
                    leftData = lData;
                    leftLabels = lLabels;
                    rightData = rData;
                    rightLabels = rLabels;
                }
            }
        }

        if (bestFeature == -1) {
            return new TreeNode(computeMean(labels));
        }

        TreeNode *node = new TreeNode(bestThreshold);
        node->feature = bestFeature;
        node->left = buildTree(leftData, leftLabels);
        node->right = buildTree(rightData, rightLabels);
        return node;
    }

    // Function to split data based on a feature and threshold
    std::tuple<std::vector<std::vector<double>>, std::vector<double>, std::vector<std::vector<double>>, std::vector<double>>
    splitData(const std::vector<std::vector<double>>& data, const std::vector<double>& labels, int feature, double threshold) {
        std::vector<std::vector<double>> leftData, rightData;
        std::vector<double> leftLabels, rightLabels;
        for (size_t i = 0; i < data.size(); ++i) {
            if (data[i][feature] <= threshold) {
                leftData.push_back(data[i]);
                leftLabels.push_back(labels[i]);
            } else {
                rightData.push_back(data[i]);
                rightLabels.push_back(labels[i]);
            }
        }
        return {leftData, leftLabels, rightData, rightLabels};
    }

    // Function to compute Gini impurity
    double computeGini(const std::vector<double>& labels) {
        if (labels.empty()) return 0.0;
        double count0 = std::count(labels.begin(), labels.end(), 0.0);
        double p0 = count0 / labels.size();
        return 1 - p0 * p0 - (1 - p0) * (1 - p0);
    }

    // Function to compute mean of labels for leaf nodes
    double computeMean(const std::vector<double>& labels) {
        double sum = std::accumulate(labels.begin(), labels.end(), 0.0);
        return sum / labels.size();
    }
};

int main() {
    std::vector<std::vector<double>> data = {{2.7, 2.5}, {1.4, 2.3}, {3.3, 4.4}, {1.3, 1.8}, {3.0, 3.3}, {7.6, 2.8}};
    std::vector<double> labels = {0, 0, 1, 0, 1, 1};

    DecisionTree dt;
    dt.train(data, labels);

    std::cout << "Decision Tree trained successfully!" << std::endl;
    return 0;
}
```

##### 3.3.6 Alkalmazások

Döntési fák széles körben alkalmazhatók különböző területeken:

1. **Orvosi Diagnózis**: A döntési fákat gyakran használják orvosi diagnózisban különböző betegségek azonosításához.
   
2. **Pénzügyi Elemzések**: A pénzügyi szektorban a döntési fákat a kockázatkezelés, a hitelképesség elemzése és a csalás detektálása során alkalmazzák.
   
3. **Marketing**: Az ügyfelek szegmentálására, viselkedésük előrejelzésére és célzott hirdetések megtervezésére.

##### 3.3.7 Előnyei és Hátrányai

**Előnyök**:
1. Könnyen érthető és értelmezhető.
2. Alkalmazható kategóriabeli és folytonos adatokra is.
3. Nem igényel bonyolult adatelőkészítést.

**Hátrányok**:
1. Hajlamos a túltanulásra.
2. Nem mindig hozza a legjobb általánosító teljesítményt.
3. Érzékeny az adatminták zajára és változékonyságára.

Összegzésként a döntési fák jól érthető és erőteljes eszközök mind a klaszterezésben, mind a regresszióban, de használatuk során fontos figyelembe venni a specifikus alkalmazási igényeket és az esetleges korlátokat.

##### 3.3.8 További Fejlesztések és Változatok

Az alapvető döntési fa modell számos kiterjesztése és változata létezik, amelyek javítják a teljesítményt és csökkentik a túltanulás esélyét:

1. **Random Forests**: Több döntési fa együttes használata a modell robusztusságának és pontosságának növelése érdekében.
2. **Boosted Trees**: Olyan módszerek, mint az AdaBoost vagy a Gradient Boosting, amelyek folyamatosan javítják a gyenge tanulókat.
3. **Extremely Randomized Trees**: Faépítési folyamat során több véletlenszerűséget vezettek be a homogenitás javítása érdekében.

Ezek a modern fejlesztések tovább növelik a döntési fák alkalmazási területeinek széles spektrumát a gépi tanulás különféle problémáiban.

### 3. Gépi tanulási algoritmusok

#### Lineáris regresszió
##### Algoritmus és alkalmazások

**Elméleti háttér**
A lineáris regresszió egy alapvető statisztikai módszer, amely arra szolgál, hogy kvantitatív kapcsolatot modellezzünk a független (input) és a függő (output) változók között. Az algoritmus egy lineáris egyenlet segítségével írja le ezt a kapcsolatot: $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon$, ahol $y$ a prediktált változó, $\beta_i$ a regressziós együtthatók, $x_i$ pedig a független változók, $\epsilon$ pedig a hibatag.

**Algoritmus**
1. **Célfüggvény meghatározása**: A lineáris regresszió célja, hogy minimalizálja a hibát a prediktált értékek és a valós célértékek között. Tipikusan a négyzetes hibák összegét (Mean Squared Error, MSE) használják célfüggvényként:
   $$
   MSE = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y_i})^2
   $$
2. **Paraméterbecslés**: A legkisebb négyzetek módszerével becsüljük meg az $\beta$ paramétereket:
   $$
   \boldsymbol{\beta} = (X^T X)^{-1} X^T \mathbf{y}
   $$
   ahol $X$ a bemeneti mátrix, amely tartalmazza a független változókat, és $\mathbf{y}$ a célváltozót tartalmazó vektor.

**Implementáció (C++)**

```cpp
#include <iostream>
#include <vector>
#include <Eigen/Dense> // Eigen könyvtár a mátrixműveletekhez

using namespace Eigen;

// Függvény a lineáris regresszió paramétereinek becslésére
VectorXd linearRegression(const MatrixXd &X, const VectorXd &y) {
    VectorXd beta = (X.transpose() * X).inverse() * X.transpose() * y;
    return beta;
}

int main() {
    MatrixXd X(5, 3); // Példa input mátrix (5 minta, 3 független változó)
    VectorXd y(5); // Célváltozó

    // Bemeneti adatok inicializálása
    X << 1, 1, 1,
         1, 2, 2,
         1, 3, 3,
         1, 4, 4,
         1, 5, 5;
    y << 1, 2, 3, 4, 5;

    // Lineáris regresszió futtatása
    VectorXd beta = linearRegression(X, y);

    std::cout << "Becslés: " << beta.transpose() << std::endl;

    return 0;
}
```

**Alkalmazások**
- **Gazdasági előrejelzések**: A lineáris regresszió az egyik leggyakrabban használt módszer gazdasági és pénzügyi adatok előrejelzésére.
- **Egészségügyi analitika**: Biomedicinában, például a betegségek előfordulásának előrejelzése változó tényezők alapján.
- **Szociális tanulmányok**: Demográfiai és szociális kutatásoknál a társadalmi trendek elemzése.

#### Logisztikus regresszió
##### Algoritmus és alkalmazások

**Elméleti háttér**
A logisztikus regresszió egy széleskörben alkalmazott statisztikai módszer, amely incidenst (kategóriát) prediktál. A logisztikus regresszió kimenete $0$ és $1$ közötti értéket ad vissza, és általában kategóriák valószínűségét modellezi. A logisztikus függvény (szigmoid függvény) jellemzi:
   $$
   \sigma(z) = \frac{1}{1 + e^{-z}}
   $$
   ahol $z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n$.

**Algoritmus**
1. **Logisztikus függvény használata**: A predikciókat a szigmoid függvény segítségével számítjuk ki.
2. **Keretrendszer kialakítása**: A maximális valószínűség (Maximum Likelihood Estimation, MLE) módszer használata a paraméterek becslésére.
3. **Gradiens lejtő optimalizálás**: A paraméterek optimalizálása egy iteratív megközelítéssel, mint például a Gradiens Descent (GD).

**Implementáció (C++)**

```cpp
#include <iostream>
#include <vector>
#include <Eigen/Dense>
#include <cmath>

using namespace Eigen;

// Sigmoid függvény definíciója
double sigmoid(double z) {
    return 1.0 / (1.0 + exp(-z));
}

// Függvény a logisztikus regresszió futtatására
VectorXd logisticRegression(const MatrixXd &X, const VectorXd &y, double alpha, int iterations) {
    int m = X.rows();
    int n = X.cols();
    VectorXd beta = VectorXd::Zero(n); // Paraméterek inicializálása

    for (int i = 0; i < iterations; ++i) {
        VectorXd z = X * beta;
        VectorXd predictions = z.unaryExpr(ptr_fun(sigmoid));

        VectorXd errors = y - predictions;
        beta += alpha * (X.transpose() * errors) / m;
    }
    return beta;
}

int main() {
    MatrixXd X(5, 3);
    VectorXd y(5);

    X << 1, 1, 1,
         1, 2, 2,
         1, 3, 3,
         1, 4, 4,
         1, 5, 5;
    y << 0, 0, 1, 1, 1;

    double learningRate = 0.01;
    int iterations = 1000;

    VectorXd beta = logisticRegression(X, y, learningRate, iterations);

    std::cout << "Becslés: " << beta.transpose() << std::endl;

    return 0;
}
```

**Alkalmazások**
- **Orvosi diagnózis**: Betegségek valószínűségének előrejelzése.
- **Pénzügyi kockázatelemzés**: Az ügyfél kockázati profiljának megállapítása.
- **Marketing elemzések**: Vásárlói viselkedés elemzése és kampányok hatékonyságának mérése.

#### Döntési fák (Decision Trees)
##### Algoritmus és alkalmazások

**Elméleti háttér**
A döntési fák döntési szabályokat (szeparátorokat) használnak, amik egy sor feltételes állításon alapulnak. A fák gyökérből, csomópontokból és levelekből állnak. A döntési fatanulás algoritmusai közé tartozik a CART (Classification and Regression Trees), ID3, C4.5 stb.

**Algoritmus**
1. **Ad véletlenszerű osztályozási kritériumokat**: Mint például az Entropia vagy Gini impurity.
2. **Rekurzív szeparálás**: Az adatbázis iteratív bontása a különböző csomópontokban a minimális impuritás értékre.
3. **Falevelek kiértékelése**: A végső osztályozási vagy regressziós értékek kiértékelése céljából.

**Implementáció (C++)**

```cpp
#include <iostream>
#include <vector>
#include <limits>

using namespace std;

// Döntési fa csomópont struktúra.
struct Node {
    bool isLeaf;
    double threshold;
    int featureIndex;
    double value;
    Node* left;
    Node* right;
    
    Node(double val) : isLeaf(true), value(val), left(nullptr), right(nullptr) {}
    Node(int feature, double threshold) : isLeaf(false), featureIndex(feature), threshold(threshold), left(nullptr), right(nullptr) {}
};

// Információveszteség kiszámítása.
double giniImpurity(const vector<int>& labels) {
    double count0 = 0;
    double count1 = 0;
    
    for (int label : labels) {
        if (label == 0) ++count0;
        else ++count1;
    }
    
    double total = count0 + count1;
    if (total == 0) return 0.0;
    
    double p0 = count0 / total;
    double p1 = count1 / total;
    
    return 1.0 - p0 * p0 - p1 * p1;
}

// Döntési fa építés.
Node* buildTree(const vector<vector<double>>& data, const vector<int>& labels) {
    // Alapfeltételek
    if (labels.empty()) return nullptr;
    if (giniImpurity(labels) == 0) return new Node(labels[0]);
    
    double minGini = numeric_limits<double>::max();
    int bestFeature = -1;
    double bestThreshold = 0.0;
    
    for (int feature = 0; feature < data[0].size(); ++feature) {
        for (const auto& instance : data) {
            double threshold = instance[feature];
            
            vector<int> leftLabels;
            vector<int> rightLabels;
            
            for (int i = 0; i < data.size(); ++i) {
                if (data[i][feature] < threshold) leftLabels.push_back(labels[i]);
                else rightLabels.push_back(labels[i]);
            }
            
            double gini = (leftLabels.size() * giniImpurity(leftLabels) + rightLabels.size() * giniImpurity(rightLabels)) / data.size();
            
            if (gini < minGini) {
                minGini = gini;
                bestFeature = feature;
                bestThreshold = threshold;
            }
        }
    }
    
    // Legjobb elágazás szerint tovább bontjuk az adatokat.
    Node* node = new Node(bestFeature, bestThreshold);
    
    vector<vector<double>> leftData;
    vector<int> leftLabels;
    
    vector<vector<double>> rightData;
    vector<int> rightLabels;
    
    for (int i = 0; i < data.size(); ++i) {
        if (data[i][bestFeature] < bestThreshold) {
            leftData.push_back(data[i]);
            leftLabels.push_back(labels[i]);
        } else {
            rightData.push_back(data[i]);
            rightLabels.push_back(labels[i]);
        }
    }
    
    node->left = buildTree(leftData, leftLabels);
    node->right = buildTree(rightData, rightLabels);
    
    return node;
}

int main() {
    vector<vector<double>> data = {
        {2.771244718, 1.784783929},
        {1.728571309, 1.169761413},
        {3.678319846, 2.81281357},
        {3.961043357, 2.61995032},
        {2.999208922, 2.209014212},
        {7.497545867, 3.162953546},
        {9.00220326, 3.339047188},
        {7.444542326, 0.476683375},
        {10.12493903, 3.234550982},
        {6.642287351, 3.319983761}
    };
    
    vector<int> labels = {0, 0, 0, 0, 0, 1, 1, 1, 1, 1};
    
    Node* tree = buildTree(data, labels);
    
    cout << "Döntési fa építése kész." << endl;
    
    // A fa további működése és vizualizálása opcionális.
    return 0;
}
```

**Alkalmazások**
- **Műszaki diagnosztika**: Hibák előrejelzése és ellenőrzése gépi rendszerekben.
- **Pénzügyi szektor**: Adathitel besorolása, csalásfelderítés.
- **Egészségügyi szektor**: Diagnosztikai és kezelési döntések segítése.

#### Neurális hálók (Neural Networks)
##### Alapok, algoritmusok és alkalmazások

**Elméleti háttér**
A neurális hálók biológiai neuronok mintájára épülnek, és több réteg neuronnal működnek. Az alapvető egység egy neuron, amely egy vagy több bemeneti értéket fogad, súlyozza ezeket, és egy aktivációs függvény segítségével kiszámít egy kimeneti értéket.

**Algoritmus**
1. **Adat előkészítése**: Az adatok normalizációja és előfeldolgozása.
2. **Hálózat különböző rétegeinek összeállítása**: Input réteg, rejtett rétegek és output réteg.
3. **Súlyok inicializálása**: Random vagy He/Glorot módszerek használatával.
4. **Továbbítási (Forward Propagation) fázis**: Az adat továbbítása a hálón keresztül a predikció érdekében.
5. **Visszaterjesztési (Backpropagation) fázis**: Hibakiszámítás és az algoritmus súlyainak frissítése.

**Implementáció (C++)**

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <algorithm>

using namespace std;

// Sigmoid aktivációs függvény és derivált
double sigmoid(double z) {
    return 1.0 / (1.0 + exp(-z));
}

double sigmoidPrime(double z) {
    return sigmoid(z) * (1.0 - sigmoid(z));
}

// Súlyok inicializálása
vector<double> initializeWeights(int size) {
    vector<double> weights(size);
    generate(weights.begin(), weights.end(), []() { return ((double) rand() / RAND_MAX) * 2 - 1; });
    return weights;
}

// Neurális háló osztálya
class NeuralNetwork {
private:
    vector<int> layers;
    vector<vector<vector<double>>> weights;
    vector<vector<double>> biases;
    
public:
    NeuralNetwork(const vector<int>& layers) : layers(layers) {
        for (int i = 1; i < layers.size(); ++i) {
            weights.push_back(vector<vector<double>>(layers[i], initializeWeights(layers[i-1])));
            biases.push_back(vector<double>(layers[i], 0.5)); // Alaphelyzetben összes biaya 0.5
        }
    }
    
    void forward(const vector<double>& input, vector<double>& output) {
        vector<vector<double>> activations = {input};
        vector<vector<double>> zs;
        
        for (int layer = 1; layer < layers.size(); ++layer) {
            vector<double> z(layers[layer]);
            for (int j = 0; j < layers[layer]; ++j) {
                z[j] = biases[layer-1][j];
                for (int k = 0; k < layers[layer-1]; ++k) {
                    z[j] += activations[layer-1][k] * weights[layer-1][j][k];
                }
            }
            
            zs.push_back(z);
            activations.push_back(vector<double>(layers[layer]));
            transform(z.begin(), z.end(), activations.back().begin(), sigmoid);
        }
        
        output = activations.back();
    }
};

int main() {
    vector<int> layers = {2, 3, 1}; // Példa rétegstruktúra: 2 bemenet, 3 rejtett neurális, 1 kimenet
    NeuralNetwork nn(layers);
    
    vector<double> input = {0.5, 0.8};
    vector<double> output;
    
    nn.forward(input, output);
    
    for (double val : output) {
        cout << "Kimenet: " << val << endl;
    }
    
    return 0;
}
```

**Alkalmazások**
- **Kép- és hangfelismerés**: Számítógép segítségével látni és hallani.
- **Szövegfeldolgozás**: Természetes nyelvi feldolgozás, chatbotok.
- **Önvezető autók**: Szenzoros adatokból való tanulás és döntés.

### Összegzés
Az ebben a fejezetben tárgyalt gépi tanulási algoritmusok a modern adatanalitikai és mesterséges intelligencia területének alapkövei. Mindegyik algoritmusnak megvan a maga előnye és hátránya, és a választott algoritmus nagymértékben függ a konkrét alkalmazástól és problémától. Az algoritmusok megértése és helyes alkalmazása kritikus fontosságú a hatékony és pontos modellezéshez.

### 3.4 Neurális hálók (Neural Networks)

A neurális hálók (neural networks) az utóbbi években hihetetlen népszerűségre tettek szert a gépi tanulás és adatbányászat területén. Az alkalmazási területek széles skálája — a képfelismeréstől kezdve a természetes nyelvfeldolgozáson át az autonóm járművek irányításáig — mutatja, hogy ezek az algoritmusok milyen sokoldalúak és hatékonyak lehetnek. Ebben a fejezetben részletesen megvizsgáljuk a neurális hálók alapjait, működését, különböző architektúrákat, tanulási algoritmusokat és jellemző alkalmazásokat.

#### 3.4.1 A Neurális Háló Alapjai

A neurális hálók az emberi agy neuronjain alapulnak, és hasonlóan működnek szinapszisok hálózatán keresztül. Egy mesterséges neuron, más néven perceptron, több bemeneti értéket fogad, ezek súlyozott összegét kiszámítja, és egy aktivációs függvény segítségével állítja elő a kimeneti értéket.

##### Mesterséges Neuron
Egy egyszerű mesterséges neuron formalizálható a következőképpen:

$$ z = w_1 \cdot x_1 + w_2 \cdot x_2 + \dots + w_n \cdot x_n + b $$
$$ a = \phi(z) $$

ahol:
- $x_i$ az $i$-edik bemenet,
- $w_i$ az $i$-edik súly,
- $b$ a bias (elfogultság),
- $z$ a súlyozott bemenetek összege,
- $\phi$ az aktivációs függvény,
- $a$ az aktivációs függvény kimenete.

##### Aktivációs Függvények
Az aktivációs függvények kritikus szerepet játszanak a neurális hálókban, mivel ezek teszik lehetővé a hálózat számára a nemlineáris problémák megoldását. Néhány elterjedt aktivációs függvény:

1. **Szignoid (Sigmoid) függvény**
   $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

2. **Hiperbolikus tangens (Tanh) függvény**
   $$ \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} $$

3. **ReLU (Rectified Linear Unit) függvény**
   $$ \text{ReLU}(z) = \max(0, z) $$

4. **Leaky ReLU függvény**
   $$ \text{Leaky ReLU}(z) = \max(0.01z, z) $$

#### 3.4.2 Hálózati Architektúrák

A neurális hálók különböző architektúrái az inputot különböző lépéseken keresztül alakítják át, és ezek különböző típusú problémák megoldására alkalmasak.

##### I. Perceptron Hálók
A perceptron egyszerű előhívású hálózat, amely egy neuront tartalmaz. Ez a hálózat lineárisan osztályozható problémák megoldására képes.

##### II. Többrétegű Perceptron (MLP)
Az MLP több rétegből áll, ezek közül legalább egy rejtett réteg. Egy tipikus MLP három rétegből áll:
1. **Bemeneti réteg:** ahol az adatok belépnek a hálózatba.
2. **Rejtett réteg(ek):** ahol a súlyok és aktivációs függvények segítségével történik az adatok feldolgozása.
3. **Kimeneti réteg:** ahol a végső osztályozás vagy predikció történik.

##### III. Konvolúciós Neurális Hálók (CNN)
A CNN-ek különösen jól alkalmazhatók képfeldolgozási feladatokhoz. Az alapelemük a konvolúciós réteg, amely szűrőket alkalmaz a bemeneti képeken, felfedve a képen található mintázatokat. A CNN-ek további fontos elemei a pooling rétegek és a teljesen összekapcsolt (fully connected) rétegek.

##### IV. Rekurrens Neurális Hálók (RNN)
Az RNN-ek olyan hálózatok, amelyek kifejezetten sorozatos adatok feldolgozására alkalmasak. Az RNN-ek rendelkeznek memóriával, amely lehetővé teszi a hálónak, hogy figyelembe vegye a korábbi inputokat. Különleges változatuk az LSTM (Long Short-Term Memory) és a GRU (Gated Recurrent Unit), amelyek képesek hosszabb távú függőségek megtanulására is.

#### 3.4.3 Tanulási Algoritmusok

A neurális hálók tanulása alapvetően súlyfrissítéssel történik egy „háromlépéses” folyamat során: előrehívás (forward pass), visszafrissítés (backpropagation) és optimalizálás.

##### I. Előrehívás (Forward Pass)
Ebben a lépésben a bemeneti adatot végighaladják a hálózaton, minden réteg végzi a maga részét a bemenetek transzformálásában.

##### II. Visszafrissítés (Backpropagation)
A visszafrissítés során az elkövetett hibát visszavezetjük a hálózatban és kiszámítjuk a gradiens értékeit minden egyes súlyra vonatkozóan. Az alapötlet, hogy minimalizáljuk a hiba függvényt a gradiens csökkenési eljárással (Gradient Descent).

##### III. Gradiensek Optimalizálása
A hálózat súlyait frissítjük a gradiens csökkenési eljárás segítségével. Számos optimalizálási módszer létezik:
- **Stochastic Gradient Descent (SGD)**
- **Adam (Adaptive Moment Estimation)**
- **RMSprop (Root Mean Square Propagation)**

#### 3.4.4 Implementáció és Példák

A neurális hálók implementációját számos könyvtár és keretrendszer támogatja, mint például TensorFlow, PyTorch, Keras stb. Az alábbiakban bemutatunk egy egyszerű neurális háló implementációját C++ nyelven, bár az ipari környezetben gyakrabban használtak a magas szintű nyelvek és könyvtárak.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <cstdlib>

using namespace std;

class Neuron {
public:
    double value;
    double activatedValue;
    double derivedValue;
    double bias;
    vector<double> weights;

    Neuron(int numOfWeights) {
        bias = ((double) rand() / (RAND_MAX)) * 2 - 1;
        for (int i = 0; i < numOfWeights; i++) {
            weights.push_back(((double) rand() / (RAND_MAX)) * 2 - 1);
        }
    }

    double activate() {
        activatedValue = 1.0 / (1.0 + exp(-value));
        return activatedValue;
    }

    double derive() {
        derivedValue = activatedValue * (1 - activatedValue);
        return derivedValue;
    }
};

// Additional Layer and Neural Network classes would be implemented similarly

int main() {
    // Example usage:
    // 3 input features, thus 3 weights
    Neuron neuron(3);

    neuron.value = 0.5;
    double activatedValue = neuron.activate();
    double derivedValue = neuron.derive();

    cout << "Neuron value: " << neuron.value << endl;
    cout << "Activated value: " << activatedValue << endl;
    cout << "Derived value: " << derivedValue << endl;

    return 0;
}
```

#### 3.4.5 Alkalmazások

A neurális hálók számtalan alkalmazási területen brillíroznak. Néhány példa:

##### I. Képfelismerés
A CNN-ek különösen népszerűek a képfelismerés terén, ahol képek osztályozására és objektumok detektálására használják.

##### II. Természetes Nyelvfeldolgozás (NLP)
Az RNN-ek, különösen az LSTM és GRU változatok, kimagaslóak az NLP feladatokban, mint a gépi fordítás, szöveg generálás és szentiment elemzés.

##### III. Autonóm járművek
Az autonóm járművek irányításában a neurális hálók különböző típusait használják, például képfeldolgozáshoz a környezet felismerésére.

#### 3.4.6 Jövőbeli Fejlesztések és Kihívások

A neurális hálók terén számos izgalmas fejlesztés van folyamatban. Kutatók azon dolgoznak, hogy javítsák az algoritmusok hatékonyságát, csökkentsék az energiafogyasztást és növeljék a modellek átláthatóságát. Ezen kívül az AI etikája és a modellek torzításának kezelése is egyre fontosabb téma.

### Összegzés

A neurális hálók az egyik legdinamikusabban fejlődő és legizgalmasabb területe a gépi tanulásnak. Az alapoktól kezdve a különböző hálózati architektúrákon át a tanulási algoritmusokig bezárólag, számos izgalmas és komplex tényező határozza meg ezen technológiák sikerességét. Az ipari és tudományos alkalmazásaik pedig mindannyiunk életére hatással vannak — és továbbra is új lehetőségeket nyitnak meg előttünk a jövőben.

### 3. Gépi tanulási algoritmusok

#### Alapok, algoritmusok és alkalmazások

A gépi tanulás alapvetően olyan algoritmusok és technikák halmaza, amelyeket arra használnak, hogy az adatokból mintákat ismerjenek fel és előrejelzéseket készítsenek. Egyes algoritmusai különösen erősek különböző problémák megoldásában, a regressziótól kezdve az osztályozáson át a bonyolult prediktív modellezésig. Ebben a fejezetben megvizsgáljuk a legelterjedtebb gépi tanulási algoritmusokat és azok alkalmazásait.

#### 3.1 Lineáris Regresszió

**Algoritmus és alkalmazások**

A lineáris regresszió az egyik legegyszerűbb és leggyakrabban használt gépi tanulási algoritmus, amely az adatok közötti lineáris kapcsolat modellezésére szolgál. Az algoritmus célja egy olyan egyenlet megtalálása, amely legjobban illeszkedik az adatokhoz.

**Matematikai formulázás**

A lineáris regresszió alapja az egyenletrendszer:
$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon $$
ahol:
- $y$ a célváltozó,
- $x_i$ a prediktorok (input változók),
- $\beta_i$ a paraméterek (súlyok),
- $\epsilon$ a hiba kifejezés.

A paraméterek becslésére a leggyakrabban a legkisebb négyzetek módszerét (Ordinary Least Squares, OLS) alkalmazzák, amely minimalizálja a megfigyelt és az előrejelzett értékek közötti különbség négyzetösszegét.

**Algoritmus**

1. **Adatgyűjtés és előkészítés**: Az adatok összegyűjtése, tisztítása, normalizálása.
2. **Modellegyüttállás**: Az $\mathbf{X}$ input mátrix és az $\mathbf{y}$ vektormátrix kialakítása.
3. **Paraméterbecslés**: A OLS módszer alkalmazásával a paraméterek ($\boldsymbol{\beta}$) becslése.
4. **Modellértékelés**: Az előrejelzett értékek és a valós értékek összehasonlítása metrikák használatával (pl. MSE, R^2).

**Pseudokód**

```plaintext
Input: Data matrix X, Target vector y

1. Append a column of ones to X for the intercept term
2. Calculate the parameter vector beta using OLS:
   beta = (X.T * X)^(-1) * X.T * y
3. Predict the target values using calculated beta:
   y_pred = X * beta
4. Evaluate the model performance using appropriate metrics
```

**Alkalmazások**

A lineáris regresszió széles körben alkalmazott az alábbi területeken:
- Gazdasági előrejelzések (pl. GDP növekedés, részvényárak).
- Epidemiológiai kutatás (pl. betegségek előfordulásának modellezése).
- Marketing (pl. kampány hatékonyságának mérése, ügyfélelvándorlás előrejelzése).

#### 3.2 Logisztikus Regresszió

**Algoritmus és alkalmazások**

A logisztikus regresszió egy bináris klasszifikációs algoritmus, amely a célváltozót valószínűségként modellezi. Az célja, hogy megtalálja azt a logit-transzformált összefüggést a prediktorok és a bináris kimenetel között.

**Matematikai formulázás**

A logisztikus regressziót a logit-függvény írja le:

$$ \text{logit}(p) = \log \left( \frac{p}{1 - p} \right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p $$

**Algoritmus**

1. **Adatgyűjtés és előkészítés**: Az adatokat összegyűjtik és előkészítik.
2. **Modellegyüttállás**: Az input mátrix ($\mathbf{X}$) és a célmátrix ($\mathbf{y}$) kialakítása.
3. **Paraméterbecslés**: Az iteratív módszerek, például a Maximum Likelihood Estimation (MLE) alkalmazása.
4. **Modellértékelés**: Teljesítménymérő paraméterek (pl. AUC, F1-score) alkalmazása.

**Pseudokód**

```plaintext
Input: Data matrix X, Target vector y

1. Initialize weights beta with random values
2. Choose a learning rate alpha

Repeat until convergence:
    1. Calculate the predicted probabilities using the sigmoid function:
       p = 1 / (1 + exp(-X * beta))
    2. Update weights using the gradient of the log-likelihood function:
       beta = beta + alpha * X.T * (y - p)

Output: Optimized weights beta
```

**Alkalmazások**

A logisztikus regressziót széles körben alkalmazzák olyan területeken, amikor a kimenet bináris érték:

- Pénzügyi előrejelzések (pl. hitelkockázat).
- Egészségügy (pl. betegségek valószínűségének előrejelzése).
- Marketing (pl. vásárlási döntések előrejelzése).

#### 3.3 Döntési Fák (Decision Trees)

**Algoritmus és alkalmazások**

A döntési fák olyan fa alapú modellek, amelyek az adatokat iteratív döntési pontok mentén bontják fel, hogy egy prediktív modellt alkossanak. A döntési fák általában kétféle típusú alkalmazások lehetnek: osztályozás és regresszió.

**Matematikai formulázás**

A döntési fákat két fő komponens alkotja:
- Csomópontok (Nodes): Amelyek az adott prediktor változók alapján döntéseket tartalmaznak.
- Ágak (Branches): Amelyek a döntés alternatíváit képviselik.

**Algoritmus**

1. **Adatok előkészítése**: Az adatok előkészítése.
2. **Faépítési kritériumok**: Kritériumok meghatározása a csomópontok felosztására (pl. Gini-index, információnyereség).
3. **Faépítés**:
   - Válassz egy prediktort, amely a legjobb felosztást biztosítja.
   - Osszd fel a csomópontot a kiválasztott prediktor alapján.
   - Ismételd addig, amíg el nem éred a maximális fa mélységet vagy egy előre meghatározott kritériumot.
4. **Predikció**: Az új adatpontok besorolása a fa alapján.

**Pseudokód**

```plaintext
Input: Data matrix X, Target vector y

Function buildTree(X, y):
    If stopping criteria met:
        return leaf with majority class
    Else:
        Find the best feature and value to split
        Create child nodes by splitting the data on best split
        Recursively build child nodes
    Return tree

Tree = buildTree(X, y)
```

**Alkalmazások**

A döntési fák különösen népszerűek számos alkalmazási területen:

- Marketing (pl. vásárlói szegmentáció).
- Pénzügyi kockázatértékelés.
- Orvosi diagnózisok.

#### 3.4 Neurális Hálók (Neural Networks)

**Alapok, algoritmusok és alkalmazások**

A neurális hálók az agy idegsejtjeinek mintájára épülnek, és rengeteg kapcsolatot tartalmaznak az input és az output között. Ideálisak bonyolult minták és kapcsolatok felismerésére.

**Matematikai formulázás**

Egy egyszerű neurális háló több rétegből áll:
$$ a^{(l+1)} = \sigma(W^{(l)} a^{(l)} + b^{(l)}) $$
ahol:
- $a^{(l)}$ a $l$-edik réteg aktivációi,
- $W^{(l)}$ és $b^{(l)}$ a súlyok és elfogások,
- $\sigma$ az aktivációs függvény (pl. sigmoid, ReLU).

**Algoritmus**

1. **Adatok előkészítése**: Normalizált adatok.
2. **Hálózat inicializálása**: Véletlenszerű súlyok és elfogások.
3. **Edzés**:
   - Előre szorzás (Forward propagation): Az inputokat áthaladva a hálón a végső kimenetig.
   - Hátra szorzás (Backpropagation): A hibák visszaterjesztése, a súlyok frissítése az optimalizálási algoritmus használatával.
4. **Validáció**: Tesztelés egész adathalmazon.

**Pseudokód**

```plaintext
Input: Data matrix X, Target vector y, Learning rate alpha, Iterations n_iter

Initialize weights and biases randomly

For i in range(n_iter):
    # Forward propagation
    a = X
    for layer in network:
        z = layer.weights * a + layer.biases
        a = activation_function(z)
    
    # Compute loss
    loss = compute_loss(y, a)
    
    # Backward propagation
    gradient = compute_gradient(loss)
    for layer in reversed(network):
        layer.weights -= alpha * gradient.get_weights(layer)
        layer.biases -= alpha * gradient.get_biases(layer)

Output: Trained neural network
```

**Alkalmazások**

A neurális hálók alkalmazási területeinek skálája lélegzetelállítóan széles:

- Képfelismerés.
- Természetes nyelvfeldolgozás (NLP).
- Játéktér automatizálása (pl. Alphago).

### Összegzés

A különböző gépi tanulási algoritmusok különböző erősségekkel és gyengeségekkel rendelkeznek. Az algoritmusok alkalmazása erősen függ a megoldandó problémától és az adatok jellemzőitől. Az itt bemutatott algoritmusok – lineáris és logisztikus regresszió, döntési fák és neurális hálók – a gépi tanulás alapvető eszközei, amelyek megértése és helyes alkalmazása elengedhetetlen a képzett adatelemzők és gépi tanulási szakértők számára.

