\newpage

## 2. Klasszikus randomizált algoritmusok

A klasszikus algoritmusok világában a randomizált módszerek különleges szerepet töltenek be, mivel a véletlen elemek integrálása révén gyakran javítják a hatékonyságot és a stabilitást. Ebben a fejezetben két kiemelkedő randomizált algoritmust vizsgálunk meg részletesen: a Randomizált gyorsrendezést (Randomized Quick Sort) és a Randomizált keresést (Randomized Search). Először bemutatjuk a Randomizált gyorsrendezés működését, majd belemerülünk annak teljesítmény elemzésébe, hogy megértsük, miért tartják sokan a hatékony adatt rendezési algoritmusok egyik legjobbjának. Ezek után áttérünk a Randomizált keresésre, ahol nemcsak az algoritmus részleteit, hanem a különböző alkalmazási területeit is feltérképezzük. Mindkét algoritmus bemutatásával és elemzésével demonstráljuk, hogy a randomizált megközelítések hogyan nyújthatnak gyakorlati előnyöket a determinisztikus technikákkal szemben, és hogyan segíthetnek megoldani valós problémákat nagy hatékonysággal.


### 2.1 Randomizált gyorsrendezés (Randomized Quick Sort)

A gyorsrendezés (Quick Sort) egy népszerű és hatékony osztás-alapú rendezési algoritmus, amely Tony Hoare nevéhez fűződik. A gyorsrendezés átlagos futási ideje $O(n \log n)$, de a legrosszabb esetben $O(n^2)$. A randomizált gyorsrendezés célja, hogy a legrosszabb esetek valószínűségét minimálisra csökkentse, ezáltal elérve az átlagos $O(n \log n)$ futási időt függetlenül az eredeti bemenettől. Ebben a fejezetben részletesen elemezzük a randomizált gyorsrendezést, annak működését és teljesítmény elemzését.

#### 2.1.1 Az algoritmus működése

A gyorsrendezés alapötlete az, hogy kiválaszt egy úgynevezett pivot elemet, amelyet nem feltétlenül a tömb közepéről szúr le, és ezt az elemet használja fel az egész tömb két alhalmazra történő felosztására: a pivot-nál kisebb és a pivot-nál nagyobb elemek halmazára. Ezután rekurzívan alkalmazza ugyanezt az eljárást az alhalmazokra.

A randomizált gyorsrendezés esetében a pivot elemet véletlenszerűen választjuk ki, amely segít elkerülni a legrosszabb eset bekövetkezését, amikor a bemeneti tömb már rendezett vagy erősen korrelált.

Az algoritmus lépései a következőképpen írhatók le:

1. Ha a tömb mérete $n \leq 1$, akkor a tömb már rendezett.
2. Válassz véletlenszerűen egy pivot elemet a tömbből.
3. Helyezd át a pivot elemet úgy, hogy a bal oldalon legyenek a pivot-nál kisebb elemek és a jobb oldalon a pivot-nál nagyobbak.
4. Rekurzívan alkalmazd a gyorsrendezést a bal és jobb alsó résztömbökön.

#### 2.1.2 Pseudocode

Az alábbiakban bemutatjuk a randomizált gyorsrendezés pseudokódját:

```c++
void randomizedQuickSort(int arr[], int left, int right) {
    if (left < right) {
        int pivotIndex = randomizedPartition(arr, left, right);
        randomizedQuickSort(arr, left, pivotIndex - 1);
        randomizedQuickSort(arr, pivotIndex + 1, right);
    }
}

int randomizedPartition(int arr[], int left, int right) {
    int randomIndex = left + rand() % (right - left + 1);
    swap(arr[randomIndex], arr[right]);
    return partition(arr, left, right);
}

int partition(int arr[], int left, int right) {
    int pivot = arr[right];
    int i = left - 1;
    for (int j = left; j < right; j++) {
        if (arr[j] < pivot) {
            i++;
            swap(arr[i], arr[j]);
        }
    }
    swap(arr[i + 1], arr[right]);
    return i + 1;
}
```

#### 2.1.3 Teljesítmény elemzés

##### Átlagos eset futási idő

A randomizált gyorsrendezés átlagos eset futási ideje $O(n \log n)$. Az alábbiakban bemutatjuk a futási idő elemzését:

- Véletlenszerűen választunk egy pivot elemet, amely definiál egy felosztást.
- Átlagosan a pivot az összes lehetséges pozíció közepén helyezkedik el, így a bal és jobb alhalmazok mérete körülbelül $n/2$.
- Ha az alhalmazok mindegyike $n/2$ méretű, akkor a rekurzió mélysége $\log n$, és az egyes rekurzív lépések során $n$ összehasonlítás történik.

Ezért az átlagos eset futási idő elemzése a következőképpen írható fel:

$$ T(n) = 2T\left( \frac{n}{2} \right) + O(n) $$

A ,,Master Theorem,, segítségével megoldva a rekurzív képletet:

$$ T(n) = O(n \log n) $$

##### Legrosszabb eset futási idő

A hagyományos gyorsrendezés legrosszabb esetének futási ideje $O(n^2)$, amikor a pivot a legkisebb vagy legnagyobb értéket választja ki, így az alhalmazok mérete $n-1$ és 1 lesz. Randomizált gyorsrendezés esetén a véletlenszerű pivot választás segít minimalizálni annak valószínűségét, hogy mindig ilyen rossz felosztások legyenek.

##### Véletlenszerűség hatása

A randomizált algoritmusok egyik kulcstulajdonsága, hogy a futási idő gyakorisági eloszlását kiegyenlítik. Még ha van is legrosszabb eset, az valószínűsége rendkívül alacsony. A véletlenszerű pivot választás miatt a valószínűségi eloszlás centruma a közepes felosztások köré összpontosul, ami $O(n \log n)$ futási időt biztosít.

#### 2.1.4 Előnyök és hátrányok

A randomizált gyorsrendezés számos előnnyel és néhány hátránnyal rendelkezik:

##### Előnyök

- **Jobb átlagos teljesítmény**: Garantálja a $O(n \log n)$ futási időt átlagosan, függetlenül a bemeneti tömb eloszlásától.
- **Egyszerű implementáció**: A véletlenszerű pivot kiválasztás viszonylag egyszerűen megvalósítható.
- **In-place rendezés**: Nem igényel további memóriát a tömbön kívül.

##### Hátrányok

- **Véletlenszerűség költsége**: A véletlenszerű számok generálása némi többletidőt vehet igénybe.
- **Rossz eset lehetőség**: Bár valószínűsége kicsi, mégis előfordulhat, hogy az algoritmus a $O(n^2)$ futási idő esetébe kerül.

#### 2.1.5 Összegzés

A randomizált gyorsrendezés egy hatékony és praktikus algoritmus, amely jelentősen javítja a hagyományos gyorsrendezés teljesítményét rossz esetekben. A véletlenszerű pivot választás segít elkerülni azokat a speciális bemeneti eseteket, amelyek a hagyományos gyorsrendezést lassítják. Az algoritmus átlagos esetben $O(n \log n)$ futási időt ér el, és a véletlenszerű eloszlás általában elegendő ahhoz, hogy minimálisra csökkentse a legrosszabb esetek előfordulási valószínűségét.

A randomizált gyorsrendezés számos alkalmazási területre ideális, mint például nagy méretű adatok rendezése, ahol a gyors elérés és rendezés kulcsfontosságú. Az algoritmus hatékony implementációja és előnyei teszik ezt egy kiemelkedő választássá a területen.


### Működés és teljesítmény elemzés

#### Randomizált Gyorsrendezés (Randomized Quick Sort)
Randomizált gyorsrendezés egy gyorsrendezési algoritmus implementáció, amely randomizációval próbálja meg elkerülni a legrosszabb esetbeli futási időt. Gyakran alkalmazzák arra, hogy az átlagos $O(n \log n)$ futási időt biztosítsák, még akkor is, ha rendkívül rossz "bemenet" adódik.

#### Működési Mechanizmus

A gyorsrendezés lényege, hogy egy adott listát rekurzívan két részre bont, és ezekre a részekre külön-külön alkalmazza magát az algoritmust. A randomizált gyorsrendezés ugyanennél a stratégiánál marad, de egy véletlenszerűen kiválasztott pivot (középpont) elemet használ minden rekurzív lépésnél. A cél az, hogy az elemeket úgy osszuk két részre a pivot elem köré, hogy az egyenletes felosztást próbáljuk maximalizálni, ezáltal csökkentve a rekurzív hívások számát.

#### Lépések

1. **Véletlen Pivot Kiválasztása:**
   Egy véletlenszerű pozíciójú elemet választunk a listából, és azt használjuk pivotként.
   
2. **Particionálás:**
   A listát két részre bontjuk: egy rész tartalmazza az összes olyan elemet, amelyek kisebbek, mint a pivot, a másik rész pedig a nagyobbakat.
   
3. **Rekurzív Hívás:**
   Az algoritmus rekurzívan alkalmazza magát a két részhalmazra.

C++ példa a randomizált gyorsrendezésre:

```cpp
#include <cstdlib>
#include <iostream>
#include <vector>
#include <algorithm>

// Helper function for swapping elements
void swap(int& a, int& b) {
    int temp = a;
    a = b;
    b = temp;
}

// Function to perform the partition operation
int partition(std::vector<int>& arr, int low, int high) {
    int pivot = arr[low];
    int i = low - 1;
    int j = high + 1;

    while (true) {
        do {
            i++;
        } while (arr[i] < pivot);

        do {
            j--;
        } while (arr[j] > pivot);

        if (i >= j)
            return j;

        swap(arr[i], arr[j]);
    }
}

// Function to randomly select a pivot and partition the array
int randomizedPartition(std::vector<int>& arr, int low, int high) {
    int randomPivotIdx = low + rand() % (high - low + 1);
    swap(arr[low], arr[randomPivotIdx]);
    return partition(arr, low, high);
}

// Quick Sort function
void randomizedQuickSort(std::vector<int>& arr, int low, int high) {
    if (low < high) {
        int pivotIdx = randomizedPartition(arr, low, high);
        randomizedQuickSort(arr, low, pivotIdx);
        randomizedQuickSort(arr, pivotIdx + 1, high);
    }
}

// Main function to illustrate the algorithm
int main() {
    std::vector<int> arr = {3, 6, 8, 10, 1, 2, 1};
    int n = arr.size();

    std::cout << "Unsorted array: ";
    for (int i : arr) {
        std::cout << i << " ";
    }
    std::cout << std::endl;

    randomizedQuickSort(arr, 0, n - 1);

    std::cout << "Sorted array: ";
    for (int i : arr) {
        std::cout << i << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

#### Teljesítmény Elemzés

A randomizált gyorsrendezés várható futási ideje $O(n \log n)$, feltételezve, hogy a bemenetet randomizált módon rendezi. A legrosszabb esetben a futási idő $O(n^2)$ lehet, ha a pivot elem a legrosszabb esetet produkálja (például, ha mindig az első vagy utolsó elem a pivot), de a randomizáció miatt ennek valószínűsége elhanyagolható.

##### Átlagos Eset
Az átlagos futási idő $O(n \log n)$, mivel a valószínűsége annak, hogy az osztások egyenletesek lesznek, magas. Az osztások egyenletessége biztosítja, hogy a rekurzív hívások száma csökken, és így az összesített futási idő kedvező lesz.

##### Legrosszabb Eset
A legrosszabb eset $O(n^2)$, amely akkor fordul elő, ha az osztások nagyon egyenetlenek, például ha mindig a legkisebb vagy a legnagyobb elem kerül kiválasztásra pivotként. A randomizáció ezt az esélyt minimalizálja.

##### Elemösszehasonlítások és Cserék Száma
Az átlagos osztás esetén az egyes elemek átlagosan $\log n$ szintet érint a rekurziók során. Amikor egy osztást végrehajtunk, minden elem a listában egyszer összehasonlításra kerül a pivottal, így minden szinten $O(n)$ összehasonlítás történik. Az így kapott összehasonlítások száma összességében $O(n \log n)$.

#### Randomizált Keresés (Randomized Search)
A randomizált keresés egy egyszerű, de hatékony technika, amely különösen hasznos a véletlenszerűen szervezett adatszerkezetekre vonatkozó keresések optimalizálására. Ebben a részben megvizsgáljuk a randomizált keresés működését és alkalmazását különböző problémákra.

#### Működési Mechanizmus

A randomizált keresés algoritmus lényege, hogy randomizált mintavétellel próbálja minimalizálni a keresési időt egy nagy adathalmazban. Az algoritmus véletlenszerűen kiválasztott elemeket vizsgál, és általában visszaad egy elfogadható eredményt egy határon belül.

#### Alkalmazás

1. **Alap Randomized Search Algoritmus:**

Az alap randomizált keresés során, véletlenszerű számmintákat veszünk, és mindegyik mintára megnézzük, hogy az keresett kulcs-e.

2. **Approximate Nearest Neighbor (ANN):**
   Az ANN problémában egy olyan pontot keresünk egy sokdimenziós térben, amely a legközelebb van az adott referenciapontokhoz. A randomizált keresés itt is hatékony lehet, hiszen véletlenszerű mintavétellel próbáljuk megtalálni a legközelebbi pontot.

#### Teljesítmény Elemzés

A randomizált keresés teljesítménye szorosan összefügg a véletlen mintavétel minőségével és a keresett struktúra tulajdonságaival.

##### Átlagos Eset
Az átlagos futási idő $O(n)$, mivel minden elemnek egyenlő esélye van arra, hogy kiválasztásra kerüljön.

##### Legrosszabb Eset
A legrosszabb eset $O(n)$, ahol minden egyes elem vizsgálatára szükség lehet a keresett elem megtalálása érdekében. Ez akkor fordulhat elő, ha a keresett elem valamilyen rendkívül ritka mintával rendelkezik.

#### Cél Funkciók és Heurisztikák

A randomizált keresés gyakran kiegészül különböző heurisztikákkal és célfüggvényekkel, amelyek segíthetik az algoritmus hatékonyságát:

1. **Próbák Száma (Number of Trials):**
   Egy meghatározott számú véletlenszerű próbát végezve, az algoritmus növelheti a siker esélyeit.

2. **Következtetési Stratégia (Inference Strategy):**
   Ha a véletlenszerű próbák során észlelhető minta áll fenn, akkor az algoritmus képes lehet optimalizálni a keresést.

3. **Párlási Stratégia (Distillation Strategy):**
   Ezzel a stratégiával, a keresés közben talált minták használhatók a keresési tér méretének csökkentésére.

#### Példa Alkalmazások

1. **Nagy Adat Elemzés:** Olyan esetekben alkalmazható, amikor az adatméret túl nagy ahhoz, hogy teljes mértékben átvizsgálható legyen.
2. **Optimális Paraméterek Keresése:** Gépi tanulási modellek optimalizálásakor nevezetes paraméterek keresésére használható.
3. **Lenyomat Keresés:** Hasonlóság alapú keresések esetében, például képfelismerésben.

A randomizált algoritmusok ereje a bizonytalanságból származik, és amikor ezen algoritmusokat jól tervezték és alkalmaztak, lenyűgöző teljesítményi előnyöket tudnak nyújtani hagyományos megoldásokhoz képest. Azonban minden alkalmazásra egyedi tervezés szükséges annak érdekében, hogy az algoritmus valóban kihasználhassa a randomizációban rejlő lehetőségeket.


### Randomizált keresés (Randomized Search)

A randomizált keresés olyan algoritmikus technika, amely magában foglalja a véletlenszerűség használatát a megoldások megtalálásához vagy az adatok feldolgozásához. Az ilyen típusú algoritmusok célja az, hogy javítsák az átlagos teljesítményt, elkerüljék a legrosszabb eseteket, és egyszerűsítsék az implementációt. Ebben a fejezetben áttekintjük a randomizált keresés alapelveit, algoritmusait és különböző alkalmazási területeit.

#### Alapelvek

A randomizált keresés alapját az képezi, hogy bizonyos műveleteket véletlenszerűen választott lépésekkel hajtunk végre. Mindez a következő előnyöket nyújtja:

1. **Robusztus teljesítmény:** A randomizálás gyakran elkerüli azokat a mintázatokat, amelyek a determinisztikus módszereket lelassítják.
2. **Egyszerűség:** Sok esetben a randomizált algoritmusok egyszerűbbek és intuitívabbak, mint a determinisztikus megfelelőik.
3. **Átlagos vs. legrosszabb teljesítmény:** Míg egy determinisztikus algoritmusnál gyengébb teljesítményt nyújthat a legrosszabb esetekben, addig egy jól tervezett randomizált algoritmus a legtöbb esetben kedvező átlagos futási időt ér el.

### Randomizált keresési algoritmusok

#### Randomizált bináris keresés (Randomized Binary Search)

A bináris keresés egy hatékony keresési technika, amely szorosan kapcsolódik a rendezett adatszerkezetekhez. A randomizált változat a hagyományos bináris keresésnél is gyorsabb működést biztosíthat bizonyos valószínűséggel.

**Algoritmus**:

1. Választunk egy véletlen indexet az aktuális keresési tartományból.
2. Összehasonlítjuk az elemet a keresett kulccsal.
3. Három eset lehetséges:
    - Ha az elem egyezik a keresett kulccsal, akkor megtaláltuk az elemet.
    - Ha a kulcs kisebb, folytatjuk a keresést a bal oldali részhalmazban.
    - Ha a kulcs nagyobb, folytatjuk a keresést a jobb oldali részhalmazban.
4. Ismételjük a folyamatot, amíg meg nem találjuk az elemet vagy a keresési tartomány ki nem merül.

**Példakód (C++)**:
```cpp
#include <iostream>
#include <cstdlib>
#include <ctime>

int randomizedBinarySearch(int arr[], int left, int right, int key) {
    if (right >= left) {
        int mid = left + rand() % (right - left + 1);

        if (arr[mid] == key) {
            return mid;
        }
        if (arr[mid] > key) {
            return randomizedBinarySearch(arr, left, mid - 1, key);
        }
        return randomizedBinarySearch(arr, mid + 1, right, key);
    }
    return -1;
}

int main() {
    std::srand(std::time(0));  // Initialize random seed

    int arr[] = {2, 3, 4, 10, 40};
    int n = sizeof(arr) / sizeof(arr[0]);
    int key = 10;
    int result = randomizedBinarySearch(arr, 0, n - 1, key);
    (result == -1) ? std::cout << "Element is not present in array"
                   : std::cout << "Element is present at index " << result;
    return 0;
}
```

### Alkalmazások

#### Geometriai algoritmusok

A randomizált keresést gyakran alkalmazzák geometriai problémák megoldására, például a legközelebbi pont keresésére vagy a konvex burkoló (convex hull) meghatározására. A geometriai adatstruktúrákban történő keresés gyakran kihasználja a randomizálás adta előnyöket a gyorsabb megoldások érdekében.

#### Adaptív keresési technikák

Adaptív keresési algoritmusok, mint például a randomizált séta (random walk), széles körben alkalmazottak a nagy gráfok bejárásánál, ahol a statisztikai tulajdonságok alapján iteráljuk a keresést. Ez különösen hatékony a nagy hálózatokban és a web indexelésében.

#### Machine Learning és Evolúciós Algoritmusok

A randomizált keresés fontos szerepet játszik a gépi tanulási algoritmusokban, különösen az optimalizálási problémákban. Az evolúciós algoritmusok esetében a randomizálás hozzájárul a sokféleség megőrzéséhez a populációban, így elkerülve a helyi optimumok csapdáit és elősegítve a globális optimum megtalálását.

**Monte Carlo és Las Vegas Algoritmusok**

- **Monte Carlo algoritmusok**: Ezek az algoritmusok egy adott valószínűségi hibával adnak eredményt. Az eredmény lehet hibás, de a hiba valószínűsége csökkenthető további számításokkal.
- **Las Vegas algoritmusok**: Ezek az algoritmusok garantálják a helyes eredményt, de a futási idő változékony lehet a randomizálás miatt.

#### Teljesítmény elemzés

A randomizált keresési algoritmusok teljesítményének elemzése több szempontból is történhet. A legfontosabb a várható futási idő és a memóriahasználat.

**Várható futási idő**: Általában a várható futási idő optimális vagy közel optimális. Például a randomizált bináris keresés esetében a várható futási idő logaritmikus, $\mathcal{O}(\log n)$, hasonlóan a hagyományos bináris kereséshez, de a mértéke erősen függ a véletlenségtől és a bemeneti adatoktól.

**Memory complexity**: A randomizált algoritmusok, különösen azok, amelyek rekurziót használnak, élhetnek a stack alapú memóriakezeléssel. Például a randomizált bináris keresés a legrosszabb esetben is a $\mathcal{O}(\log n)$ memóriaigénytől függ.

**Szimuláció és Empirikus Elemzés**: Gyakori az ilyen algoritmusok esetében, hogy szimulációkkal vagy valós adathalmazokon végzett kísérletekkel ellenőrzik a teljesítményt.

#### Példakód Monte Carlo algoritmusra: Prímteszt
Az alábbi példakód a Miller-Rabin prímtesztet mutatja be, ami egy Monte Carlo algoritmus.

**Példakód (C++)**:
```cpp
#include <iostream>
#include <cstdlib>

// Power function to compute (x^y) % p
int power(int x, unsigned int y, int p) {
    int res = 1;
    x = x % p;
    while (y > 0) {
        if (y & 1)
            res = (res * x) % p;
        y = y >> 1;
        x = (x * x) % p;
    }
    return res;
}

// This function is called for all k trials. It returns
// false if n is composite and returns true if n is
// probably prime.
bool millerTest(int d, int n) {
    int a = 2 + rand() % (n - 4);
    int x = power(a, d, n);
    if (x == 1 || x == n - 1)
        return true;
    while (d != n - 1) {
        x = (x * x) % n;
        d *= 2;
        if (x == 1) return false;
        if (x == n - 1) return true;
    }
    return false;
}

// It returns false if n is composite and returns true
// if n is probably prime. k is an input parameter that
// determines accuracy level. Higher value of k indicates
// more accuracy.
bool isPrime(int n, int k) {
    if (n <= 1 || n == 4) return false;
    if (n <= 3) return true;
    int d = n - 1;
    while (d % 2 == 0)
        d /= 2;
    for (int i = 0; i < k; i++)
        if (!millerTest(d, n))
            return false;
    return true;
}

int main() {
    srand(time(NULL));
    int k = 4;  // Number of iterations
    int n = 31;  // Number to check
    isPrime(n, k) ? std::cout << "Prime" : std::cout << "Not Prime";
    return 0;
}
```

### Összefoglalás

A randomizált keresési algoritmusok jelentős szerepet játszanak a modern algoritmus tervezésben, mivel gyakran nyújtanak jobb átlagos teljesítményt és nagyobb rugalmasságot, mint a determinisztikus algoritmusok. Az ilyen algoritmusok felhasználhatók különböző kontextusokban, beleértve a gépi tanulást, a hálózati kereséseket, és a különféle számítástudományi problémák megoldását. Az elméleti elemzésük és az empirikus tesztelésük egyaránt hozzájárul a megértésükhöz és a hatékony alkalmazásukhoz.

### Algoritmusok és Alkalmazások

A randomizált algoritmusok nemcsak elméleti szempontból érdekesek, hanem számos gyakorlati alkalmazásban is jelentős szerepet játszanak. Ebben az alfejezetben két alapvető randomizált algoritmust, a Randomizált Gyorsrendezést (Randomized Quick Sort) és a Randomizált Keresést (Randomized Search) tekintjük át. Mindkét algoritmus különösen érdekes, mivel randomizált elemeik segítségével gyakran javítják a teljesítményt és az átlagos esetre vonatkozó futási időt a determinisztikus megfelelőikhez képest.

#### Randomizált Gyorsrendezés (Randomized Quick Sort)

Az eredei gyorsrendezés algoritmus először Tony Hoare által lett bevezetve 1961-ben. Ez a rendezési algoritmus az oszd meg és uralkodj stratégiát követi, ahol az adathalmazt egy pivot elem mentén particionáljuk, majd rekurzívan alkalmazzuk ugyanezt a stratégiát a keletkező részhalmazokra. A gyorsrendezés hatékonysága nagyban függ a pivot elem megválasztásától. A legjobb és az átlagos esetben O(n log n) futási időt produkál, míg a legrosszabb esetben O(n^2) időt igényel, ha a pivot választás mindig a legkedvezőtlenebb.

A randomizált gyorsrendezés esetében a pivot elemet véletlenszerűen választjuk, hogy minimalizáljuk annak esélyét, hogy a legrosszabb esetet kapjuk. A véletlenszerű választás eredményeként az algoritmus átlagos futási ideje közeledik az O(n log n)-hez, a legrosszabb eset O(n^2) valószínűsége csökken.

##### Működés

A randomizált gyorsrendezés lépései a következők:

1. **Véletlen pivot választása:** Válasszunk ki véletlenszerűen egy pivot elemet az adathalmazból.
2. **Particionálás:** Particionáljuk az elemeket úgy, hogy a pivot elemnél kisebbek kerüljenek balra, a nagyobbak pedig jobbra.
3. **Rekurzív rendezés:** Rekurzívan alkalmazzuk ugyanezt a folyamatot a két részharmadra.

##### Teljesítmény Elemzés

A randomizált gyorsrendezés átlagos futási ideje O(n log n). Az átlagos eset megértése érdekében tekintsük:

- `T(n)` a futási idő egy n méretű tömb esetén.
- Véletlenszerű pivot választás esetén az algoritmus teljesítménye az átlagos esetben is fennmarad,
mivel bármelyik pivot elem valószínűsége 1/n, így a pivot elem választásának variációi kiegyenlítik egymást.

Rekurzív osztás esetén a várható érték (expectation) a T(n) futási időre:

$$ T(n) = n + \frac{1}{n} \sum_{k=0}^{n-1} (T(k) + T(n-k-1)) $$

Ez végül az O(n log n) várható futási időt eredményezi.

#### Randomizált Keresés (Randomized Search)

A randomizált keresési algoritmusok olyan algoritmusokat jelentenek, ahol a keresési műveletekbe véletlenszerűséget építünk be annak érdekében, hogy átlagosan jobb futási időt kapjunk. Egy tipikus példa ilyen típusú algoritmusra a randomizált bináris kereső fa (Randomized Binary Search Tree, RBST).

##### Algoritmusok

**Randomizált Bináris Kereső Fa (RBST):**

Ez a fa egy hagyományos bináris kereső fa, amelynél minden beszúrás és törlés véletlenszerűség alapú. A fa elemei úgy kerülnek be a struktúrába, hogy azok valószínűsége egyenletesen oszlik el, aminek következménye, hogy várható magassága O(log n) marad.

A RBST műveletei a következők:

1. **Beszúrás (Insert):** Véletlenszerűen döntjük el, hogy az új elem a megfelelő helyen a bal vagy a jobb al-fába kerül.
2. **Törlés (Delete):** Véletlenszerű rotációk alkalmazásával a kívánt elem egy levél pozícióba kerül, ahol könnyen eltávolítható.

**Example in C++:**

```cpp
#include <iostream>
#include <cstdlib>

struct Node {
    int key;
    Node* left;
    Node* right;
    Node(int k) : key(k), left(nullptr), right(nullptr) {}
};

Node* rightRotate(Node* y) {
    Node* x = y->left;
    Node* T2 = x->right;
    x->right = y;
    y->left = T2;
    return x;
}

Node* leftRotate(Node* x) {
    Node* y = x->right;
    Node* T2 = y->left;
    y->left = x;
    x->right = T2;
    return y;
}

Node* insert(Node* root, int key) {
    if (root == nullptr)
        return new Node(key);
    
    if (rand() % 2) { // Randomized decision
        root->left = insert(root->left, key);
        root = rightRotate(root);
    } else {
        root->right = insert(root->right, key);
        root = leftRotate(root);
    }
    
    return root;
}

void inorder(Node* root) {
    if (root != nullptr) {
        inorder(root->left);
        std::cout << root->key << " ";
        inorder(root->right);
    }
}

int main() {
    Node* root = nullptr;
    root = insert(root, 10);
    root = insert(root, 20);
    root = insert(root, 30);
    root = insert(root, 40);
    root = insert(root, 50);

    std::cout << "Inorder traversal of the Randomized BST: ";
    inorder(root);

    return 0;
}
```

##### Alkalmazások

A randomizált keresési algoritmusok számos területen alkalmazhatók, beleértve a következőket:

1. **Database Indexing:**
   A véletlenszerűség beépítése az indexelő módszerekbe segíthet elkerülni a rossz eseteket és javítani a keresési műveletek átlagos idejét.

2. **Numerical Algorithms:**
   A Monte Carlo és a Las Vegas típusú algoritmusok széles körben alkalmazzák a randomizált keresési technikákat a komplex matematikai problémák megoldásában.

3. **Machine Learning:**
   Randomizált keresési algoritmusok használhatók a hiperparaméter optimalizálásban, ahol a randomizált keresési stratégia gyakran hatékonyabb, mint a rácsos keresés (grid search).

4. **Network Routing:**
   A hálózati útvonalválasztási algoritmusokban a randomizált keresési módszerek növelhetik a robusztusságot, mivel kiegyenlítik a forgalmi terhelést és elkerülik a determinisztikus mintázatok kialakulását, amelyek hálózati torlódáshoz vezethetnek.

5. **Cryptography:**
   A titkosítási rendszerekben a véletlenszerűséget használó algoritmusok növelik a biztonságot, mivel megnehezítik a jelszó/feltöréses támadások kivitelezését.

#### Végső Gondolatok

A randomizált algoritmusok fogalma a számítástudományban alapvető fontosságú, mivel lehetővé teszi a bonyolult problémák hatékony megoldását anélkül, hogy ezek a legrosszabb eset futási időre korlátozódnának. Mind a Randomizált Gyorsrendezés, mind a Randomizált Keresés kiváló példái annak, hogy a véletlenszerűség beépítése hogyan segíthet javítani az algoritmusok általános teljesítményét. Ezek az algoritmusok nemcsak elméleti értékűek, hanem számos valós alkalmazásban is hasznosak, amint azt a fentiekben részletezett példákból láthattuk. Az algoritmusok mélyebb megértése és a randomizáció megértése új lehetőségeket nyithat meg az optimális megoldások kidolgozásában a számítástudomány különböző területein.

