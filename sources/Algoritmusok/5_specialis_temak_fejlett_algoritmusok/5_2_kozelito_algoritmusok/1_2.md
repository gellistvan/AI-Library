2. Klasszikus k√∂zel√≠t≈ë algoritmusok

A k√∂zel√≠t≈ë algoritmusok vil√°ga leny≈±g√∂z≈ë megold√°si eszk√∂zt√°rat k√≠n√°l a bonyolult √©s nehezen kezelhet≈ë optimaliz√°l√°si probl√©m√°kra. Ebben a fejezetben k√©t olyan klasszikus probl√©m√°t vizsg√°lunk meg, amelyek kih√≠v√°st jelentenek a sz√°m√≠t√°studom√°ny √©s az oper√°ci√≥kutat√°s ter√ºlet√©n: a h√°tizs√°k probl√©ma (Knapsack Problem) √©s az utaz√≥ √ºgyn√∂k probl√©ma (Traveling Salesman Problem). Mindk√©t probl√©ma NP-teljes, ami azt jelenti, hogy nincs ismert polinomi√°lis idej≈± algoritmus, amely a legjobb megold√°st garant√°lja minden esetben. Azonban k√∂zel√≠t≈ë algoritmusok √©s heurisztik√°k seg√≠ts√©g√©vel gyakran tal√°lhatunk olyan megold√°sokat, amelyek elfogadhat√≥ eredm√©nyeket ny√∫jtanak √©sszer≈± id≈ën bel√ºl. Ebben a fejezetben bemutatjuk √©s elemezz√ºk a h√°tizs√°k probl√©ma √©s az utaz√≥ √ºgyn√∂k probl√©ma k√ºl√∂nb√∂z≈ë k√∂zel√≠t≈ë megold√°sait, hangs√∫lyt fektetve az alkalmazott m√≥dszerek hat√©konys√°g√°ra √©s gyakorlati felhaszn√°l√°s√°ra. A c√©lunk, hogy az olvas√≥ √©rtse √©s tudja alkalmazni ezeket a technik√°kat val√≥s probl√©m√°k megold√°s√°ban, valamint k√©pes legyen √©rt√©kelni a megold√°sok min≈ës√©g√©t √©s az alkalmazott algoritmusok teljes√≠tm√©ny√©t.

### 2. Klasszikus k√∂zel√≠t≈ë algoritmusok

#### H√°tizs√°k probl√©ma (Knapsack Problem)

A h√°tizs√°k probl√©ma (Knapsack Problem) az egyik legismertebb √©s leggyakrabban tanulm√°nyozott kombinatorikai optimaliz√°l√°si probl√©ma. A probl√©ma sokf√©le val√≥s alkalmaz√°sban felmer√ºl, kezdve a k√©szletez√©s optimaliz√°l√°s√°t√≥l √©s p√©nz√ºgyi portf√≥li√≥k √∂ssze√°ll√≠t√°s√°ig, k√ºl√∂nf√©le logisztikai tervez√©si probl√©m√°kig. A klasszikus h√°tizs√°k probl√©ma t√∂bb v√°ltozatban l√©tezik, ezek k√∂z√ºl a leggyakrabban eml√≠tett t√≠pus az √∫n. 0/1 h√°tizs√°k probl√©ma.

#### Klasszikus H√°tizs√°k Probl√©ma Defin√≠ci√≥ja

A 0/1 h√°tizs√°k probl√©ma form√°lis defin√≠ci√≥ja a k√∂vetkez≈ë:

- van egy h√°tizs√°k, amelynek maxim√°lis kapacit√°sa $W$,
- van $n$ t√°rgy, mindegyik t√°rgyhoz tartozik egy s√∫ly $w_i$ √©s egy √©rt√©k $v_i$,
- a c√©l az, hogy v√°lasszunk ki egy v√°logat√°st a t√°rgyakb√≥l √∫gy, hogy a h√°tizs√°kban l√©v≈ë t√°rgyak √∂sszs√∫lya ne haladja meg a $W$ kapacit√°s √©s az √∂ssz√©rt√©k maxim√°lis legyen.

Matematikailag ezt a k√∂vetkez≈ëk√©ppen lehet megfogalmazni:

$$ \max \sum_{i=1}^{n} v_i x_i $$
$$ \text{subject to} \quad \sum_{i=1}^{n} w_i x_i \leq W $$
$$ x_i \in \{0, 1\} \quad \text{for all } i $$

Ahol $x_i$ egy bin√°ris v√°ltoz√≥, amely megmutatja, hogy az $i$-ik t√°rgyat kiv√°lasztottuk-e vagy sem.

#### K√∂zel√≠t≈ë Megold√°sok √©s Elemz√©sek

A h√°tizs√°k probl√©ma NP-teljes, teh√°t nincs ismert hat√©kony algoritmus az √∂sszes l√©tez≈ë eset megold√°s√°ra. Ez√©rt gyakran alkalmaznak k√∂zel√≠t≈ë algoritmusokat, amelyek garant√°lj√°k, hogy a tal√°lt megold√°s egy adott hat√°ron bel√ºl lesz az optim√°list√≥l.

##### Kerek√≠t√©si Heurisztika

A kerek√≠t√©si heurisztika egy egyszer≈± m√≥dszer a h√°tizs√°k probl√©ma k√∂zel√≠t≈ë megold√°s√°ra. Az al√°bbiakban ismertetj√ºk a m√≥dszert l√©p√©sr≈ël-l√©p√©sre:

1. **Relax√°ci√≥ √©s megold√°s:** El≈ësz√∂r a 0/1 h√°tizs√°k probl√©m√°t relax√°ljuk √∫gy, hogy enged√©lyezz√ºk a t√°rgyak r√©szleges kiv√°laszt√°s√°t is (vagyis $x_i \in [0, 1]$).
2. **Frakcion√°lis probl√©ma megold√°sa:** √çgy a probl√©m√°t egy line√°ris programoz√°si (LP) probl√©ma form√°j√°ban oldhatjuk meg.
3. **Kerek√≠t√©s:** Az LP megold√°sb√≥l sz√°rmaz√≥ frakcion√°lis √©rt√©keket eg√©sz √©rt√©kekk√© kerek√≠tj√ºk. K√ºl√∂nb√∂z≈ë kerek√≠t√©si strat√©gi√°k l√©teznek, de egy k√∂zismert m√≥dszer a k√∂vetkez≈ë:
   - Rendezze a t√°rgyakat az √©rt√©k/s√∫ly ar√°nyuk alapj√°n cs√∂kken≈ë sorrendben ($\frac{v_i}{w_i}$).
   - V√°lasszon addig teljes t√°rgyakat, am√≠g a h√°tral√©v≈ë kapacit√°s m√©g engedi.
   - Ha nem f√©r be t√∂bb teljes t√°rgy, v√°lasszuk ki a t√°rgyak azon r√©sz√©t, amely a h√°tral√©v≈ë kapacit√°st elfoglalja.

Ez az egyszer≈± kerek√≠t≈ë heurisztika √°ltal√°ban nagyon gyorsan ad egy j√≥ k√∂zel√≠t√©st, de nem mindig optim√°lis.

##### Greedy Megk√∂zel√≠t√©s

Egy m√°sik gyakran alkalmazott m√≥dszer a moh√≥ algoritmus (greedy algorithm). Ez hasonl√≥ a kerek√≠t√©si heurisztik√°hoz, de nem kell a frakcion√°lis probl√©m√°t megoldani el≈ësz√∂r.

1. Rendezze a t√°rgyakat az √©rt√©k/s√∫ly ar√°nyuk ($\frac{v_i}{w_i}$) alapj√°n cs√∂kken≈ë sorrendben.
2. Kezdje a legmagasabb ar√°ny√∫ t√°rggyal, √©s v√°lassza ki addig, am√≠g a kapacit√°s m√©g megengedi.
3. Addig ism√©telje, am√≠g a h√°tral√©v≈ë kapacit√°s engedi az √∫jabb t√°rgyak beilleszt√©s√©t.

Ennek a m√≥dszernek az id≈ëbeli bonyolults√°ga $O(n \log n)$ a rendez√©s miatt, de az eredm√©ny ellen≈ërz√©se line√°ris id≈ëben ($O(n)$) t√∂rt√©nik.

##### Dynamic Programming Megk√∂zel√≠t√©s

A dinamikus programoz√°s egy hat√©kony technika a h√°tizs√°k probl√©ma pontos megold√°s√°ra kicsi √©s k√∂zepes m√©ret≈± inputok eset√©n. Az alap√∂tlet az, hogy egy t√°bl√°zatot √©p√≠t√ºnk, amelyben minden mez≈ë a probl√©mat√©r egy r√©szprobl√©m√°j√°nak megold√°s√°t t√°rolja:

1. Defini√°lj egy $DP[i][w]$ t√°bl√°zatot, ahol $i$ jelent√©se az els≈ë $i$ t√°rgy figyelembe v√©tele, √©s $w$ jelent√©se a #s√∫lykapacit√°s#.
2. Inicializ√°l√°s: $DP[0][w] = 0$ minden $w$-re, √©s $DP[i][0] = 0$ minden $i$-re.
3. Iter√°ci√≥: T√∂ltsd fel a t√°bl√°zatot a t√°rgyak √©s a s√∫lyok alapj√°n.
4. Az optim√°lis megold√°st a $DP[n][W]$ mez≈ë fogja tartalmazni.

Az id≈ëbeli bonyolults√°g $O(nW)$, ami elfogadhat√≥, ha $W$ nem t√∫l nagy.

#### Eredm√©nyek √©s Elemz√©sek

##### Kerek√≠t√©si Heurisztika

A kerek√≠t√©si heurisztika √°ltal√°ban gyorsan tal√°l egy j√≥ k√∂zel√≠t√©st. Azonban nem garant√°lt, hogy az eredm√©ny optim√°lis, √©s n√©ha jelent≈ës elt√©r√©sek is lehetnek. Az algebrai elemz√©s sor√°n fontos megjegyezni, hogy a frakcion√°lis h√°tizs√°k probl√©ma optim√°lis megold√°sa biztos√≠tja, hogy a kerek√≠t√©si hib√°k ne legyenek t√∫l nagyok, k√ºl√∂n√∂sen, ha a t√°rgyak sz√°ma nagy, √©s az egyes t√°rgyak √©rt√©ke nem k√ºl√∂nb√∂zik jelent≈ësen.

##### Moh√≥ Algoritmus

A moh√≥ algoritmus egyszer≈±, de hat√©kony megold√°s, ami sok val√≥s alkalmaz√°sban k√∂zel optim√°lis eredm√©nyt ad. Az elm√©leti szempontb√≥l viszont fontos √©szrevenni, hogy ez a m√≥dszer is csak k√∂zel√≠t≈ë megold√°st biztos√≠t, √©s n√©h√°ny pazarl√°ssal j√°rhat. Az optim√°lis megold√°ssal val√≥ √∂sszehasonl√≠t√°s sor√°n √°ltal√°ban $O(\log n)$ ar√°nyt √©r el a teljes√≠tm√©ny.

##### Dinamikus Programoz√°s

A dinamikus programoz√°s alap√∫ megk√∂zel√≠t√©s pontos optim√°lis megold√°st biztos√≠t, de csak k√∂zepes m√©ret≈± h√°tizs√°k probl√©m√°k eset√©n hat√©kony. A magasabb m√©ret≈± (pl. t√∂bb ezer t√°rgy √©s s√∫ly) probl√©m√°kn√°l az id≈ë- √©s mem√≥riaig√©ny megugorhat, ami gyakorlati alkalmaz√°s sor√°n neh√©zs√©get okozhat.

### √ñsszegz√©s

A h√°tizs√°k probl√©ma egy √∂sszetett, de gyakorlati szempontb√≥l nagyon fontos probl√©ma, melynek gyors √©s hat√©kony k√∂zel√≠t≈ë megold√°saira nagy ig√©ny van. Az itt teltet√©sedik m√≥dszerek k√ºl√∂nb√∂z≈ë el≈ëny√∂kkel √©s h√°tr√°nyokkal rendelkeznek, melyeket az alkalmaz√°si kontextusban kell m√©rlegelni. Az optim√°lis megold√°s keres√©se helyett ezek a k√∂zel√≠t≈ë algoritmusok gyakran nagyon hasznosak lesznek val√≥s, nagy m√©ret≈± probl√©m√°k eset√©n.

A k√∂vetkez≈ë al√°bbi p√©ldak√≥d bemutatja a Greedy algoritmus megval√≥s√≠t√°s√°t C++ nyelven:

```cpp
#include <vector>
#include <iostream>
#include <algorithm>

struct Item {
    int value, weight;
    Item(int v, int w) : value(v), weight(w) {}
};

bool cmp(const Item &a, const Item &b) {
    double r1 = (double)a.value / a.weight;
    double r2 = (double)b.value / b.weight;
    return r1 > r2;
}

double knapsack(int W, std::vector<Item> &items) {
    std::sort(items.begin(), items.end(), cmp);
    int currentWeight = 0;
    double finalValue = 0.0;

    for (size_t i = 0; i < items.size(); i++) {
        if (currentWeight + items[i].weight <= W) {
            currentWeight += items[i].weight;
            finalValue += items[i].value;
        } else {
            int remain = W - currentWeight;
            finalValue += items[i].value * ((double)remain / items[i].weight);
            break;
        }
    }

    return finalValue;
}

int main() {
    int W = 50;  // Maximum weight of knapsack
    std::vector<Item> items = { {60, 10}, {100, 20}, {120, 30} };

    std::cout << "Maximum value in Knapsack = " << knapsack(W, items) << std::endl;
    return 0;
}
```

Ez a k√≥d a Greedy algoritmus megval√≥s√≠t√°s√°t tartalmazza, amely t√°rgyakat rangsorol az √©rt√©k/s√∫ly ar√°nyuk alapj√°n, majd kiv√°lasztja a legnagyobb ar√°ny√∫ t√°rgyakat eg√©szen a h√°tizs√°k kapacit√°s√°nak el√©r√©s√©ig.

## 2.2 K√∂zel√≠t≈ë megold√°sok √©s elemz√©sek

### 2.2.1 Bevezet√©s a K√∂zel√≠t≈ë Megold√°sokba

A k√∂zel√≠t≈ë algoritmusok c√©lja, hogy olyan megold√°sokat tal√°ljanak neh√©z optimaliz√°l√°si probl√©m√°kra, amelyek ‚Äûel√©g j√≥k‚Äù eredm√©nyt adnak elfogadhat√≥ fut√°si id≈ë alatt. Ezek a technik√°k k√ºl√∂n√∂sen fontosak az NP-teljes probl√©m√°k eset√©ben, ahol a pontos megold√°s megtal√°l√°sa exponenci√°lis l√©pt√©k≈± sz√°m√≠t√°si er≈ëforr√°sokat ig√©nyelhet. K√©t klasszikus p√©lda az NP-nehezen kezelhet≈ë probl√©m√°kra a H√°tizs√°k probl√©ma (Knapsack Problem) √©s az Utaz√≥ √úgyn√∂k Probl√©ma (Traveling Salesman Problem, TSP).

### 2.2.2 H√°tizs√°k Probl√©ma (Knapsack Problem)

#### 2.2.2.1 Probl√©maformul√°ci√≥

A h√°tizs√°k probl√©ma egy optimaliz√°l√°si probl√©ma, ahol adott egy h√°tizs√°k, amelynek maxim√°lis s√∫lyterhel√©se $W$. Tov√°bb√° rendelkez√©sre √°ll $n$ darab t√°rgy, melyek mindegyik√©hez tartozik egy $w_i$ s√∫ly √©s egy $v_i$ √©rt√©k. A c√©l az, hogy kiv√°lasszuk a t√°rgyak egy r√©szhalmaz√°t √∫gy, hogy azok √∂sszs√∫lya ne haladja meg a $W$-t, √©s a kiv√°lasztott t√°rgyak √∂ssz√©rt√©ke maxim√°lis legyen.

#### 2.2.2.2 K√∂zel√≠t≈ë Algoritmusok a H√°tizs√°k Probl√©m√°ra

##### 2.2.2.2.1 Greedy Algoritmus

A greedy (kapzsi) k√∂zel√≠t≈ë algoritmus egy intuit√≠v megk√∂zel√≠t√©s, amely minden iter√°ci√≥ban a ‚Äûlegjobbnak‚Äù t≈±n≈ë v√°laszt√°st teszi. Ebben az esetben a legjobb v√°laszt√°s az, hogy a t√°rgyakat az √©rt√©k-t√∂meg ar√°nyuk ($v_i/w_i$) alapj√°n rendezve v√°logassuk be a h√°tizs√°kba.

---
**Greedy Algoritmus Pseudok√≥d:**

```cpp
struct Item {
    int value, weight;
};

bool compare(Item a, Item b) {
    double r1 = (double)a.value / a.weight;
    double r2 = (double)b.value / b.weight;
    return r1 > r2;
}

double knapsackGreedy(int W, Item arr[], int n) {
    sort(arr, arr + n, compare);
    int currentWeight = 0;
    double finalValue = 0.0;

    for (int i = 0; i < n; i++) {
        if (currentWeight + arr[i].weight <= W) {
            currentWeight += arr[i].weight;
            finalValue += arr[i].value;
        } else {
            int remain = W - currentWeight;
            finalValue += arr[i].value * ((double)remain / arr[i].weight);
            break;
        }
    }
    return finalValue;
}
```

Ez az algoritmus gyorsan ad k√∂zel√≠t≈ë megold√°st, viszont nem garant√°lt, hogy a legjobbat ny√∫jtja minden esetben. Az eredm√©ny min≈ës√©ge f√ºgg az input param√©terekt≈ël √©s a t√°rgyak ar√°ny√°t√≥l.

##### 2.2.2.2.2 Dynamic Programming Relaxation

M√°sik k√∂zel√≠t≈ë strat√©gia a dinamikus programoz√°s haszn√°lata egy relax√°lt probl√©mav√°ltozattal. Ez esetben az optim√°lis bin√°ris d√∂nt√©sek helyett folytonos megk√∂zel√≠t√©st alkalmazunk.

#### 2.2.2.3 Elemz√©sek √©s √ârt√©kel√©sek

A greedy algoritmus teljes√≠tm√©ny√©t √°ltal√°ban akkor √©rt√©kelj√ºk, amikor az optim√°lis megold√°ssal hasonl√≠tjuk √∂ssze, leggyakrabban az ùù∞-approxim√°ci√≥ m√©r≈ësz√°mmal. Ezzel a m√≥dszerrel k√∂nnyen meg√©rthetj√ºk, hogyan viszonyul a k√∂zel√≠t≈ë megold√°s az optim√°lishoz.

---
**√Åltal√°nos P√©lda √©s Vizsg√°lat:**

1. H√°tizs√°k t√∂megkapacit√°s: $W = 50$
2. T√°rgyak list√°ja: $\{(value: 60, weight: 10), (value: 100, weight: 20), (value: 120, weight: 30)\}$

Az optim√°lis megold√°s ebben az esetben a $220$, m√≠g a greedy algoritmus kb. $240$ √©rt√©ket ny√∫jtana ugyanazon fel√°ll√°s mellett. Az eredm√©ny t√∫lbecsl√©se ugyan el≈ëfordulhat, de az algoritmus hat√©konys√°ga √©s gyorsas√°ga miatt nagyon gyakran haszn√°lt k√∂zel√≠t≈ë m√≥dszer.

### 2.2.3 Utaz√≥ √úgyn√∂k Probl√©ma (Traveling Salesman Problem)

#### 2.2.3.1 Probl√©maformul√°ci√≥

Az Utaz√≥ √úgyn√∂k Probl√©ma egy k√∂r√∫t megtervez√©s√©t foglalja mag√°ba, amely sor√°n az √ºgyn√∂k megl√°togat $n$ v√°rost, mindegyiket pontosan egyszer, √©s v√©g√ºl visszat√©r a kiindul√°si pontba. A c√©l az, hogy minimaliz√°ljuk a teljes megtett t√°vols√°got vagy k√∂lts√©get.

#### 2.2.3.2 K√∂zel√≠t≈ë Algoritmusok a TSP-re

##### 2.2.3.2.1 Nearest Neighbor Heurisztika

A Nearest Neighbor (legk√∂zelebbi szomsz√©d) algoritmus egy egyszer≈± √©s gyors heurisztikus m√≥dszer a TSP megold√°s√°ra. Ez az algoritmus mindig az aktu√°lisan legk√∂zelebbi v√°rost v√°lasztja a k√∂vetkez≈ë c√©lpontnak, amely m√©g nem lett l√°togatva.

---
**Nearest Neighbor Heurisztika Pseudok√≥d:**

```cpp
#include <iostream>
#include <vector>
#include <cmath>

struct Point {
    int x, y;
};

double calculateDistance(Point a, Point b) {
    return sqrt((a.x - b.x) * (a.x - b.x) + (a.y - b.y) * (a.y - b.y));
}

std::vector<int> nearestNeighborTSP(int n, Point points[]) {
    std::vector<int> tour;
    std::vector<bool> visited(n, false);

    int current = 0; 
    tour.push_back(current);
    visited[current] = true;

    for (int i = 1; i < n; i++) {
        double nearestDist = __DBL_MAX__;
        int nearest = -1;

        for (int j = 0; j < n; j++) {
            if (!visited[j] && calculateDistance(points[current], points[j]) < nearestDist) {
                nearestDist = calculateDistance(points[current], points[j]);
                nearest = j;
            }
        }

        current = nearest;
        tour.push_back(current);
        visited[current] = true;
    }

    return tour;
}
```

A Nearest Neighbor heurisztika gyorsan ad egy megold√°st, de nem felt√©tlen√ºl optim√°lis. Az eredm√©nyek √°ltal√°ban 25-50%-kal rosszabbak lehetnek, mint az optim√°lis megold√°s.

##### 2.2.3.2.2 Minimum Spanning Tree Heurisztika

Az MST (Minimum Spanning Tree) alap√∫ megk√∂zel√≠t√©s szint√©n egy gyakran haszn√°lt k√∂zel√≠t≈ë m√≥dszer. El≈ësz√∂r a v√°rosok k√∂z√∂tt fel√©p√≠tj√ºk a minim√°lis fesz√≠t≈ëf√°t, majd Preorder Walk algoritmussal k√∂rbej√°rjuk azt. 

---
**MST Heurisztika Pseudok√≥d:**

```cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <cmath>

struct Edge {
    int u, v;
    double weight;
};

struct Point {
    int x, y;
};

std::vector<Edge> primMST(int n, std::vector<std::vector<double>>& graph) {
    std::vector<bool> inMST(n, false);
    std::vector<Edge> edges;
    std::vector<double> key(n, __DBL_MAX__);
    std::vector<int> parent(n, -1);

    key[0] = 0.0;

    for (int count = 0; count < n - 1; count++) {
        double minKey = __DBL_MAX__;
        int u;

        for (int v = 0; v < n; v++) {
            if (!inMST[v] && key[v] < minKey) {
                minKey = key[v];
                u = v;
            }
        }

        inMST[u] = true;

        for (int v = 0; v < n; v++) {
            if (graph[u][v] && !inMST[v] && graph[u][v] < key[v]) {
                key[v] = graph[u][v];
                parent[v] = u;
            }
        }
    }

    for (int i = 1; i < n; i++) {
        edges.push_back({parent[i], i, graph[i][parent[i]]});
    }

    return edges;
}
```

Ez az algoritmus garant√°ltan ad egy k√∂zel√≠t≈ë megold√°st, amely legfeljebb k√©tszerese az optim√°lis megold√°snak (2-approximation).

#### 2.2.3.3 Elemz√©sek √©s √ârt√©kel√©sek

A k√∂zel√≠t≈ë algoritmusok teljes√≠tm√©nye az Utaz√≥ √úgyn√∂k Probl√©ma eset√©ben t√∂bb param√©ter f√ºggv√©nye, p√©ld√°ul a v√°rosok t√°vols√°gait√≥l √©s geometriai elhelyezked√©s√©t≈ël. Emellett a runtime komplexit√°s √©s a mem√≥ria ig√©nyek is fontos szempontok. A teoretikus garanci√°k k√∂z√ºl kiemelhet≈ë, hogy az MST-heurisztika mindig legfeljebb k√©tszeres k√∂lts√©g≈± megold√°st ad.

### 2.2.4 K√∂vetkeztet√©sek √©s Z√°r√≥ Gondolatok

A k√∂zel√≠t≈ë algoritmusok kulcsszerepet j√°tszanak a val√≥s √©letben alkalmazott sz√°m√≠t√≥g√©pes megold√°sokban, k√ºl√∂n√∂sen az NP-nehezen kezelhet≈ë probl√©m√°k eset√©ben. Hab√°r nem mindig adnak optim√°lis megold√°st, gyakorlatias megk√∂zel√≠t√©st ny√∫jtanak, amely gyakran elegend≈ë a t√©nyleges alkalmaz√°si ter√ºleteken. Az ilyen algoritmusok tanulm√°nyoz√°sa √©s fejleszt√©se folyamatosan fontos kutat√°si ter√ºletet k√©pez az algorithmikus elm√©leti √©s gyakorlati sz√°m√≠t√°stechnika k√∂z√∂ss√©geiben.

## 2. Klasszikus k√∂zel√≠t≈ë algoritmusok

A modern sz√°m√≠t√°stechnika √©s az optimaliz√°l√°si probl√©m√°k vil√°g√°ban sz√°mos kih√≠v√°ssal tal√°lkozunk, amelyek megold√°sa rendk√≠v√ºl sz√°m√≠t√°sig√©nyes lehet. K√©t ilyen jelent≈ës probl√©ma a H√°tizs√°k probl√©ma (Knapsack Problem) √©s az Utaz√≥ √ºgyn√∂k probl√©ma (Traveling Salesman Problem, TSP). Ezen fejezet a TSP-re √∂sszpontos√≠t, r√©szletesen ismertetve a probl√©m√°t, a k√∂zel√≠t≈ë megold√°sokat, a heurisztik√°kat √©s az elemz√©sek m√≥dszereit.

### Utaz√≥ √ºgyn√∂k probl√©ma (Traveling Salesman Problem)

#### Probl√©ma defin√≠ci√≥ja

Az Utaz√≥ √ºgyn√∂k probl√©ma (TSP) egy j√≥l ismert kombinatorikai optimaliz√°l√°si k√©rd√©s, amelyet el≈ësz√∂r Karl Menger mutatott be a 1930-as √©vekben. A probl√©ma l√©nyege, hogy adott egy √ºgyn√∂k, aki be szeretn√© j√°rni N v√°rost √∫gy, hogy minden v√°rost pontosan egyszer l√°togat meg, √©s √∫tja v√©g√©n visszat√©r a kiindul√≥pontba. Az √ºgyn√∂k c√©lja az, hogy a legr√∂videbb utat tal√°lja meg.

Form√°lisan az TSP a k√∂vetkez≈ëk√©ppen √≠rhat√≥ le:
- Van egy v√°rosokat reprezent√°l√≥ $V = {v_1, v_2, ..., v_n}$ halmaz.
- Az √∂sszes v√°ros k√∂z√∂tt l√©tez≈ë t√°vols√°gokat ad√≥ $D = {d_{ij}}$ m√°trix, ahol $d_{ij}$ a $v_i$ √©s $v_j$ v√°rosok k√∂z√∂tti t√°vols√°g.

A c√©l az, hogy tal√°ljunk egy olyan permut√°ci√≥t $\pi$ az $1, 2, ..., n$ sz√°mok k√∂z√ºl, amely minimaliz√°lja az al√°bbi k√∂lts√©gf√ºggv√©nyt:
$$ C(\pi) = \sum_{i=1}^{n-1} d_{\pi(i), \pi(i+1)} + d_{\pi(n), \pi(1)} $$

#### NP-teljess√©g

A TSP probl√©m√°nak sz√°mos v√°ltozata l√©tezik, pl. az euklideszi TSP (ahol a v√°rosok az Euklideszi s√≠kon helyezkednek el), a szimmetrikus TSP (ahol minden t√°vols√°g szimmetrikus, azaz $d_{ij} = d_{ji}$), √©s az aszimmetrikus TSP. F√ºggetlen√ºl att√≥l, hogy melyik v√°ltozatr√≥l van sz√≥, a TSP probl√©m√°k √°ltal√°noss√°gban NP-teljesek. Ez azt jelenti, hogy nincs ismert polinomi√°lis idej≈± algoritmus, amely mindig optim√°lis megold√°st tal√°lna.

#### K√∂zel√≠t≈ë megold√°sok √©s heurisztik√°k

Mivel a TSP NP-teljes probl√©mak√©nt megoldhatatlan nagyobb m√©ret≈± instanci√°kra hagyom√°nyos, pontos m√≥dszerekkel, ez√©rt k√ºl√∂nb√∂z≈ë k√∂zel√≠t≈ë algoritmusokra √©s heurisztik√°kra t√°maszkodunk. A k√∂zel√≠t≈ë algoritmusok c√©lja, hogy hat√©konyan ny√∫jtsanak j√≥, b√°r nem felt√©tlen√ºl optim√°lis megold√°sokat.

##### Nearest Neighbor Heurisztika

Az egyik legegyszer≈±bb heurisztika, amely k√∂nnyen implement√°lhat√≥ √©s gyakran gyorsan j√≥ megold√°sokat ad, a Nearest Neighbor (NN) algoritmus:

1. V√°lassz egy kezd≈ë v√°rost (√°ltal√°ban v√©letlenszer≈±en).
2. Ism√©teld meg a k√∂vetkez≈ë l√©p√©seket, am√≠g minden v√°rost be nem j√°rtunk:
   - Az aktu√°lis v√°rosb√≥l v√°laszd a legk√∂zelebbi, m√©g nem l√°togatott v√°rost.
   - L√©pj √°t ebbe a v√°rosba.
3. T√©rj vissza a kiindul√≥pontba.

Ez a heurisztika gyorsan m≈±k√∂dik, de a kapott √∫tvonal t√°vol √°llhat az optim√°list√≥l. Nem garant√°lt pl. az $O(n)$ k√∂zel√≠t√©s.

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <algorithm>

struct City {
    int x, y;
    bool visited = false;
};

double distance(const City& a, const City& b) {
    return std::sqrt(std::pow(a.x - b.x, 2) + std::pow(a.y - b.y, 2));
}

std::vector<int> nearest_neighbor(const std::vector<City>& cities) {
    int num_cities = cities.size();
    std::vector<int> tour;
    std::vector<City> to_visit = cities;
    tour.reserve(num_cities);
    
    int current_index = 0;
    tour.push_back(current_index);
    to_visit[current_index].visited = true;

    for (int i = 1; i < num_cities; ++i) {
        double min_dist = std::numeric_limits<double>::max();
        int next_city = -1;

        for (int j = 0; j < num_cities; ++j) {
            if (!to_visit[j].visited && distance(to_visit[current_index], to_visit[j]) < min_dist) {
                min_dist = distance(to_visit[current_index], to_visit[j]);
                next_city = j;
            }
        }

        current_index = next_city;
        to_visit[current_index].visited = true;
        tour.push_back(current_index);
    }

    return tour;
}

int main() {
    std::vector<City> cities = {{0, 0}, {1, 3}, {4, 3}, {6, 1}};
    std::vector<int> tour = nearest_neighbor(cities);

    std::cout << "Tour: ";
    for (int city : tour) {
        std::cout << city << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

##### Minimum Spanning Tree Heurisztika (MST Heuristic)

A Minimum Spanning Tree (MST) heurisztika szint√©n n√©pszer≈± megk√∂zel√≠t√©st ny√∫jt a TSP probl√©m√°ra. Az algoritmus sor√°n az al√°bbi l√©p√©seket tessz√ºk:

1. Hozzunk l√©tre egy s√∫lyozott gr√°fot, ahol a v√°rosok cs√∫csok, √©s az √©lek s√∫lya megegyezik a v√°rosok k√∂z√∂tti t√°vols√°ggal.
2. Az √©lek k√∂z√ºl v√°lasszuk ki azokat, amelyek alkotj√°k a grafo minimumk√∂lts√©g≈± fesz√≠t≈ëf√°j√°t (MST) ‚Äì haszn√°lhatunk p√©ld√°ul Kruskal vagy Prim algoritmus√°t.
3. V√©gezett√ºl haszn√°ljunk egy preorder bej√°r√°st az MST-n az √∫thoz.

Ez a heurisztika garant√°lja, hogy a megtal√°lt √∫t hossza legfeljebb k√©tszerese lesz az optim√°lis √∫t hossz√°nak ($3/2$ k√∂zel√≠t√©s≈± megold√°st is el√©rhet speci√°lis esetekben).

##### K√©tszeres Fa Heurisztika (Double Tree Heuristic)

Ez a heurisztika egy $2$-approximation megold√°st szolg√°ltat, √©s az al√°bbi l√©p√©seket k√∂veti:

1. √âp√≠ts√ºnk egy MST-t a v√°rosok k√∂z√∂tt.
2. K√©sz√≠ts√ºnk egy olyan gr√°fot, ahol minden √©l megdupl√°z√≥dik.
3. Keress√ºnk egy Euler-k√∂rt ebben a gr√°fban.
4. Haszn√°ljunk shortcutokat az Euler-k√∂rb≈ël egy ciklushoz, amely minden v√°roson csak egyszer halad √°t.

Ez szint√©n egyszer≈±en implement√°lhat√≥ √©s gyors megold√°st szolg√°ltat plan√°ris gr√°fok eset√©n.

##### Genetikus Algoritmusok (GA) √©s Egy√©b Metaheurisztik√°k

A metaheurisztik√°kat, mint a Genetikus Algoritmusok (GA), a Szimul√°lt Leh≈±l√©s (Simulated Annealing), √©s a Tabu keres√©s (Tabu Search), szint√©n gyakran haszn√°ljuk a TSP probl√©m√°k k√∂zel√≠t≈ë megold√°s√°ra.

- **Genetikus Algoritmusok (GA)**: A GA olyan evolv√∫ci√≥s megk√∂zel√≠t√©st alkalmaz, amelyben egy popul√°ci√≥ k√ºl√∂nb√∂z≈ë megold√°si pr√≥b√°lkoz√°sokb√≥l √°ll, √©s ez a popul√°ci√≥ gener√°ci√≥kon kereszt√ºl fejl≈ëdik a term√©szetes kiv√°laszt√≥d√°s, keresztbekombin√°ci√≥ √©s mut√°ci√≥ r√©v√©n.
- **Szimul√°lt Leh≈±l√©s**: Ez az algoritmus a termodinamikai modellez√©s ihlette, ahol a rendszer leh≈±l√©s√©ben a r√©szletek cser√©l≈ëdnek, hogy min√©l optim√°lisabb energetikai √°llapotba ker√ºlj√∂n a rendszer.
- **Tabu keres√©s**: Ez a m√≥dszer az aktu√°lis √∂tletek c√©lzott helyekre koll√°tozott kutat√°s√°t v√©gzi, mik√∂zben elker√ºli a kor√°bban m√°r felfedezett, √©s rossz min≈ës√©g≈± megold√°sok ism√©telt vizsg√°lat√°t.

A fent eml√≠tett k√∂zel√≠t≈ë megold√°sok √©s heurisztik√°k mindegyike k√ºl√∂nb√∂zik a sz√°m√≠t√°si id≈ë, a bonyolults√°g √©s a kapott megold√°sok min≈ës√©ge szempontj√°b√≥l. Nincs egyetlen ‚Äúlegjobb‚Äù algoritmus, amely minden esetben a t√∂k√©letes v√°laszt√°s volna, a probl√©ma nagys√°g√°t√≥l, a konkr√©t implement√°ci√≥s k√∂vetelm√©nyekt≈ël √©s a k√∂rnyezeti felt√©telekt≈ël f√ºgg≈ëen v√°ltozik, melyik megk√∂zel√≠t√©s a legmegfelel≈ëbb.

### K√∂vetkeztet√©s

Az utaz√≥ √ºgyn√∂k probl√©m√°j√°nak fontoss√°ga a kombinatorikai optimaliz√°l√°s ter√ºlet√©n nem vitathat√≥. Sz√°mos gyakorlati alkalmaz√°ssal b√≠r, bele√©rtve a logisztik√°t, a t√©rk√©pez√©st √©s a gy√°rt√°soptimaliz√°l√°st. Hab√°r a probl√©ma megold√°sa NP-teljes, sz√°mos k√∂zel√≠t≈ë algoritmus √©s heurisztika √°ll rendelkez√©sre, amelyek praktikus megold√°sokat ny√∫jtanak a k√ºl√∂nf√©le feladatok v√©grehajt√°s√°hoz. Ezek k√∂z√ºl a Nearest Neighbor, a Minimum Spanning Tree Heurisztika √©s a Genetikus Algoritmusok nagy n√©pszer≈±s√©gnek √∂rvendenek az optimaliz√°l√°s k√ºl√∂nb√∂z≈ë ter√ºletein.

### 2. Klasszikus k√∂zel√≠t≈ë algoritmusok

#### Utaz√≥ √ºgyn√∂k probl√©ma (Traveling Salesman Problem)
##### Heurisztik√°k √©s k√∂zel√≠t≈ë megold√°sok

Az utaz√≥ √ºgyn√∂k probl√©ma (Traveling Salesman Problem, TSP) az egyik legismertebb NP-teljes optimaliz√°l√°si probl√©ma, amely sokf√©le gyakorlati alkalmaz√°ssal rendelkezik, mint a logisztika, a gy√°rt√°s √©s az √°ramk√∂r√∂k tervez√©se. A probl√©m√°t √°ltal√°ban √∫gy defini√°lj√°k, hogy adott egy sor v√°ros √©s azok k√∂z√∂tti t√°vols√°gok, egy olyan utaz√°si √∫tvonalat kell megadni, amely minden v√°rost pontosan egyszer √©rint, √©s visszat√©r a kiindul√°si v√°rosba, mik√∂zben minimaliz√°lja az √∂sszes megtett t√°vols√°got.

Mivel a TSP pontos megold√°sa sok esetben sz√°m√≠t√°silag megval√≥s√≠thatatlan, k√ºl√∂n√∂sen nagy v√°rossz√°m eset√©n, a k√∂zel√≠t≈ë algoritmusok √©s heurisztik√°k sz√©les k√∂rben alkalmazottak a probl√©ma megold√°s√°ra.

###### 2.1. Heurisztikus megk√∂zel√≠t√©sek

A heurisztikus megk√∂zel√≠t√©sek egyszer≈± √©s gyors algoritmusok, amelyek nem garant√°lnak optim√°lis, de √°ltal√°ban j√≥ min≈ës√©g≈± megold√°sokat. N√©h√°ny alapvet≈ë heurisztikus algoritmus a TSP-re vonatkoz√≥an:

**Legk√∂zelebbi szomsz√©d (Nearest Neighbor, NN)**:
Az algoritmus minden l√©p√©sben mindig azt a v√°rost v√°lasztja, amelyik a legk√∂zelebb van az aktu√°lis v√°roshoz, addig, am√≠g az √∂sszes v√°rost be nem j√°rja.

**Legk√∂zelebbi szomsz√©d algoritmus:**
1. Kezdje az els≈ë v√°rosban.
2. Addig ism√©telje, am√≠g minden v√°rost be nem j√°rt:
    - V√°lassza a legk√∂zelebbi, m√©g nem l√°togatott v√°rost.
3. T√©rjen vissza a kiindul√°si v√°rosba.

**Voronoi diagram √©s legk√∂zelebbi szomsz√©d alkalmaz√°s√°val:**

```cpp
#include <iostream>
#include <vector>
#include <cmath>
#include <limits>

struct City {
    int x, y;
};

double distance(const City& a, const City& b) {
    return std::sqrt((a.x - b.x)*(a.x - b.x) + (a.y - b.y)*(a.y - b.y));
}

std::vector<int> nearestNeighbor(const std::vector<City>& cities) {
    int n = cities.size();
    std::vector<bool> visited(n, false);
    std::vector<int> tour;
    tour.push_back(0);  // starting from the first city
    visited[0] = true;

    for (int i = 0; i < n - 1; ++i) {
        int last = tour.back();
        int nextCity = -1;
        double minDist = std::numeric_limits<double>::infinity();

        for (int j = 0; j < n; ++j) {
            if (!visited[j]) {
                double dist = distance(cities[last], cities[j]);
                if (dist < minDist) {
                    minDist = dist;
                    nextCity = j;
                }
            }
        }
        visited[nextCity] = true;
        tour.push_back(nextCity);
    }

    tour.push_back(0);  // return to the starting city
    return tour;
}

int main() {
    std::vector<City> cities = {{0, 0}, {1, 2}, {4, 3}, {5, 5}, {8, 8}};  // example cities
    std::vector<int> tour = nearestNeighbor(cities);

    std::cout << "Tour: ";
    for (int c : tour) {
        std::cout << c << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

A Legk√∂zelebbi szomsz√©d algoritmus nagyon gyors, de az eredm√©ny min≈ës√©ge nagyon f√ºgg a kezd≈ëv√°ros kiv√°laszt√°s√°t√≥l, √©s lehetnek nagyon rossz eredm√©nyei is, ha a v√°rosok elhelyezked√©se nem egyenletes.

**Legolcs√≥bb besz√∫r√°s (Cheapest Insertion)**:
Az algortimus mindig azt a v√°rost sz√∫rja be az aktu√°lis r√©sz-utaz√°si √∫tvonalba, amelyiknek ez a besz√∫r√°sa a legolcs√≥bb lesz (a legkevesebbet n√∂veli az √∂sszt√°vols√°got).

**Legolcs√≥bb besz√∫r√°s algoritmus l√©p√©sei:**
1. Kezdjen egy tetsz≈ëleges v√°rossal.
2. Addig ism√©telje, am√≠g minden v√°rost be nem sz√∫rt az √∫tvonalba:
    - V√°lassza ki a legolcs√≥bb besz√∫r√°st (olyan v√°rost, amely besz√∫r√°sa minim√°lis k√∂lts√©gn√∂veked√©st jelent).
3. T√©rjen vissza a kiindul√°si v√°rosba.

**P√©lda legolcs√≥bb besz√∫r√°s heurisztik√°ra:**

```cpp
std::vector<int> cheapestInsertion(const std::vector<City>& cities) {
    int n = cities.size();
    std::vector<bool> visited(n, false);
    std::vector<int> tour = {0};
    visited[0] = true;

    int bestNext = 1;
    for (int i = 2; i < n; ++i) {
        if (distance(cities[0], cities[i]) < distance(cities[0], cities[bestNext])) {
            bestNext = i;
        }
    }
    tour.insert(tour.end(), {bestNext, 0});
    visited[bestNext] = true;

    for (int i = 1; i < n - 1; ++i) {
        int bestCity = -1;
        int bestPos = -1;
        double bestCost = std::numeric_limits<double>::infinity();

        for (int j = 1; j < n; ++j) {
            if (!visited[j]) {
                for (int k = 0; k < tour.size() - 1; ++k) {
                    double cost = distance(cities[tour[k]], cities[j]) +
                                  distance(cities[j], cities[tour[k + 1]]) -
                                  distance(cities[tour[k]], cities[tour[k + 1]]);
                    if (cost < bestCost) {
                        bestCity = j;
                        bestPos = k;
                        bestCost = cost;
                    }
                }
            }
        }
        
        tour.insert(tour.begin() + bestPos + 1, bestCity);
        visited[bestCity] = true;
    }

    return tour;
}

// A Main function to demonstrate the Cheapest insertion method
int main() {
    std::vector<City> cities = {{0, 0}, {1, 2}, {4, 3}, {5, 5}, {8, 8}};  // example cities
    std::vector<int> tour = cheapestInsertion(cities);

    std::cout << "Tour: ";
    for (int c : tour) {
        std::cout << c << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

**Minim√°lis √ñsszef√ºgg≈ë Fa (MST) alap√∫ algoritmusok**:
Az MST-alap√∫ algoritmus egy minim√°lis fesz√≠t≈ëf√°t (Minimum Spanning Tree, MST) alkot a v√°rosok k√∂z√∂tt, majd azt egy √∫n. preorder t√°vj√°val (preorder walk) j√°rja v√©gig. Ez a heurisztika 2-hez k√∂zel√°ll√≥ megold√°st ad a k√∂r√ºl j√°r√≥ elj√°r√°sokban.

**MST-alap√∫ algoritmus l√©p√©sei::**
1. K√©sz√≠tsen egy minim√°lis fesz√≠t≈ëf√°t a v√°rosok k√∂z√∂tt.
2. Hajtsa v√©gre a preorder t√°v √∂ssze√°ll√≠t√°st az MST-n.
3. Z√°rja le a t√°vot a kezd≈ë v√°ros-ba val√≥ visszat√©r√©ssel.

A k√∂zel√≠t≈ë algoritmusok lehet≈ëv√© t√©tele mellett a metaheurisztik√°k is sz√©les k√∂rben alkalmazottak a TSP-hez, ahol c√©ljuk az, hogy egy kezd≈ë heurisztikus megold√°s min≈ës√©g√©t jav√≠ts√°k k√ºl√∂nb√∂z≈ë m√≥dszerekkel.

##### Metaheurisztik√°k

A metaheurisztik√°k √°ltal√°nos optim√°lis keres√©si m√≥dszerek, amelyek c√©lja a j√≥ min≈ës√©g≈± megold√°sok megtal√°l√°sa elfogadhat√≥ sz√°m√≠t√°si id≈ë mellett. N√©h√°ny p√©lda a TSP-hez alkalmazott metaheurisztik√°k k√∂z√ºl:

**Simulated Annealing (Szimul√°lt Edz√©s)**:
A TSP egy lok√°l√≥ minimum elker√ºl√©s√©re haszn√°lt metaheurisztika, amely a termodinamika h≈ëm√©rs√©kletgr√°dienseivel anal√≥g.

**Simulated Annealing algoritmus:**
1. V√°lasszon egy kezd≈ë megold√°st s.
2. Ism√©telje a k√∂vetkez≈ë l√©p√©seket a h≈ëm√©rs√©klet T cs√∂kkent√©se mellett:
   - Gener√°ljon egy szomsz√©dos megold√°st, s'.
   - Fogadja el s'-et k√∂vetkez≈ë megold√°sk√©nt bizonyos val√≥sz√≠n≈±s√©ggel, amely a T-vel cs√∂kken.
3. Visszat√©r s'-hez.

A szimul√°lt edz√©s alapelve az energetikai minimum keret√©nek hat√©kony t√©r√©se.

**Genetikus Algoritmusok**:
A Genetikus Algoritmusok (GA) a biol√≥giai evol√∫ci√≥ra alapozva √∫gy m≈±k√∂dnek, hogy popula√°ci√≥kat v√©grehajtanak a keresztez≈ëd√©s √©s mut√°ci√≥ r√©v√©n.

**Genetikus algoritmus l√©p√©sei:**
1. Kezdjen egy kezdeti popul√°ci√≥ l√©trehoz√°s√°val.
2. Addig ism√©telje, am√≠g nem teljes√≠ti az elv√°rt meg√°ll√°si felt√©teleket:
    - Keresztezze, v√°lasszon a megl√©v≈ë egyedekb≈ël.
    - Alkalmazza a mut√°ci√≥kat v√©letlenszer≈±en.
3. V√°lassza ki a legjobb megold√°sokat.

**V√°rosok keresztez√©se TSP-ben (Crossover in GA for TSP):**

```cpp
// Define a structure to hold the population and solutions
struct Solution {
    std::vector<int> tour;
    double cost;
};

// Implement a function to initialize the population
std::vector<Solution> initializePopulation(const std::vector<City>& cities, int populationSize) {
    std::vector<Solution> population;
    // Initialize population with random tours
    for (int i = 0; i < populationSize; ++i) {
        std::vector<int> tour(cities.size());
        std::iota(tour.begin(), tour.end(), 0);
        std::random_shuffle(tour.begin(), tour.end());
        double cost = calculateTourCost(cities, tour);
        population.push_back({tour, cost});
    }
    return population;
}

// Implement a function to calculate the tour cost
double calculateTourCost(const std::vector<City>& cities, const std::vector<int>& tour) {
    double cost = 0;
    for (size_t i = 0; i < tour.size() - 1; ++i) {
        cost += distance(cities[tour[i]], cities[tour[i + 1]]);
    }
    cost += distance(cities[tour.back()], cities[tour[0]]);
    return cost;
}

// Define a mutation function for the GA
void mutate(std::vector<int>& tour) {
    int n = tour.size();
    int i = rand() % n;
    int j = rand() % n;
    std::swap(tour[i], tour[j]);
}

// Implement the main genetic algorithm function
std::vector<int> geneticAlgorithm(const std::vector<City>& cities, int populationSize, int generations) {
    std::vector<Solution> population = initializePopulation(cities, populationSize);

    for (int generation = 0; generation < generations; ++generation) {
        // Perform crossover and mutation to create new population
        std::vector<Solution> newPopulation;
        for (int i = 0; i < populationSize; ++i) {
            int parent1Index = rand() % populationSize;
            int parent2Index = rand() % populationSize;

            std::vector<int> childTour = crossover(population[parent1Index].tour, population[parent2Index].tour);
            mutate(childTour);

            double childCost = calculateTourCost(cities, childTour);
            newPopulation.push_back({childTour, childCost});
        }

        // Select the best solutions to form the new population
        sort(newPopulation.begin(), newPopulation.end(), [](const Solution& a, const Solution& b) {
            return a.cost < b.cost;
        });

        population = newPopulation;
    }

    return population.front().tour;
}

// Main function to use the genetic algorithm
int main() {
    std::vector<City> cities = {{0, 0}, {1, 2}, {4, 3}, {5, 5}, {8, 8}};  // example cities

    int populationSize = 50;
    int generations = 100;

    std::vector<int> bestTour = geneticAlgorithm(cities, populationSize, generations);

    std::cout << "Best Tour: ";
    for (int city : bestTour) {
        std::cout << city << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

A heurisztik√°k, k√∂zt√ºk a legk√∂zelebbi szomsz√©d, a legolcs√≥bb besz√∫r√°s √©s MST-alap√∫ megk√∂zel√≠t√©sek alapvet≈ë m√≥don alkalmazhat√≥k a TSP-re gyors √©s elfogadhat√≥ megold√°sok megtal√°l√°s√°ra. Ezenk√≠v√ºl a metaheurisztikus m√≥dszerek, mint a szimul√°lt edz√©s √©s genetikus algoritmusok mintav√©telez√©se jobb eredm√©nyeket ny√∫jthatnak a keres√©si t√©r optimaliz√°l√°s√°ban. A tov√°bbi kutat√°s √©s fejleszt√©s ezen algoritmusokban √©s szerkezetekben magas szint≈± eredm√©nyeket √°ll√≠t fel, relevanci√°t jelezve a re√°lis vil√°g sz√°mtalan feladat√°ban, p√©ld√°ul a logisztik√°ban, gy√°rt√°sban √©s √∫tvonal tervez√©sben.

A fenti integr√°lt algoritmusok √©s m√≥dszertanok elismer√©se √©s alkalmaz√°sa alapvet≈ë fontoss√°g√∫ TSP vari√°nsok √©s azok modellez√©si, elemz√©si teljes√≠tm√©nyek optimaliz√°l√°s√°nak √©rdek√©ben.

