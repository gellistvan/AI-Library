\newpage

## 6.2. Veszteségmentes adatkompressziós algoritmusok

Az információ hatékony tárolása és átvitele napjaink egyik legfontosabb kihívása lett, különösen a digitális korszakban, ahol az adatfolyamok folyamatosan növekvő mennyisége könnyen túlterheli a rendelkezésre álló erőforrásokat. Veszteségmentes adatkompressziós algoritmusok nélkülözhetetlen eszközként szolgálnak ebben a kontextusban, mivel lehetővé teszik az adatok olyan módon történő tömörítését, hogy az eredeti információ sértetlen maradjon és teljesen visszaállítható legyen. Ebben a fejezetben három meghatározó veszteségmentes kompressziós technikát vizsgálunk meg: a Huffman kódolást, az LZ77 és LZ78 algoritmusokat, valamint a Lempel-Ziv-Welch (LZW) módszert. Ezen algoritmusok áttekintésével megérthetjük, hogyan képesek optimalizálni a tárhely és adatátvitel hatékonyságát anélkül, hogy veszélyeztetnék az eredeti információ integritását.

### Huffman kódolás

A Huffman kódolás egy veszteségmentes adatkompressziós eljárás, amelyet David A. Huffman fejlesztett ki 1952-ben. Ez az algoritmus alapvető eszköze az adatok tömörítésének, és széles körben alkalmazzák különböző adattömörítési rendszerekben és fájlformátumokban. Az algoritmus alapja a karakterek előfordulási valószínűségeinek elemzése és ennek megfelelően változó hosszúságú kódszavak hozzárendelése minden egyes karakterhez. Ebben a fejezetben részletesen megvizsgáljuk a Huffman kódolás elméleti hátterét, működését és alkalmazását.

#### 1. Elméleti háttér

A Huffman kódolás a prefix kódok egy speciális esete. A prefix kódok olyan kódrendszerek, ahol egyetlen kódszó sem lehet egy másik kódszó előtagja. Ez lehetővé teszi a kód egyértelmű és hatékony dekódolását, mivel minden karakter kódja egyszerűen és egyértelműen azonosítható.

A Huffman kódolás fő célja, hogy minimális hosszúságú bináris kódokat rendeljen a karakterekhez úgy, hogy a gyakrabban előforduló karakterek rövidebb kódokat kapjanak, míg a ritkábban előforduló karakterek hosszabb kódokat. Ezzel a módszerrel az átlagos kódhosszúság minimalizálható.

#### 2. Huffman kódolás lépései

A Huffman kódolási algoritmus a következő lépéseken keresztül hajtja végre a tömörítést:

1. **Frekvencia-táblázat létrehozása**: A bemeneti adatokat feldolgozva meghatározzuk minden egyes karakter előfordulási gyakoriságát.

2. **Prioritási sor létrehozása**: A karaktereket és azok gyakoriságait egy prioritási sorban (általában egy minimum prioritási kupacban) rendezzük el, ahol az elemeket a karakterek gyakorisága szerint válogatjuk.

3. **Bináris fa építése**: Az elemeket összefűzve egy bináris fát építünk. Minden lépésben a két legkisebb gyakoriságú elemet vesszük ki a prioritási sorból, és egy új csomópontot hozunk létre úgy, hogy ezek összege képzi az új csomópont gyakoriságát. Ezután az új csomópontot visszahelyezzük a prioritási sorba. Addig folytatjuk ezt a folyamatot, amíg csak egy elem marad a sorban, amely a bináris fa gyökércsomópontja lesz.

4. **Kódfák hozzárendelése**: Az elkészült bináris fa alapján a karakterekhez bináris kódokat rendelünk. A bal oldali ág általában '0'-át, míg a jobb oldali ág '1'-et kap.

#### 3. Huffman fa példája

Tekintsük a következő karakterek gyakoriságait egy egyszerű példában:

| Karakter | Gyakoriság |
|----------|------------|
| A        | 45         |
| B        | 13         |
| C        | 12         |
| D        | 16         |
| E        | 9          |
| F        | 5          |

Az algoritmus a következő lépéseken keresztül építi fel a Huffman fát:
   
1. Prioritási sor kezdeti állapota:

    ```
    (F, 5), (E, 9), (C, 12), (B, 13), (D, 16), (A, 45)
    ```

2. Első lépés: Összevonjuk az 'F' és 'E' karaktereket:

    ```
    (C, 12), (B, 13), (D, 16), (A, 45), (EF, 14)
    ```

3. Második lépés: Összevonjuk a 'C' és 'B' karaktereket:

    ```
    (D, 16), (EF, 14), (CB, 25), (A, 45)
    ```

4. Harmadik lépés: Összevonjuk a 'D' és 'EF' karaktereket:

    ```
    (CB, 25), (DEF, 30), (A, 45)
    ```

5. Negyedik lépés: Összevonjuk a 'CB' és 'DEF' karaktereket:

    ```
    (A, 45), (CBDEF, 55)
    ```

6. Ötödik lépés: Összevonjuk az 'A' és 'CBDEF' karaktereket:

    ```
    (ACBDEF, 100)
    ```

A kapott fa alapján a következő kódokat rendeljük a karakterekhez:
- 'A': 0
- B: 101
- C: 100
- D: 111
- E: 1101
- F: 1100

#### 4. Huffman kódolás implementációja C++ nyelven

Az alábbiakban bemutatjuk a Huffman kódolási algoritmus egy lehetséges implementációját C++ nyelven:

```cpp
#include <iostream>
#include <queue>
#include <unordered_map>
#include <vector>

using namespace std;

struct HuffmanNode {
    char character;
    int frequency;
    HuffmanNode* left;
    HuffmanNode* right;

    HuffmanNode(char character, int frequency) {
        this->character = character;
        this->frequency = frequency;
        left = right = nullptr;
    }
};

struct Compare {
    bool operator()(HuffmanNode* a, HuffmanNode* b) {
        return a->frequency > b->frequency;
    }
};

void encode(HuffmanNode* root, string str, unordered_map<char, string>& huffmanCode) {
    if (root == nullptr) return;

    if (root->left == nullptr && root->right == nullptr) {
        huffmanCode[root->character] = str;
    }

    encode(root->left, str + "0", huffmanCode);
    encode(root->right, str + "1", huffmanCode);
}

void decode(HuffmanNode* root, int& index, string str) {
    if (root == nullptr) return;
    if (root->left == nullptr && root->right == nullptr) {
        cout << root->character;
        return;
    }

    index++;
    if (str[index] == '0') decode(root->left, index, str);
    else decode(root->right, index, str);
}

void buildHuffmanTree(string text) {
    unordered_map<char, int> freq;
    for (char ch : text) {
        freq[ch]++;
    }

    priority_queue<HuffmanNode*, vector<HuffmanNode*>, Compare> pq;

    for (auto pair : freq) {
        pq.push(new HuffmanNode(pair.first, pair.second));
    }

    while (pq.size() != 1) {
        HuffmanNode* left = pq.top(); pq.pop();
        HuffmanNode* right = pq.top(); pq.pop();

        int sum = left->frequency + right->frequency;
        pq.push(new HuffmanNode('\0', sum, left, right));
    }

    HuffmanNode* root = pq.top();

    unordered_map<char, string> huffmanCode;
    encode(root, "", huffmanCode);

    cout << "Huffman Codes are :\n";
    for (auto pair : huffmanCode) {
        cout << pair.first << " " << pair.second << '\n';
    }

    cout << "\nOriginal string was :\n" << text << '\n';

    string str = "";
    for (char ch : text) {
        str += huffmanCode[ch];
    }

    cout << "\nEncoded string is :\n" << str << '\n';

    int index = -1;
    cout << "\nDecoded string is :\n";
    while (index < (int)str.size() - 2) {
        decode(root, index, str);
    }
}

int main() {
    string text = "HUFFMANALGORITHM";

    buildHuffmanTree(text);

    return 0;
}
```

#### 5. Huffman kódolás előnyei és hátrányai

**Előnyök:**
1. **Optimális kódolás**: A Huffman kódolás garantáltan optimális a karakterek valószínűségi eloszlása esetén.
2. **Veszteségmentes tömörítés**: A Huffman kódolás nem veszíti el az információt, így a dekódolt adat megegyezik az eredetivel.

**Hátrányok:**
1. **Állandó hosszúságú karakterkészletekhez nem praktikus**: Olyan esetekben, ahol a karakterek előfordulási gyakorisága közel azonos, a Huffman kódolás nem éri el a várt eredményt.
2. **Túlburjánzás**: Nagyon nagy és változatos karakterkészletek esetén a Huffman fa mérete és komplexitása is jelentősen növekedhet, ami befolyásolja a hatékonyságot.

#### 6. Alkalmazási területek

A Huffman kódolást számos területen alkalmazzák, például:
- **Fájlformátumok**: JPEG, PNG és más veszteségmentes képformátumok.
- **Adattömörítési programok**: ZIP, GZIP.
- **Adatátviteli protokollok**: Széles körben alkalmazzák a hálózati adatátvitel optimalizálásához.

A Huffman kódolás kiemelkedő példája annak, hogy a matematika és az informatika hogyan ötvöződhet hatékony algoritmusok létrehozása érdekében, amelyek képesek az információt kompaktabb formában tárolni és továbbítani, anélkül, hogy az eredeti adat sérülne.

### LZ77 és LZ78

Az LZ77 és LZ78 algoritmusok a Lempel-Ziv kompressziós család két alapvető tagja. Az izraeli kutatók, Abraham Lempel és Jacob Ziv által 1977-ben és 1978-ban megalkotott algoritmusok jelentős hatással voltak az adatkompresszió terén, és széles körben alkalmazzák őket különböző adattömörítési rendszerekben. Ezen algoritmusok közös jellemzője, hogy adaptívak és veszteségmentesek, tehát az eredeti adat teljes egészében visszanyerhető a tömörített adatból. Ebben a fejezetben részletesen áttekintjük mind az LZ77, mind az LZ78 algoritmusokat, kitérünk a működésükre, előnyeikre és hátrányaikra, valamint alkalmazási területeikre.

#### 1. LZ77 algoritmus

Az LZ77 algoritmus a bemeneti szöveget egy ablak segítségével dolgozza fel, amely az aktuális pozíció előtti adatokat figyeli. Az algoritmus a visszamutató hivatkozások segítségével az adatok ismétlődéseit jeleníti meg.

##### 1.1 Működési elv

Az LZ77 algoritmus fogalmilag egyetlen ablakot tartalmaz, amely két részre oszlik:
- **Lookahead Buffer**: Ez a puffer tartalmazza az aktuálisan olvasásra váró karaktereket.
- **Search Buffer**: Ez a puffer a korábban olvasott karaktereket tartalmazza.

Az algoritmus háromtagú tételt ({hossz, távolság, következő karakter}) használ az ismétlődések észlelésére:
- **hossz**: Az ismétlődő szekvencia hosszúsága.
- **távolság**: Az ismétlődő szekvencia pozíciója (hány karakterrel korábban kezdődik).
- **következő karakter**: Az aktuális szekvencia után következő karakter.

##### 1.2 Példa

Tekintsünk egy egyszerű példát a bemeneti szövegre: `abcabcabcabc`

1. Iteráció: `a` - {0,0,a}
2. Iteráció: `b` - {0,0,b}
3. Iteráció: `c` - {0,0,c}
4. Iteráció: `a` - {1,3,a} - Visszamutat 3 karakterrel, hossza 1 és az 'a' az új karakter
5. Iteráció: `b` - {1,3,b}
6. Iteráció: `c` - {1,3,c}
  
A létrejövő kimenet: `{0,0,a}, {0,0,b}, {0,0,c}, {1,3,a}, {1,3,b}, {1,3,c}`

##### 1.3 LZ77 algoritmus előnyei és hátrányai

**Előnyök:**
- **Egyszerű implementáció**: Az LZ77 algoritmus strukturáltsága viszonylag egyszerűvé teszi a megvalósítást.
- **Adaptáció**: Az algoritmus adaptív, azaz nem igényel előzetes statisztikákat a bemeneti adatokról.

**Hátrányok:**
- **Hatékony tárolás**: Olyan adatállományokban működik a legjobban, ahol sok ismétlődés van a szövegben.
- **Nagyobb tárolási igény**: Előfordul, hogy a tömörített adat nagyobb, mint az eredeti, különösen ha kevés vagy semmilyen ismétlődés nincs az adatokban.

#### 2. LZ78 algoritmus

Az LZ78 algoritmus az LZ77 továbbfejlesztett változata. Az LZ78 célja, hogy javítsa az adatok feldolgozását és tárolását azáltal, hogy az ismétlődéseket explicit módon eltárolja egy szótárban.

##### 2.1 Működési elv

Az LZ78 algoritmus egy szótárt használ, amelybe az algoritmus során új ismétlődő szekvenciák kerülnek felvételre. Az algoritmus két elemből álló tételt ({index, karakter}) használ:
- **index**: Az ismétlődő szekvencia szótárbeli indexe.
- **karakter**: Az aktuális szekvencia után következő karakter.

##### 2.2 Példa

Tekintsünk egy példát a bemeneti szövegre: `abcabcabcabc`

1. Iteráció: `a` - {0,a} - Szótár: {'a'}
2. Iteráció: `b` - {0,b} - Szótár: {'a', 'b'}
3. Iteráció: `c` - {0,c} - Szótár: {'a', 'b', 'c'}
4. Iteráció: `ab` - {1,b} - Szótár: {'a', 'b', 'c', 'ab'}
5. Iteráció: `c` - {3,c} - Szótár: {'a', 'b', 'c', 'ab', 'bc'}

A keletkező kimenet: `{0,a}, {0,b}, {0,c}, {1,b}, {3,c}`

##### 2.3 LZ78 algoritmus előnyei és hátrányai

**Előnyök:**
- **Hatékonyabb tömörítés**: Az LZ78 általában jobban teljesít az LZ77-nél olyan adatoknál, amelyek nem tartalmaznak hosszú ismétlődő szekvenciákat.
- **Szótár alapú**: A szótár módszer hatékonyabb adatreprezentációt eredményezhet.

**Hátrányok:**
- **Komplexitás**: A szótár kezelésének és karbantartásának komplexitása.
- **Memóriaigény**: A szótár méretének növekedésével nő a memóriaigény is, különösen nagy input esetén.

#### 3. Implementáció C++ nyelven

Az alábbiakban bemutatjuk az LZ77 és LZ78 algoritmusok C++ nyelvű implementációját. Először az LZ77 következik:

##### LZ77 Implementáció:

```cpp
#include <iostream>
#include <vector>
#include <tuple>
#include <string>

using namespace std;

vector<tuple<int, int, char>> LZ77Compress(string input, int searchBufferSize, int lookaheadBufferSize) {
    vector<tuple<int, int, char>> compressed;
    int searchBufferStart = 0;
    int inputSize = input.size();

    for (int i = 0; i < inputSize; ) {
        int matchLength = 0;
        int matchPosition = -1;
        char nextChar = input[i];
        
        for (int j = max(0, i - searchBufferSize); j < i; j++) {
            int length = 0;
            while (j + length < i && i + length < inputSize && input[j + length] == input[i + length]) {
                length++;
            }
            if (length > matchLength) {
                matchLength = length;
                matchPosition = j;
                if (i + length < inputSize) {
                    nextChar = input[i + length];
                } else {
                    nextChar = '\0';
                }
            }
        }

        if (matchLength > 0) {
            compressed.push_back(make_tuple(i - matchPosition, matchLength, nextChar));
            i += matchLength + 1;
        } else {
            compressed.push_back(make_tuple(0, 0, input[i]));
            i++;
        }
    }

    return compressed;
}

int main() {
    string input = "abcabcabcabc";
    vector<tuple<int, int, char>> compressed = LZ77Compress(input, 6, 6);

    for (auto& t : compressed) {
        cout << "(" << get<0>(t) << ", " << get<1>(t) << ", " << get<2>(t) << ")" << endl;
    }

    return 0;
}
```

##### LZ78 Implementáció:

```cpp
#include <iostream>
#include <unordered_map>
#include <vector>
#include <tuple>
#include <string>

using namespace std;

vector<tuple<int, char>> LZ78Compress(string input) {
    unordered_map<string, int> dictionary;
    vector<tuple<int, char>> compressed;
    string current = "";
    int dictSize = 1;

    for (char ch : input) {
        string next = current + ch;
        if (dictionary.find(next) != dictionary.end()) {
            current = next;
        } else {
            if (!current.empty()) {
                compressed.push_back(make_tuple(dictionary[current], ch));
            } else {
                compressed.push_back(make_tuple(0, ch));
            }
            dictionary[next] = dictSize++;
            current = "";
        }
    }

    if (!current.empty()) {
        compressed.push_back(make_tuple(dictionary[current], '\0'));
    }

    return compressed;
}

int main() {
    string input = "abcabcabcabc";
    vector<tuple<int, char>> compressed = LZ78Compress(input);

    for (auto& t : compressed) {
        cout << "(" << get<0>(t) << ", " << get<1>(t) << ")" << endl;
    }

    return 0;
}
```

#### 4. Összegzés

Az LZ77 és LZ78 algoritmusok alapvető szerepet játszanak az adatkompresszióban. Mindkét algoritmus adaptív módon kezeli a bemeneti adatokat, így hatékonyan képesek tömöríteni különféle adattípusokat. Az LZ77 algoritmus elsősorban a folytonos karakterismétlődések esetén hatékony, míg az LZ78 a szótár alapú megközelítésével rugalmasságot és jobb teljesítményt nyújt.

Bár mindkét algoritmusnak megvannak a maga előnyei és hátrányai, az általuk biztosított veszteségmentes tömörítés számos alkalmazási területen elengedhetetlen. Ezek közé tartoznak a fájlformátumok, adattovábbítási rendszerek és egyéb kompressziós technológiák.

Az LZ77 és LZ78 algoritmusok megértése nemcsak a tömörítési technikák elmélyítéséhez, hanem az ezekre épülő továbbfejlesztett algoritmusok, például az LZW (Lempel-Ziv-Welch) jobb megértéséhez is kulcsfontosságú. A következő alfejezetben az LZW algoritmust tárgyaljuk részletesebben.

### LZW (Lempel-Ziv-Welch)

Az LZW (Lempel-Ziv-Welch) algoritmus, amelyet Terry Welch 1984-ben az LZ78 algoritmus továbbfejlesztéseként publikált, az adatkompresszió egy fontos eszköze lett különböző adattömörítési rendszerek és fájlformátumok, például a GIF és az UNIX `compress` parancs számára. Az LZW algoritmus az LZ78 azon alapvető elvén nyugszik, hogy egy szótárat épít az adatok előállítása során, de azt számos szempontból optimalizálja. Ez az algoritmus veszteségmentes tömörítést biztosít, azaz az eredeti információ pontosan visszaállítható a tömörített adatból.

#### 1. Elméleti háttér

Az LZW algoritmus fő célja, hogy az adatok ismétlődő mintázatainak felismerésével csökkentse az adatok méretét. Az LZW diccionario-alapú technikát alkalmaz, amely nem igényel előzetes statisztikákat a bemeneti adatok gyakorisági eloszlásáról. Ehelyett az algoritmus menet közben építi fel a szótárat, figyelve az adatokban megjelenő ismétlődéseket.

##### 1.1 Szótár kezelés

Az LZW algoritmus külön szótárt használ a tömörítés és a visszaállítás során. A szótár kezdetben az összes egykarakteres bemeneti szimbólumot tartalmazza, és új szimbólumokat ad hozzá minden egyes alkalommal, amikor ismétlődő mintázatokat talál.

Például, ha az „ABCABCABC” adatsort kell tömöríteni, a szótár az algoritmus során folyamatosan bővül az új szekvenciákkal.

##### 1.2 Kódolási folyamat

A kódolási folyamat során az LZW algoritmus minden elolvaskélet megszaporzott karakterláncot hozzáad a szótárhoz, ha az még nincs benne:

- Kezdi az adatok feldolgozását a bemeneti karakterlánc első karakterével.
- Amíg találsz egy bemeneti karakterláncot a szótárban, folytatod az olvasást.
- Ha egy karakterlánc már nincs a szótárban, hozzáadod azt a szótárhoz és a szótár indexe alapján tárolod.

##### 1.3 Dekódolási folyamat

Az LZW dekódolási folyamata az LZW kódolási folyamat fordított eljárása:

- Kezdetben az összes egy karorges szimbólumot tartalmazza.
- A dekódolás az indexek alapján történik, amelyek a szótárban lévő karakterláncokat hivatkozzák.

#### 2. Működési elv

Az LZW működése fokozatosan bővíti a kezdeti szótárat, hogy magába foglalja az adatokban található összes ismétlődő mintát. 

##### 2.1 Kódolás

A kódolási folyamat során az algoritmus a következő lépéseket követi:

1. **Kezdődik az alapszótárral**: Az alapszótár tartalmazza az összes egykarakteres bemeneti szimbólumot.
2. **Bemenet olvasása**: Az algoritmus a bemeneti adatfolyamot karakterről karakterre olvassa. Ha az aktuális karakterlánc megtalálható a szótárban, folytatja a karakterek olvasását.
3. **Minta hozzáadása**: Amikor egy karakterlánc már nincs a szótárban, hozzáadja azt a szótárhoz, az előző karakterlánc szimbólumának indexe és a következő karakter kombinációjaként.
4. **Kimeneti kód**: Az előző karakterlánc szimbólumának indexét hozzáadja a kimeneti kódhoz.

##### 2.2 Dekódolás

A dekódolási folyamat hasonló a kódoláshoz, de az indexek és szótári bejegyzések alapján történik:

1. **Kezdődik az alapszótárral**: Az alapszótár ugyanazokat az egykarakteres szimbólumokat tartalmazza, mint a kódolási folyamat szótára.
2. **Indexek olvasása**: Az algoritmus az indexeket olvassa a tömörített adatfolyamból.
3. **Karakterlánc kibővítése**: Minden index alapján kibővíti és meghatározza a karakterláncokat.
4. **Szótár bővítése**: Az új, kibővített karakterláncokat hozzáadja a szótárhoz.

#### 3. Példa

Tekintsük a `TOBEORNOTTOBEORTOBEORNOT` bemeneti adatot:

1. Alapszótár:
   ```
   0: T, 1: O, 2: B, 3: E, 4: R, 5: N, 6: O, 7: T, 8: B, 9: E
   ```

2. Kódolás:

   - `T`: 84
   - `O`: 79
   - `B`: 66
   - `E`: 69
   - `O`: 79
   - `RN`: új szimbólum: 256
   - `OT`: új szimbólum: 257
   - `TO`: 84
   - `BE`: 66
   - Használja az új szimbólumokat a szótár bővítésére és a szekvencia folytatásához:
     ```
     256: RN, 257: OT
     ```

3. Dekódolás:

   - Olvassa az indexeket és hivatkozik a szótár bejegyzéseire, hogy visszaállítsa az eredeti szöveget.

##### C++ Implementáció

Az alábbiakban bemutatjuk az LZW algoritmus C++ nyelvű implementációját.

```cpp
#include <iostream>
#include <unordered_map>
#include <vector>
#include <string>

using namespace std;

vector<int> LZWCompress(string input) {
    unordered_map<string, int> dictionary;
    vector<int> compressed;
    int dictSize = 256; // Initial dictionary size

    // Initialize dictionary with single character strings
    for (int i = 0; i < 256; i++) {
        dictionary[string(1, i)] = i;
    }

    string currentStr = "";
    for (char ch : input) {
        string nextStr = currentStr + ch;
        if (dictionary.find(nextStr) != dictionary.end()) {
            currentStr = nextStr;
        } else {
            compressed.push_back(dictionary[currentStr]);
            dictionary[nextStr] = dictSize++;
            currentStr = string(1, ch);
        }
    }

    if (!currentStr.empty()) {
        compressed.push_back(dictionary[currentStr]);
    }

    return compressed;
}

string LZWDecompress(vector<int> compressed) {
    unordered_map<int, string> dictionary;
    int dictSize = 256; // Initial dictionary size

    for (int i = 0; i < 256; i++) {
        dictionary[i] = string(1, i);
    }

    string prevStr = string(1, compressed[0]);
    string decompressed = prevStr;
    string currentStr = "";

    for (size_t i = 1; i < compressed.size(); i++) {
        int currentCode = compressed[i];
        if (dictionary.find(currentCode) != dictionary.end()) {
            currentStr = dictionary[currentCode];
        } else if (currentCode == dictSize) {
            currentStr = prevStr + prevStr[0];
        }

        decompressed += currentStr;

        dictionary[dictSize++] = prevStr + currentStr[0];
        prevStr = currentStr;
    }

    return decompressed;
}

int main() {
    string input = "TOBEORNOTTOBEORTOBEORNOT";
    vector<int> compressed = LZWCompress(input);

    cout << "Compressed: ";
    for (int code : compressed) {
        cout << code << " ";
    }
    cout << endl;

    string decompressed = LZWDecompress(compressed);
    cout << "Decompressed: " << decompressed << endl;

    return 0;
}
```

#### 4. LZW algoritmus előnyei és hátrányai

**Előnyök:**
- **Hatékony tárhelykihasználás**: Az LZW algorithmus hatékonyan kihasználja a tárhelyet, különösen a nagy adatállományok esetében.
- **Szótár alapú**: A szótár használata lehetővé teszi az ismétlődő szekvenciák hatékony tömörítését.
- **Egyszerű dekódolás**: A dekódolási folyamat egyszerű és hatékony, mivel követi a kódolási folyamatot.

**Hátrányok:**
- **Memóriaigény**: A szótár kezelése és tárolása növelheti a memóriaigényt, különösen nagy input esetén.
- **Nagy szótár probléma**: A szótár mérete exponenciálisan nőhet, ami az algoritmus hatékonyságának csökkenéséhez vezethet hosszabb adatfolyamok esetén.

#### 5. Összegzés

Az LZW algoritmus jelentős előrelépés az LZ78-hoz képest, és számos praktikus alkalmazási területen bizonyította hatékonyságát. Az LZW segítségével elért tömörítési eredmények számos fájlformátumban és adattovábbítási rendszerben meghatározóvá váltak. Az LZW erőssége, hogy képes dinamikusan és hatékonyan kezelni az adatokat anélkül, hogy előzetes információra lenne szükség a bemeneti adatokról. Az algoritmus megértése és alkalmazása kulcsfontosságú az adatkompresszió területén dolgozó szakemberek számára, hiszen lehetővé teszi a nagy mennyiségű adat hatékony és gyors tömörítését.

