\newpage

## 6. Tömörítési algoritmusok

Az adattömörítés az információtechnológia egyik alapvető és létfontosságú területe, amely lehetővé teszi, hogy az adatok kevesebb helyet foglaljanak el tárolóeszközeinken, illetve hatékonyabb és gyorsabb adatátvitelt tesz lehetővé a hálózatokon keresztül. A tömörítési algoritmusokat számos alkalmazási területen használják, a fájlarchiválástól kezdve a videó- és hangfájlok hatékony tárolásán és továbbításán át egészen a biztonságos kommunikációig. Ebben a fejezetben három jelentős tömörítési módszert vizsgálunk meg részletesen: a Huffman kódolást, az LZW (Lempel-Ziv-Welch) algoritmust, valamint a JPEG, MPEG és más média tömörítési technikákat. Ezeknek az algoritmusoknak az elméletét és gyakorlati alkalmazását bemutatva világítunk rá, hogy miként képesek ezek a technológiák jelentős mértékben csökkenteni az adatmennyiséget miközben megőrzik, vagy adott esetben javítják az adatok minőségét és integritását.

### Huffman kódolás

A Huffman-kódolás az egyik legismertebb veszteségmentes adattömörítési módszer, amelyet David A. Huffman fejlesztett ki 1952-ben, a Massachusetts Institute of Technology (MIT) hallgatójaként. Ez az algoritmus a prefix kódokon alapul, és hatékonyan képes tömöríteni az adatokat azáltal, hogy a gyakoribb elemeket rövidebb kódszavakkal, míg a ritkább elemeket hosszabb kódszavakkal helyettesíti. A Huffman-kódolás két fő részre osztható: a kódfák előállítása és maga a kódolási folyamat.

#### Huffman-fák létrehozása

A Huffman-fák olyan bináris fák, amelyek levelei egy adott karaktergyakorisági eloszlást tükröznek. Az algoritmus az alábbi lépésekben építi fel a Huffman-fát:

1. **Gyakoriságok megállapítása**: Az első lépés a bemenetként szolgáló karakterlánc minden karakterének előfordulási gyakoriságát megszámolja.
2. **Prioritási sor kialakítása**: A karaktereket a gyakoriságuk alapján egy prioritási sorba rendezzük. Ez a prioritási sor egy min-kupac (minimum heap) segítségével valósítható meg, amelyben a legkisebb gyakoriságú elemek kerülnek először elő.
3. **Faépítés**: Két legkisebb prioritású elemet kivesz a kupacból és egy új csomópontot hoz létre, amely a két kivett csomópont gyermekeként jelenik meg. Az új csomópont gyakorisága az összeadott csomópontok gyakoriságainak összege lesz. Ezt az új csomópontot visszahelyezi a kupacba.
4. **Ismétlés**: Az előző lépést ismételni kell, amíg csak egy csomópont marad. Ez a csomópont lesz a Huffman-fa gyökere.

Ez a folyamat garantálja, hogy az összes betű egyedi bináris kódot kap, amelynek nincs más betű előtagja (prefix), ezáltal biztosítva a kód egyértelmű dekódolhatóságát.

#### Huffman-kódolás

Miután a Huffman-fát felépítettük, megkezdhetjük a karakterek kódolását a fa útvonalai alapján. Ehhez a következő lépéseket követjük:

1. **Kód hozzárendelése**: Kezdve a fa gyökerétől, mindegyik balra tett lépteket 0-sal, a jobbra tett lépteket pedig 1-gyel kódolva felírjuk az egyes karakterekhez tartozó kódszavakat.
2. **Kódolás**: Az eredeti adatfolyamot szimbólumról szimbólumra haladva helyettesítjük az adott szimbólumhoz tartozó bináris kóddal.

#### Huffman-dekódolás

A dekódolási folyamat során a bináris adatfolyamot a Huffman-fa segítségével visszaalakítjuk eredeti szimbólumsorozattá. A dekódoló a fa gyökerétől indul, és a 0-kal balra, 1-gyel pedig jobbra lépegetve olvassa ki a karaktereket.

#### Példakód (C++)

Itt egy egyszerű példa a Huffman-kódolás implementálására C++ nyelven:

```cpp
#include <iostream>
#include <queue>
#include <unordered_map>
#include <vector>

using namespace std;

// Egy Huffman fa csomópontjának definíciója
struct Node {
    char ch;
    int freq;
    Node* left;
    Node* right;
    
    Node(char ch, int freq) {
        left = right = nullptr;
        this->ch = ch;
        this->freq = freq;
    }
};

// Egy összehasonlító funktor a prioritási sorhoz (min-kupachoz)
struct compare {
    bool operator()(Node* l, Node* r) {
        return l->freq > r->freq;
    }
};

// A Huffman kódtábla építése
void encode(Node* root, string str, unordered_map<char, string> &huffmanCode) {
    if (root == nullptr)
        return;

    if (!root->left && !root->right) {
        huffmanCode[root->ch] = str;
    }
    
    encode(root->left, str + "0", huffmanCode);
    encode(root->right, str + "1", huffmanCode);
}

// A Huffman fa felszabadítása
void freeTree(Node* root) {
    if (root == nullptr) 
        return;
    freeTree(root->left);
    freeTree(root->right);
    delete root;
}

// A Huffman fa építése és a szimbólumok kódolása
unordered_map<char, string> buildHuffmanTree(string text) {
    // Karakterek gyakoriságának kiszámítása
    unordered_map<char, int> freq;
    for (char ch : text) {
        freq[ch]++;
    }

    // Prioritási sor (min-kupac) létrehozása
    priority_queue<Node*, vector<Node*>, compare> pq;

    // Fa leveleinek inicializálása
    for (auto pair : freq) {
        pq.push(new Node(pair.first, pair.second));
    }

    // Fa építése
    while (pq.size() != 1) {
        Node* left = pq.top(); pq.pop();
        Node* right = pq.top(); pq.pop();

        int sum = left->freq + right->freq;
        pq.push(new Node('\0', sum, left, right));
    }

    // Gyökér elmentése
    Node* root = pq.top();

    // Huffman kódtábla építése
    unordered_map<char, string> huffmanCode;
    encode(root, "", huffmanCode);

    // Huffman fa felszabadítása
    freeTree(root);

    return huffmanCode;
}

int main() {
    string text = "Huffman coding is a data compression algorithm.";

    // Huffman kódtábla építése
    unordered_map<char, string> huffmanCode = buildHuffmanTree(text);

    // Eredmény kiírása
    cout << "Huffman Codes are :\n" << endl;
    for (auto pair : huffmanCode) {
        cout << pair.first << " " << pair.second << endl;
    }

    return 0;
}
```

#### Huffman-kódolás hatékonysága és alkalmazási területei

A Huffman-kódolás különösen hatékony olyan helyzetekben, ahol a karakterek előfordulási gyakorisága nagyon különböző. Az algoritmus garantálja, hogy a leggyakrabban előforduló karakterek a lehető legrövidebb kódot kapják, ezáltal csökkentve az átlagos kódhosszúságot.

A Huffman-kódolást széles körben használják különféle alkalmazásokban, beleértve a fájlarchiváló programokat (pl. ZIP, GZIP), média tömörítési formátumokat (pl. JPEG, MP3) és hálózati protokollokat (pl. HTTP/2). Az algoritmus előnyei közé tartozik a viszonylag egyszerű implementáció, a hatékony tömörítés és a veszteségmentes jelleg.

Azonban a Huffman-kódolásnak vannak korlátai is. Az egyik jelentős korlát az, hogy a kódolási hatékonyság nagymértékben függ a karakterek valószínűségi eloszlásától. Amennyiben az eloszlás egyenletes, akkor a Huffman-kódolás nem nyújt jelentős tömörítési előnyt. Ezen kívül az algoritmus statikus változata nem alkalmazkodik a változó adat eloszláshoz, bár léteznek dinamikus változatok, amelyek ezt a problémát kezelik.

Összegzésül a Huffman-kódolás egy rendkívül hasznos és hatékony módszer sokféle adattömörítési feladat megoldására. Az algoritmus alapelvei és implementációja viszonylag egyszerűek, mégis erős elméleti alapokra épülnek, és széles körű gyakorlati alkalmazási lehetőségekkel rendelkeznek.

### LZW (Lempel-Ziv-Welch) algoritmus

A Lempel-Ziv-Welch (LZW) algoritmus egy veszteségmentes adattömörítési algoritmus, amelyet Abraham Lempel és Jacob Ziv eredetileg 1978-ban fejlesztett ki (LZ78), majd Terry Welch tökéletesített 1984-ben. Az LZW a szekvenciális adattömbök (például szövegfájlok) gyakori alárendeleteinek azonosításával és kódolásával tömörít. Az algoritmus különösen népszerű az egyszerűsége és hatékonysága miatt. Többek között olyan formátumok és protokollok használják, mint a GIF, TIFF és az UNIX 'compress' parancs.

#### LZW algoritmus működési elve

Az LZW algoritmus egy szótár alapú tömörítési módszer, amely az adatokat dinamikusan kódolja egy növekvő szótár alapján. Az algoritmus minden új, korábban nem találkozott karaktersorozatot hozzárendel egy új kódszóhoz. Amint az algoritmus később találkozik ugyanazzal a sorozattal, a teljes sorozatot helyettesíti a hozzárendelt kódszóval.

##### LZW tömörítés

1. **Inicializáció**: A szótárat a lehető legkisebb alapszimbólumokkal inicializáljuk (például az ASCII karakterkészlettel, ahol a karakterkészlet 256 egyedi karakterből áll).

2. **Beolvasás**: Kezdje el olvasni az adatáramot egy szimbólummal, amelyből az aktuális szekvenciát ("character sequence" vagy "cs") képezi.

3. **Szekvenciák felépítése**: Hozzáad egy új szimbólumot a cs-hoz minden lépésben, és ellenőrizze, hogy az így létrejött szekvencia megtalálható-e a szótárban:
	- Ha a szekvencia megtalálható a szótárban, folytatja az olvasást, és egy újabb szimbólumot ad hozzá.
	- Ha a szekvencia nem található a szótárban, akkor:
		1. Hozzáadja a szekvenciát a szótárhoz egy új kódszóval.
		2. Az aktuális szekvenciából eltávolítja az utolsó szimbólumot, és az ebből származó szekvenciát az előző kódszóval reprezentálja.
		3. Az eltávolított szimbólum a következő szekvencia kezdetének tekinthető, és a folyamat ismétlődik.

4. **Befejezés**: A folyamat addig folytatódik, amíg az egész adatáram be nem kerül a szótárba és megfelelően kódolásra kerül.

##### LZW dekompresszió

Az LZW dekompresszió nagyban hasonlít a tömörítési módszerhez, de fordított irányban működik. A dekompresszió során az algoritmus a beérkező kódokat szótár segítségével visszaalakítja a megfelelő karakterlánccá.

1. **Inicializáció**: Kezdje azáltal, hogy egy szótárt inicializál alapszimbólumokkal.

2. **Kódolvasás**: Olvassa be az első kódot, és fordítsa le a szótár segítségével az első karakterláncra, majd írja ki a karakterláncot.

3. **További kódok feldolgozása**: Olvassa be a következő kódot, ha a kód megtalálható a szótárban:
	- Fordítsa le a kódot a karakterláncra és írja ki.
	- Hozza létre az új karakterláncot az előző karakterlánc és az aktuális karakterlánc első karakterének összefűzésével, majd adja hozzá a szótárhoz.
	- Frissítse az előző karakterláncot az aktuális karakterlánc értékére.
	- Ha a kód nincs a szótárban, kezelje az önhivatkozást oly módon, hogy az előző karakterláncot összefűzi az első karakterével, majd ezt hozzáadja a szótárhoz és kinyomtatja.

4. **Befejezés**: A folyamat addig ismétlődik, amíg az összes kód feldolgozásra kerül.

#### Példakód (C++)

Itt van egy egyszerű LZW tömörítési és dekompressziós példa C++ nyelven, amely bemutatja az algoritmus alapvető működését:

```cpp
#include <iostream>
#include <vector>
#include <unordered_map>
#include <string>

using namespace std;

vector<int> LZWCompress(const string &input) {
    int dictionarySize = 256;
    unordered_map<string, int> dictionary;
    
    for (int i = 0; i < 256; i++) {
        dictionary[string(1, i)] = i;
    }
    
    string current;
    vector<int> compressedData;
    
    for (char c : input) {
        current += c;
        if (dictionary.find(current) == dictionary.end()) {
            dictionary[current] = dictionarySize++;
            current.pop_back();
            compressedData.push_back(dictionary[current]);
            current = c;
        }
    }
    
    if (!current.empty()) {
        compressedData.push_back(dictionary[current]);
    }
    
    return compressedData;
}

string LZWDecompress(const vector<int> &compressedData) {
    int dictionarySize = 256;
    unordered_map<int, string> dictionary;
    
    for (int i = 0; i < 256; i++) {
        dictionary[i] = string(1, i);
    }
    
    string current(1, compressedData[0]);
    string decompressedData = current;
    string entry;
    
    for (size_t i = 1; i < compressedData.size(); i++) {
        int k = compressedData[i];
        
        if (dictionary.find(k) != dictionary.end()) {
            entry = dictionary[k];
        } else {
            entry = current + current[0];
        }
        
        decompressedData += entry;
        dictionary[dictionarySize++] = current + entry[0];
        current = entry;
    }
    
    return decompressedData;
}

int main() {
    string data = "TOBEORNOTTOBEORTOBEORNOT";
    vector<int> compressedData = LZWCompress(data);
    
    cout << "Compressed data: ";
    for (int code : compressedData) {
        cout << code << " ";
    }
    cout << endl;
    
    string decompressedData = LZWDecompress(compressedData);
    cout << "Decompressed data: " << decompressedData << endl;
    
    return 0;
}
```

#### LZW algoritmus hatékonysága és alkalmazási területei

Az LZW algoritmus hatékonysága nagymértékben függ az adattartalomtól. Az olyan adatok esetében, ahol sok ismétlődő szekvencia van (pl. szövegek, bináris fájlok), az LZW kiváló tömörítési arányokat érhet el. Az algoritmus előnyei közé tartozik a gyors tömörítés és dekompresszió, valamint az adatveszteségmentes eljárás.

Az LZW algoritmusként való alkalmazását több területen is találhatjuk:
- **Fájltípusok és formátumok**: Az LZW széles körben használt a GIF (Graphics Interchange Format) képformátumban, ami rendkívül népszerű a weboldalak illusztrációinál. Továbbá TIFF (Tagged Image File Format) és PDF (Portable Document Format) fájlokban is találkozhatunk az LZW tömörítési módszerrel.
- **Általános fájltömörítés**: Az UNIX 'compress' parancsa szintén az LZW algoritmust használja. Habár az utóbbi években újabb tömörítési algoritmusok is megjelentek, például az LZ77 és az LZ78 különféle változatai, az LZW még mindig fontos szerepet játszik.

#### LZW algoritmus korlátai

Az LZW algoritmus néhány hátránnyal is jár. Az egyik fő korlátja a tömörítés hatékonysága a nagyon rövid fájlok vagy nagyon véletlen jellegű adatok esetében, ahol az ismétlődési minták kevésbé jelentkeznek. Ez vezethet a kevésbé hatékony tömörítési arányokhoz.

Másik szempont a szabadalmak. Az LZW algoritmus szabadalmazási helyzete sokáig korlátozta annak szabad alkalmazását, mivel az Unisys Corporation birtokolta a szabadalmi jogokat. Bár ezek a szabadalmak már lejártak, a történeti hatás még mindig érezhető néhány alkalmazási területen.

#### Összegzés

Az LZW egy rendkívül fontos és hatékony adattömörítési algoritmus, amely számos területen jelentősége miatt kiemelkedő helyet foglal el. Az algoritmus egyszerűsége és hatékonysága mellett széleskörű felhasználhatóságot kínál különféle fájlformátumokban és protokollokban. Annak ellenére, hogy néhány korlátozással rendelkezik, az LZW továbbra is releváns és hasznos megoldás a modern adattömörítési igények kielégítésére.

### JPEG, MPEG és egyéb média tömörítési technikák

A média tömörítés magában foglalja a képek, videók és hangfájlok hatékony tárolásának és továbbításának módszereit. Ezek a technikák különféle algoritmusokat használnak, hogy az adatok méretét tartalomveszteséggel vagy anélkül csökkentsék, ugyanakkor megőrzik a megfelelő minőséget. Ebben a részben három kiemelkedő média tömörítési módszert vizsgálunk meg részletesen: a JPEG (Joint Photographic Experts Group) képtömörítést, az MPEG (Moving Picture Experts Group) videótömörítést és néhány további elterjedt média tömörítési technikát, mint például az MP3.

#### JPEG (Joint Photographic Experts Group)

A JPEG formátum az egyik legszélesebb körben használt képtömörítési szabvány, amely lehetővé teszi a fotórealisztikus képek hatékony tömörítését. A JPEG egy veszteséges tömörítési eljárást alkalmaz, amely az emberi szem korlátaira alapozva csökkenti a kép adatainak méretét úgy, hogy a vizuális minőség romlása minimális lesz.

##### JPEG tömörítési folyamat

1. **Színterek átalakítása**: A kép RGB (Red, Green, Blue) színtérben tárolt adatait átalakítjuk YCbCr színtérbe, ahol Y a fényerőt (luminancia), míg Cb és Cr a színinformációkat (krominancia) hordozza.

2. **Blokkokra bontás**: Az átalakított kép adatait 8x8 pixeles blokkokra osztjuk, amelyeket egyedileg tömörítünk.

3. **Diszkrét koszinusz-transzformáció (DCT)**: Az egyes blokkokra diszkrét koszinusz-transzformációt (DCT) alkalmazunk, amely a kép adatait frekvenciakomponensekre bontja.

4. **Kvantilálás**: A frekvenciakomponenseket kvantáljuk, ami az emberi szem érzékenységi profiljának figyelembevételével csökkenti a magas frekvenciájú komponensek pontosságát, ezzel csökkentve az adattárolási igényt.

5. **Huffman-kódolás**: Az egyes blokkok kvantált frekvenciakomponenseit Huffman-kódolással további tömörítést érünk el.

6. **Fájlformátum**: Az összes tömörített blokkot egy fájlformátumba egyesítjük, hozzátéve a szükséges fejléceket és metaadatokat.

##### JPEG dekompressziós folyamat

A JPEG dekompresszió alapvetően a kompressziós folyamat fordítottja. A Huffman-kódokat dekódoljuk, visszakonvertáljuk a blokkok kvantált DCT komponenseit, majd inverz DCT (IDCT) segítségével visszaállítjuk az eredeti képtartalmat. Az így létrehozott YCbCr adatokat végül visszaalakítjuk RGB formátumba.

#### MPEG (Moving Picture Experts Group)

Az MPEG egy szabványosított videótömörítési módszer, amely különféle szabványokat foglal magában, mint például az MPEG-1, MPEG-2, MPEG-4. Az MPEG algoritmusok különlegessége, hogy veszteséges tömörítést alkalmaznak, amelyek a videó és audió adatok hatékony tárolását és továbbítását teszik lehetővé minimális minőségi veszteséggel.

##### MPEG tömörítési folyamat

1. **Vázlatkockák (I-frames)**: Ezek a képkockák teljes képadatokat tartalmaznak és nincs szükségük korábbi vagy későbbi képkockák adataira a dekódolás során. Gyakran alkalmaznak JPEG-hez hasonló DCT és kvantilálási lépéseket.

2. **Interkockák (P-frames és B-frames)**: Ezek a képkockák az előző és/vagy következő képkockák alapján kerülnek tömörítésre. A mozgáselemzés és mozgáskompenzáció révén a képkockák közötti különbségeket tároljuk, ami jelentős tömörítést tesz lehetővé.
    - **P-frames**: Az előző I-frame vagy P-frame alapján kódolják.
    - **B-frames**: Az előző és következő képkockák alapján kódolják.

3. **Frekvencia és időbeli redukció**: A mozgáselemzés és -kompenzáció során a frekvenciakomponensek és időbeli redundanciák eltávolítása jelentős méretcsökkenést eredményez.

4. **Entropikus kódolás**: Az összesített adatok Huffman-kódolással vagy aritmetikai kódolással történő további tömörítése.

##### MPEG szabványok

- **MPEG-1**: Alapértelmezett tömörítési formátum, melyet a Video CD formátumban használnak. Az MP3 (MPEG-1 Layer 3) hangformátumra vezetett, amely a zenei adattömörítés szabványává vált.
- **MPEG-2**: Javított tömörítési hatékonyság HDTV és DVD lejátszóknál. MPEG-2 képfelbontása magasabb és mozgásvektorainak becslése pontosabb, mint az MPEG-1 esetében.
- **MPEG-4**: Magas szintű kompresszió a videó streameléshez, mobil eszközökhöz és interaktív média alkalmazásokhoz. Az MPEG-4 kódolás lehetőséget kínál arra, hogy különféle objektumok és rétegek külön-külön kerüljenek tárolásra és manipulálásra.

#### Egyéb Média Tömörítési Technikák

##### MP3 (MPEG-1 Audio Layer 3)

Az MP3 a veszteséges hangtömörítési eljárások egyik legismertebb módszere, amely az MPEG-1 és későbbi MPEG-2 szabványok része. Az MP3 tömörítési eljárás pszichoakusztikus modelleket használ, amelyek figyelembe veszik az emberi fül érzékenységét különböző frekvenciákra. Az algoritmus az alábbi lépéseket követi:
- **Szűrőbank alkalmazása**: A bemeneti hangjelet különböző frekvenciakomponensekre bontják.
- **Pszichoakusztikai modellek alkalmazása**: A fül által nem érzékelt komponensek (pl. zajok) eltávolításra kerülnek.
- **MDCT (Modified Discrete Cosine Transform)**: A hangjelek MDCT transzformációja további tömörítést biztosít.
- **Kvantilálás és kódolás**: A frekvenciakomponensek kvantilálása és Huffman vagy aritmetikai kódolása.

##### AAC (Advanced Audio Coding)

Az AAC egy fejlettebb hangtömörítési technika, amelyet az MPEG-2 és MPEG-4 szabványokban is használnak. Az AAC számos előnyt kínál az MP3-al szemben:
- **Jobb minőség**: Az AAC jobb minőséget biztosít alacsonyabb bitráták esetén.
- **Több csatorna támogatása**: Az AAC akár 48 teljes frekvenciájú audiocsatornát is támogat.
- **Hatékonyabb tömörítés**: Az AAC fejlett tömörítési technikákat (például TNS, PNS) alkalmaz, amelyek javítják a tömörítés hatékonyságát.

##### FLAC (Free Lossless Audio Codec)

A FLAC egy veszteségmentes hangtömörítési eljárás, amely lehetővé teszi a hangjelek tömörítését az eredeti minőség teljes megtartása mellett. A FLAC algoritmus jellemzői:
- **Predikciós modell**: Lineáris predikció használata az adatok redukálására.
- **Entropy-kódolás**: A maradék különbségek további tömörítése Huffman-kódolással.
- **Gazdag metaadatok támogatása**: A FLAC fájlok gazdag metaadatokat tartalmazhatnak, beleértve a szöveges információkat, képeket és egyéb kiegészítő adatokat.

#### Összegzés

A médiatömörítési technikák, mint a JPEG, MPEG és egyéb médiumok tömörítési algoritmusai, alapvető szerepet játszanak az adatok hatékony tárolásában és továbbításában. Ezek a technikák különféle algoritmusokat kombinálnak, hogy az adatok méretét jelentősen csökkentsék, miközben megőrzik a megfelelő minőséget. Eredményességük az emberi érzékelés sajátosságaira, valamint a különböző adatstruktúrák és minták kihasználására épül. Ezek a technológiák kulcsfontosságúak a digitális tartalom hatékony kezelésében, és nélkülözhetetlenek a modern adatátviteli rendszerek, multimédiás alkalmazások és tárolási megoldások területén.

