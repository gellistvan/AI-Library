\newpage

## 7. Process Scheduling

In any multitasking operating system, the efficiency and responsiveness with which processes are managed play a critical role in overall system performance. Process scheduling in the Linux kernel is a sophisticated and complex mechanism that ensures optimal utilization of the CPU and seamless execution of tasks. This chapter delves into the intricacies of process scheduling, focusing on key components such as scheduling algorithms, context switching, and the various scheduling classes and policies. We will explore the Completely Fair Scheduler (CFS) and Real-Time (RT) scheduling algorithms, dissect the mechanics behind context switching, and unravel how different scheduling classes and policies cater to diverse workload requirements. By the end of this chapter, you will gain a comprehensive understanding of how Linux prioritizes and allocates CPU time among processes, balancing the needs for fairness, efficiency, and real-time responsiveness.

### Scheduling Algorithms (CFS, RT)

Process scheduling is a pivotal aspect of the Linux kernel, responsible for determining which process runs on the CPU at any given time. Effective scheduling algorithms are crucial for achieving a balance between system throughput, responsiveness, and process fairness. In this section, we will delve deeply into two primary scheduling algorithms in the Linux kernel: the Completely Fair Scheduler (CFS) and the Real-Time (RT) Scheduler. We will explore their theoretical foundations, practical implementations, and their impact on system performance.

#### Completely Fair Scheduler (CFS)

Introduced in Linux kernel version 2.6.23, the Completely Fair Scheduler (CFS) is the default process scheduler for the Linux kernel. It was designed to provide a more balanced approach to process scheduling, emphasizing fairness and efficiency.

##### Theoretical Basis

1. **Fairness:** 
   CFS is based on the concept of fair queuing, ensuring that every runnable process gets an equal share of the CPU over time. The fundamental philosophy is to model an ideal, precise multitasking processor that can run all processes simultaneously, giving each process an equal fraction of CPU time.

2. **Virtual Runtime (vruntime):**
   Each process in CFS is associated with a virtual runtime, a metric that represents the amount of CPU time a process has used. Processes with smaller vruntime are prioritized, ensuring that processes that have used less CPU time are given more opportunities to run.

##### Implementation Details

1. **Red-Black Tree:**
   CFS utilizes a red-black tree, a self-balancing binary search tree, to manage the vruntime of runnable processes. Each node in the red-black tree corresponds to a process, and the tree is ordered by vruntime. This data structure allows CFS to efficiently identify the process with the smallest vruntime, which is selected to run next.

2. **Granularity:**
   CFS introduces the concept of scheduling granularity, which determines the minimum amount of time a process is allowed to run before a context switch can occur. This ensures that processes get a fair share of CPU time without excessive context switching.

3. **Load Balancing:**
   CFS performs load balancing across multiple CPUs by periodically redistributing tasks among CPUs to ensure an even distribution of workload. It uses a technique called "task migration" to move processes from overloaded CPUs to underloaded ones.

##### Pseudo Code Example

Here’s a simplified pseudocode representation of how CFS selects the next process to run:

```cpp
struct process {
   int pid;
   int vruntime;
};

// Red-Black Tree storing processes ordered by vruntime
RedBlackTree<process> cfs_tree;

process select_next_process() {
   // The process with the smallest vruntime is at the leftmost node
   return cfs_tree.min();
}

void update_vruntime(process p, int delta_time) {
   p.vruntime += delta_time;
   cfs_tree.update(p);
}

void run_cfs_scheduler() {
   while (true) {
      // Select the process with the smallest vruntime
      process next_process = select_next_process();
      
        // Simulate running the process for a time quantum
      int delta_time = run_process(next_process);
      
        // Update the vruntime of the process
      update_vruntime(next_process, delta_time);
   }
}
```

This pseudocode provides a high-level overview of how CFS operates, but the actual implementation in the Linux kernel is more complex, involving additional considerations like priority and niceness.

#### Real-Time (RT) Scheduler

The Real-Time (RT) scheduler in Linux is designed for tasks that require guaranteed execution within strict timing constraints. Real-time scheduling is crucial for applications in fields such as telecommunications, industrial automation, and multimedia processing, where timing predictability is paramount.

##### Theoretical Basis

1. **Determinism:** 
   The primary goal of the RT scheduler is to provide deterministic behavior. This means that the scheduler must guarantee that high-priority tasks are executed within specified time constraints.

2. **Prioritization:** 
   RT tasks are assigned static priorities, with the highest priority tasks preempting lower priority ones. Unlike the CFS, the RT scheduler does not rely on vruntime; instead, it strictly adheres to task priorities.

##### Scheduling Policies

1. **SCHED_FIFO:**
   The First-In-First-Out (FIFO) policy schedules tasks in the order they become runnable. Once a SCHED_FIFO task starts running, it will continue until it either voluntarily relinquishes the CPU, blocks, or is preempted by a higher priority RT task.

2. **SCHED_RR:**
   The Round-Robin (RR) policy is similar to FIFO but includes time slicing. Each RT task is assigned a time slice, which is the maximum amount of time it can run before being preempted to allow other tasks at the same priority level to execute.

##### Implementation Details

1. **Prioritization:** 
   RT tasks are organized in priority queues. Each priority level has its own run queue, and the scheduler selects the highest priority non-empty queue for execution.

2. **Preemption:** 
   RT tasks can preempt running CFS tasks and other lower-priority RT tasks. This preemption ensures that high-priority RT tasks meet their timing requirements.

##### Pseudo Code Example

Here’s a simplified pseudocode representation of how the RT scheduler selects the next RT task to run:

```cpp
struct rt_task {
   int pid;
   int priority;
   int runtime;
};

// Priority queues storing RT tasks ordered by priority
PriorityQueue<rt_task> rt_queues[MAX_PRIORITY];

rt_task select_next_rt_task() {
   for (int i = MAX_PRIORITY; i >= 0; --i) {
      if (!rt_queues[i].empty()) {
         return rt_queues[i].top();
      }
   }
   return nullptr; // No RT task to run
}

void run_rt_scheduler() {
   while (true) {
      // Select the highest-priority RT task
      rt_task next_task = select_next_rt_task();
      
        if (next_task != nullptr) {
         // Simulate running the task for its time slice
         run_task(next_task);
      }
   }
}
```

This pseudocode illustrates the basic flow of the RT scheduler, but the actual kernel implementation includes additional mechanisms for handling task blocking, preemption, and IRQ handling.

#### Conclusion

The scheduling algorithms within the Linux kernel, notably the Completely Fair Scheduler (CFS) and the Real-Time (RT) Scheduler, demonstrate the kernel's ability to balance the requirements of general-purpose computing with those of real-time applications. CFS emphasizes fairness and efficient CPU utilization through innovative mechanisms like vruntime and red-black trees, while the RT scheduler guarantees deterministic behavior for time-critical tasks through strict prioritization and preemption policies.

Understanding these algorithms provides valuable insights into how the Linux kernel manages diverse workloads, ensuring both performance and predictability. Whether you are an OS developer, a system administrator, or a real-time application developer, a deep comprehension of these scheduling mechanisms empowers you to optimize and troubleshoot system performance effectively.

### Context Switching

Context switching is a fundamental concept in multitasking operating systems, serving as the backbone for maintaining the illusion of concurrent execution on a single or multiple CPU cores. It refers to the process of saving the state of a currently running process or thread and restoring the state of the next process or thread to be executed. This intricate procedure enables an operating system to switch between processes, ensuring efficient utilization of CPU resources and offering a responsive user experience. In this chapter, we will delve into the mechanics, types, and performance considerations of context switching, emphasizing its implementation within the Linux kernel.

#### The Mechanics of Context Switching

To appreciate the intricacies of context switching, it's essential to understand what constitutes the context of a process. The context includes all information required to resume the execution of a process at a later time. This information can be broadly categorized as:

1. **CPU Registers:**
   - General-purpose registers (e.g., EAX, EBX in x86 architecture)
   - Special-purpose registers (e.g., Instruction Pointer (IP), Stack Pointer (SP), Program Status Word (PSW))
   
2. **Memory Management Information:**
   - Page tables, segment registers, and other data structures used by the Memory Management Unit (MMU)

3. **Process Control Block (PCB):**
   - Process ID (PID)
   - Process state (e.g., running, ready, blocked)
   - Accounting information (e.g., CPU usage, priority)
   - Open file descriptors, security attributes, and other resources

##### Steps in Context Switching

A typical context switch involves the following steps:

1. **Save State of Current Process:**
   - The state of the currently running process is saved in its PCB. This involves saving CPU registers, program counter, stack pointer, and other critical context information.
   
2. **Update Process States:**
   - The state of the currently running process is updated to reflect its new status (e.g., running to ready or blocked).
   
3. **Select Next Process:**
   - The scheduler selects the next process to run based on the scheduling algorithm in use (CFS, RT, etc.).
   
4. **Restore State of Next Process:**
   - The state of the selected process is restored from its PCB. This involves loading CPU registers, program counter, stack pointer, and other necessary context information.
   
5. **Switch Address Space:**
   - If the next process has a different address space, the MMU updates the page tables and other memory management data structures.

6. **Resume Execution:**
   - The CPU resumes execution of the selected process from the point where it was previously interrupted.

#### Types of Context Switching

Context switching can be categorized into several types based on the granularity and nature of the entities involved:

1. **Process-level Context Switching:**
   - Involves switching between processes, each with its own address space. This type incurs significant overhead due to the need to reload the memory management context.
   
2. **Thread-level Context Switching:**
   - Involves switching between threads within the same process. As threads share the same address space, the overhead is lower compared to process-level switches.
   
3. **Kernel-level Context Switching:**
   - Occurs between different kernel threads or between user threads and kernel threads. This type often involves additional considerations for preserving kernel-mode and user-mode states.

#### Performance Considerations

Context switching, while essential, incurs overhead that can affect system performance. The primary sources of overhead include:

1. **CPU Register Saving/Restoring:**
   - Each context switch requires saving and restoring the entire set of CPU registers, which can be time-consuming.
   
2. **Cache and TLB Misses:**
   - Switching processes can lead to cache invalidation and Translation Lookaside Buffer (TLB) misses, resulting in increased memory access latency.
   
3. **Address Space Switching:**
   - Switching address spaces involves updating the MMU, which can be expensive in terms of CPU cycles.

To mitigate these performance impacts, various optimizations are employed:

1. **Lazy Context Switching:**
   - The kernel defers saving and restoring certain registers until their values are actually needed, reducing the overhead in scenarios where context switches are frequent but the registers are not actively used.
   
2. **Hardware Support:**
   - Modern CPUs provide features like hardware task switching and dedicated instructions to speed up context switching (e.g., Intel's Task State Segment (TSS)).

3. **Lightweight Contexts:**
   - Techniques such as thread pooling and lightweight processes (LWP) reduce the overhead by minimizing the amount of context information that needs to be saved and restored.

#### Context Switching in the Linux Kernel

The Linux kernel employs a well-defined mechanism for performing context switches, encapsulated primarily within the `schedule()` function. This function is responsible for selecting the next task to run and orchestrating the context switch.

##### Saving the Context

When a process is preempted, an interrupt or trap handler is invoked, which saves the current context. The Linux kernel uses per-CPU data structures to save and manage this context efficiently.

```c
void save_context(struct task_struct *task) {
   // Save general-purpose registers
   asm("mov %eax, task->eax");
   asm("mov %ebx, task->ebx");
   // Save other registers and state
}
```

##### Switching the Context

The actual context switch is performed by the `context_switch()` function, which updates the kernel's view of the currently running process and switches the CPU state.

```c
void context_switch(struct task_struct *prev, struct task_struct *next) {
   // Switch address space if needed
   if (prev->mm != next->mm) {
      switch_mm(prev->mm, next->mm);
   }
   // Switch the CPU state
   switch_to(prev, next);
}
```

##### Restoring the Context

The context of the new process is then restored, allowing it to resume execution.

```c
void restore_context(struct task_struct *task) {
   // Restore general-purpose registers
   asm("mov task->eax, %eax");
   asm("mov task->ebx, %ebx");
   // Restore other registers and state
}
```

##### Preemption and Voluntary Context Switching

Context switching can be triggered either preemptively or voluntarily:

1. **Preemptive Context Switching:** 
   - This occurs when the scheduler forcibly interrupts a running process, typically via a timer interrupt or when a higher-priority task becomes runnable.
   
2. **Voluntary Context Switching:** 
   - A process can voluntarily relinquish the CPU, for instance, while waiting for I/O operations or if it explicitly calls a yield function.

In the Linux kernel, preemption is managed by periodically invoking the scheduler through the timer interrupt. Voluntary context switching occurs through system calls such as `sched_yield()` or when a process enters a waiting state.

#### Conclusion

Context switching is a critical mechanism that enables the Linux kernel to manage the concurrent execution of multiple processes and threads, ensuring efficient CPU utilization and responsive multitasking. By carefully saving and restoring process state, handling different types of context switches, and optimizing for performance, the Linux kernel achieves a delicate balance between the overhead of context switching and the benefits of multitasking.

Understanding the detailed mechanics and performance implications of context switching provides valuable insights into the inner workings of the Linux scheduler and helps in optimizing system performance. Whether you are working on kernel development, system tuning, or real-time applications, a deep comprehension of context switching mechanisms empowers you to make informed decisions and effectively manage CPU resources.

### Scheduling Classes and Policies

The Linux kernel leverages a sophisticated scheduling framework to address the diverse needs of various workloads, ranging from interactive desktop applications to real-time systems requiring strict timing guarantees. This flexibility is achieved through the implementation of different scheduling classes, each with its own set of policies tailored to specific types of tasks. Understanding these scheduling classes and policies is crucial for optimizing system performance and ensuring that tasks are executed in a way that aligns with their requirements.

#### Scheduling Classes

Scheduling classes in the Linux kernel represent different types of schedulers, each implementing a unique strategy for selecting which process should run next. These classes are organized in a hierarchy where higher-priority classes can preempt lower-priority ones.

1. **Stop Scheduling Class:** 
   - The highest priority class, responsible for stopping or halting tasks. It is rarely used and mainly serves for internal kernel functions.
   
2. **Deadline Scheduling Class:**
   - Designed for real-time tasks with specific deadline constraints. Implemented using the `SCHED_DEADLINE` policy, this class ensures that tasks meet their deadlines by reserving CPU time.

3. **Real-Time Scheduling Class:**
   - Includes two policies: `SCHED_FIFO` (First-In-First-Out) and `SCHED_RR` (Round-Robin). These policies cater to real-time applications requiring predictable and low-latency execution.

4. **CFS Scheduling Class:**
   - The default scheduling class, implementing the Completely Fair Scheduler (CFS) using the `SCHED_NORMAL` and `SCHED_BATCH` policies. This class focuses on fairness and balanced CPU resource allocation.

5. **Idle Scheduling Class:**
   - Used for low-priority background tasks that run only when the system is idle. Implemented using the `SCHED_IDLE` policy, tasks in this class have the lowest scheduling priority.

#### Scheduling Policies

Each scheduling class employs one or more scheduling policies that define how tasks are prioritized and executed. Let's delve into the specifics of each policy:

##### SCHED_DEADLINE

The `SCHED_DEADLINE` policy is part of the Deadline Scheduling Class and is designed for tasks with strict timing constraints. It is based on the Earliest Deadline First (EDF) algorithm, which prioritizes tasks with the earliest deadlines.

###### Key Parameters:

1. **Runtime (Runtime):**
   - The maximum time a task is allowed to run within a given period.
   
2. **Deadline (Deadline):**
   - The specific time by which the task must complete its execution.
   
3. **Period (Period):**
   - The repeating interval at which the task must meet its deadline.

###### Characteristics:

1. **Predictability:**
   - Ensures that high-priority tasks meet their deadlines through careful CPU time reservation.
   
2. **Isolation:**
   - Prevents interference from lower-priority tasks, making it suitable for critical real-time applications.

##### SCHED_FIFO

The `SCHED_FIFO` policy is part of the Real-Time Scheduling Class. In this policy, tasks are scheduled in a First-In-First-Out manner based on their priority. Higher-priority tasks preempt lower-priority ones, and once a task starts running, it continues until it voluntarily gives up the CPU or is preempted by a higher-priority task.

###### Characteristics:

1. **Non-Preemptive within Same Priority:**
   - Tasks of the same priority run until they complete or block, ensuring predictable execution sequences.
   
2. **Deterministic:**
   - Provides a high degree of timing predictability, making it suitable for real-time operations.

##### SCHED_RR

The `SCHED_RR` policy, also part of the Real-Time Scheduling Class, extends `SCHED_FIFO` by adding time slicing within the same priority level. This ensures that tasks of the same priority take turns executing, improving responsiveness.

###### Characteristics:

1. **Time Slicing:**
   - Tasks of the same priority are given equal time slices, allowing more equitable CPU sharing.

2. **Preemptive:**
   - Higher-priority tasks can preempt lower-priority ones, ensuring real-time constraints are met.

##### SCHED_NORMAL

The `SCHED_NORMAL` policy, also known as `SCHED_OTHER`, is the default policy used by the Completely Fair Scheduler. It aims to balance fairness and efficiency for general-purpose workloads.

###### Characteristics:

1. **Fairness:**
   - Uses vruntime to ensure that every task gets a fair share of the CPU over time.
   
2. **Dynamic Prioritization:**
   - Adjusts task priorities dynamically based on their recent CPU usage and interactive behavior.

##### SCHED_BATCH

The `SCHED_BATCH` policy is a variant of the `SCHED_NORMAL` policy, optimized for non-interactive, CPU-intensive batch jobs. It trades off responsiveness for higher throughput.

###### Characteristics:

1. **Lower Priority for Interactive Tasks:**
   - Emphasizes CPU-bound processing over interactive responsiveness.
   
2. **Reduced Context Switching:**
   - Minimizes context switches, enhancing efficiency for batch processing.

##### SCHED_IDLE

The `SCHED_IDLE` policy is part of the Idle Scheduling Class, designed for tasks that should only run when the system is otherwise idle.

###### Characteristics:

1. **Lowest Priority:**
   - Tasks with this policy are only scheduled when no other tasks are runnable.
   
2. **Resource Utilization:**
   - Ideal for background maintenance tasks that should not interfere with regular task execution.

#### Implementation in the Linux Kernel

The Linux kernel implements these scheduling classes and policies through a modular and extensible framework. Let's delve into the key components and their roles:

##### `struct sched_class`

The `struct sched_class` structure defines the interface for scheduling classes. Each scheduling class implements this structure with its own methods for enqueueing, dequeueing, and selecting tasks.

```c
struct sched_class {
   const struct sched_class *next;
   void (*enqueue_task)(struct rq *rq, struct task_struct *p, int flags);
   void (*dequeue_task)(struct rq *rq, struct task_struct *p, int flags);
   void (*yield_task)(struct rq *rq);
   bool (*select_task_rq)(struct task_struct *p, int cookie);
   void (*check_preempt_curr)(struct rq *rq, struct task_struct *p, int flags);
   struct task_struct *(*pick_next_task)(struct rq *rq);
   void (*put_prev_task)(struct rq *rq, struct task_struct *prev);
};
```

##### Run Queues

Each CPU in the system has its own run queue (`struct rq`), which holds tasks that are ready to run. The run queue structure includes pointers to instances of scheduling classes, enabling the kernel to manage tasks of different classes efficiently.

```c
struct rq {
   /* ... other members ... */
   struct load_weight load;
   unsigned long nr_running;
   struct sched_class *curr_class;
   struct task_struct *curr;
   struct cfs_rq cfs;
   struct rt_rq rt;
   struct dl_rq dl;
};
```

##### Scheduler Entry Points

Various entry points in the kernel invoke scheduler functions to manage task states. These include:

1. **`schedule()`:**
   - The primary function for context switching. It invokes the scheduler to select the next task to run.
   
2. **`sched_fork()`:**
   - Initializes scheduling parameters for a new task.
   
3. **`wake_up()`:**
   - Moves a task from the blocked state to the runnable state, making it eligible for scheduling.

##### Example: Integrating a New Scheduling Class

If you wanted to introduce a new scheduling class, you would define a new `struct sched_class` and implement its methods.

```c
struct sched_class new_sched_class = {
   .next = NULL,
   .enqueue_task = new_enqueue_task,
   .dequeue_task = new_dequeue_task,
   .yield_task = new_yield_task,
   .select_task_rq = new_select_task_rq,
   .check_preempt_curr = new_check_preempt_curr,
   .pick_next_task = new_pick_next_task,
   .put_prev_task = new_put_prev_task,
};

void new_enqueue_task(struct rq *rq, struct task_struct *p, int flags) {
   // Implementation of task enqueueing
}

void new_dequeue_task(struct rq *rq, struct task_struct *p, int flags) {
   // Implementation of task dequeueing
}

struct task_struct *new_pick_next_task(struct rq *rq) {
   // Implementation of selecting the next task to run
   return next_task;
}
```

After defining your `sched_class`, you would integrate it into the kernel's scheduling framework by including it in the appropriate run queues and making necessary adjustments to the scheduler's decision-making logic.

#### Conclusion

The Linux kernel's flexible scheduling architecture, comprising multiple scheduling classes and policies, addresses a wide array of application needs, from general-purpose computing to real-time and deadline-sensitive tasks. By understanding the characteristics and implementations of these classes and policies, you can effectively manage and optimize system performance, ensuring that tasks are executed in a manner that best suits their requirements.

Whether you are optimizing a high-performance computing system, tuning an interactive desktop environment, or developing real-time applications, a deep comprehension of Linux's scheduling classes and policies empowers you to make informed decisions, improving both efficiency and responsiveness.

