\newpage

## 8. Tools for Scheduling Analysis

To fully grasp the intricacies of process scheduling in the Linux operating system, it is essential not only to understand the theoretical underpinnings but also to gain hands-on experience with the tools available for scheduling analysis. In this chapter, we will delve into a suite of powerful tools that are indispensable for both system administrators and developers who seek to optimize system performance. We'll begin with `top`, `htop`, and `ps`, which offer real-time insights into process activity and resource utilization. Next, we will explore advanced scheduling tracing capabilities using `perf` and `ftrace`, tools that provide a deeper, event-driven view of whatâ€™s happening under the hood. Through practical case studies and examples, this chapter aims to equip you with the skills needed to effectively analyze and troubleshoot scheduling issues, thereby enhancing your ability to fine-tune Linux systems for optimal performance.

### Using `top`, `htop`, and `ps`

#### Introduction

Understanding the behavior of processes and how resources are utilized in a Linux system is crucial for performance tuning and troubleshooting. Among the myriad of tools available for this purpose, `top`, `htop`, and `ps` are some of the most commonly used and powerful utilities. This chapter delves into these tools, elucidating their functionalities, underlying mechanics, and how they can be leveraged to gain deep insights into process scheduling and resource management.

#### `top`

`top` is a command-line utility that provides a real-time view of system activity and performance. It displays a summary area showing system-level metrics, followed by a list of currently running processes, ordered by resource consumption.

##### Key Features of `top`:

1. **Real-Time Monitoring:**
   `top` refreshes its display periodically, typically every few seconds, allowing users to observe changes in system activity in real-time.
   
2. **Comprehensive Metrics:**
   - **CPU Usage:** The percentage of CPU time used by user processes, system processes, and idle time.
   - **Memory Usage:** Information about physical and virtual memory usage.
   - **Load Average:** The system load average over the last 1, 5, and 15 minutes.
   - **Number of Tasks:** The total number of processes running, sleeping, stopped, or zombied.

3. **Interactive Commands:**
   Users can interact with `top` to sort processes, kill processes, and change the display metrics. Some key commands include:
   - `k`: Kill a process.
   - `r`: Renice a process (change its priority).
   - `s`: Change the refresh interval.

##### Using `top`:

Running `top` is straightforward. Simply execute the following command in the terminal:
```bash
top
```

Once `top` is running, you can use various interactive commands to manipulate the display and control processes. For example, to sort processes by memory usage, press `Shift+M`.

##### Limitations of `top`:

- **Basic Interface:** The text-based interface of `top` might be less intuitive for some users, especially when managing many processes.
- **Static Configuration:** While `top` provides extensive information, the configuration of the output is somewhat limited compared to more advanced tools like `htop`.

#### `htop`

`htop` is an interactive process viewer for Unix systems. It is considered as an enhanced version of `top`, providing a more user-friendly interface and additional features.

##### Key Features of `htop`:

1. **Tree View:**
   `htop` allows users to view processes as a tree, showing parent-child relationships, which can be particularly useful for understanding processes' hierarchies and dependencies.

2. **Color-Coded Display:**
   The user interface uses colors to differentiate between various types of resource usage, making it easier to identify bottlenecks.

3. **Ease of Use:**
   - **Scrolling:** Unlike `top`, `htop` allows users to scroll horizontally and vertically through the process list.
   - **Mouse Support:** `htop` supports mouse interactions, making it easier to navigate.

4. **Customizable Display:**
   Users can customize which columns to display, reorder columns, and choose sorting criteria.

##### Using `htop`:

To install `htop`, you can use your package manager:
```bash
sudo apt-get install htop   # Debian/Ubuntu systems
sudo yum install htop       # CentOS/RHEL systems
sudo pacman -S htop         # Arch Linux systems
```

To run `htop`:
```bash
htop
```

Once running, you can use the arrow keys to navigate and F-keys to perform actions such as filtering processes, searching, and killing processes.

##### Advantages of `htop` over `top`:

- **User-Friendly Interface:** The colorful, customizable interface of `htop` makes it easier to interpret data and manage processes.
- **Enhanced Interactivity:** Improved interactivity with mouse support and better navigation through large process lists.

#### `ps`

The `ps` (process status) command is a fundamental utility in Unix and Unix-like systems for reporting information about active processes.

##### Key Features of `ps`:

1. **Snapshot View:**
   Unlike `top` and `htop`, which provide real-time monitoring, `ps` gives a snapshot of processes at the time it is invoked.

2. **Flexible Output:**
   Users can specify which attributes of the processes to display, and `ps` can generate a wide variety of reports based on various criteria.

3. **Scriptability:**
   `ps` is highly suitable for inclusion in shell scripts for process monitoring and automation tasks.

##### Common `ps` Options:

- **Standard Syntax (`ps -ef`):**
  ```bash
  ps -ef
  ```
  Displays a full-format listing of all processes.

- **BSD Syntax (`ps aux`):**
  ```bash
  ps aux
  ```
  Lists all processes with detailed information, including user, CPU and memory usage, process state, start time, and command.

- **Custom Columns (`ps -eo`):**
  ```bash
  ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu
  ```
  Displays specific columns, in this case, process ID (pid), parent process ID (ppid), command (cmd), memory usage (%mem), and CPU usage (%cpu), sorted by CPU usage.

##### Using `ps` in Shell Scripts:

The `ps` command is invaluable in shell scripts for monitoring and managing processes. Here's a simple example script in Bash to alert if a critical process is not running:

```bash
#!/bin/bash

# Define the critical process name
critical_process="my_critical_process"

# Check if the process is running
if ! pgrep -x "$critical_process" > /dev/null; then
    echo "$critical_process is not running. Restarting the process..."
    /path/to/$critical_process &
else
    echo "$critical_process is running."
fi
```

This script uses `pgrep` to check for the presence of the critical process and restarts it if not found.

#### Comparative Analysis

Both `top`, `htop`, and `ps` are indispensable tools for process management, each with its unique strengths.

- **`top`:** Best suited for real-time monitoring with basic interactive capabilities.
- **`htop`:** Offers an enhanced, user-friendly interface with advanced features for real-time monitoring and interaction.
- **`ps`:** Ideal for snapshot views of processes and flexible, scriptable reporting.

#### Summary

In this subchapter, we have explored the essential tools for process scheduling analysis in Linux: `top`, `htop`, and `ps`. These utilities provide different perspectives and functionalities for monitoring and managing processes, from real-time interactive interfaces to highly customizable and scriptable outputs. By mastering these tools, users can effectively analyze system performance, identify bottlenecks, and optimize resource utilization, thereby ensuring the smooth and efficient operation of Linux systems.

### Scheduling Tracing with `perf` and `ftrace`

#### Introduction

To gain deep insights into process scheduling and performance bottlenecks in a Linux system, simply observing CPU and memory usage with tools like `top`, `htop`, and `ps` is often insufficient. For a more granular view, we need to delve into the kernel's inner workings using tracing tools. `perf` and `ftrace` are powerful Linux tracing utilities designed to profile and trace various aspects of kernel and user-space performance. This chapter explores the capabilities of `perf` and `ftrace` for scheduling analysis, their applications, and practical usage scenarios.

#### `perf`

`perf` is a performance analysis tool in Linux that provides both software and hardware event sampling capabilities. It is part of the Linux kernel's performance monitoring framework and can be used to analyze CPU performance, trace system calls, profile hardware counters, and much more.

##### Key Features of `perf`:

1. **Event Sampling:**
   `perf` can capture samples of various events such as CPU cycles, cache misses, and scheduling events. This allows for the identification of performance bottlenecks.

2. **Tracing:**
   `perf` can trace function calls, interruptions, and scheduling events, capturing detailed traces of system activity.

3. **Statistical Analysis:**
   `perf` provides statistical summaries of collected data, offering insights into distributions, averages, and other statistical measures.

##### Installing `perf`:

`perf` comes as part of the Linux kernel, but its user-space utilities may need to be installed. On Debian-based systems, you can install it with:
```bash
sudo apt-get install linux-tools-common linux-tools-generic
```

On RPM-based systems, use:
```bash
sudo yum install perf
```

##### Using `perf` for Scheduling Analysis:

One of the primary uses of `perf` in scheduling analysis is to obtain insights into scheduling latency, context switches, and other scheduling-related events.

###### Example: Measuring Context Switches

To collect data about context switches and interrupts, you can use the following command:
```bash
sudo perf stat -e context-switches,interrupts sleep 10
```

This command measures the number of context switches and interrupts that occur over a 10-second period.

###### Example: Tracing Scheduling Events

To trace scheduling events, you can use:
```bash
sudo perf record -e sched:sched_switch -a sleep 10
sudo perf report
```

In this example, `perf` records scheduling switch events (`sched_switch`) system-wide for 10 seconds, and `perf report` processes and displays the recorded data.

##### Internals of `perf`:

- **Event Types:** `perf` supports various event types including hardware events (such as CPU cycles and cache references), software events (such as context switches and page faults), and tracepoints (such as scheduler events and system calls).
  
- **Overhead:** The overhead introduced by `perf` is generally minimal, but it can vary based on the type and frequency of events being recorded.

##### Limitations of `perf`:

- **Complexity:** `perf` offers extensive capabilities, but its complexity can be daunting for beginners.
- **Intrusiveness:** Although `perf` is designed to be low-overhead, excessive tracing can impact system performance.

#### `ftrace`

`ftrace` is the Linux kernel's official tracer. It is highly flexible and can trace virtually any part of the kernel. Unlike `perf`, which focuses on performance analysis, `ftrace` is designed for in-depth kernel tracing.

##### Key Features of `ftrace`:

1. **Dynamic Tracing:**
   `ftrace` can dynamically enable and disable tracing for specific events and functions. This flexibility allows for targeted analysis without a complete system overhaul.

2. **High Granularity:**
   `ftrace` provides detailed trace information, including function entry and exit, scheduling events, interrupts, and more.

3. **Customizable Output:**
   Trace output can be highly customized, allowing users to filter and format trace data to suit their needs.

##### Enabling `ftrace`:

`ftrace` is integrated into the Linux kernel, but it needs to be enabled. This is typically done via the `/sys/kernel/debug/tracing` directory.

To enable tracing, ensure the `debugfs` filesystem is mounted:
```bash
sudo mount -t debugfs none /sys/kernel/debug
```

##### Using `ftrace` for Scheduling Analysis:

###### Example: Enabling Basic Tracing

To enable basic function tracing:
```bash
echo function > /sys/kernel/debug/tracing/current_tracer
echo 1 > /sys/kernel/debug/tracing/tracing_on
```

To stop tracing:
```bash
echo 0 > /sys/kernel/debug/tracing/tracing_on
```

The trace output can be viewed in `/sys/kernel/debug/tracing/trace`.

###### Example: Tracing Scheduling Events

To trace scheduling switch events:
```bash
echo sched_switch > /sys/kernel/debug/tracing/set_event
echo 1 > /sys/kernel/debug/tracing/tracing_on
```

The trace can later be analyzed from the `/sys/kernel/debug/tracing/trace` file.

##### Internals of `ftrace`:

- **Tracing Mechanism:** `ftrace` hooks into the kernel's function entry and exit points as well as other key places such as scheduling switches and interrupts.
  
- **Event Filters:** Users can specify which functions or events to trace using filter files like `/sys/kernel/debug/tracing/set_ftrace_filter`.

- **Overhead:** The overhead varies based on the level of tracing enabled. Simple function tracing incurs less overhead compared to full context trace.

##### Limitations of `ftrace`:

- **Expertise Required:** Effective use of `ftrace` requires a deep understanding of kernel internals and the specific tracing needs.
- **Data Volume:** Detailed tracing can generate large volumes of data, necessitating careful management and filtering.

#### Practical Considerations

##### Combining `perf` and `ftrace`:

In many scenarios, the most comprehensive insights are obtained by combining `perf` and `ftrace`. For example, `perf` can be used for high-level performance analysis to identify bottlenecks, and `ftrace` can then be employed for detailed tracing of the suspected problematic areas.

###### Example Workflow:

1. **Initial Profiling with `perf`:**
   Use `perf` to identify high context switch rates or scheduling latencies.
   ```bash
   sudo perf stat -e context-switches,task-clock,cpu-migrations sleep 10
   ```

2. **Detailed Tracing with `ftrace`:**
   Once a potential issue is identified, employ `ftrace` to trace specific scheduling events.
   ```bash
   echo 'sched:sched_switch' > /sys/kernel/debug/tracing/set_event
   echo 1 > /sys/kernel/debug/tracing/tracing_on
   ```

##### Real-World Applications:

- **Performance Tuning:**
  By identifying and analyzing scheduling latencies and context switches, both `perf` and `ftrace` can directly contribute to optimizing system performance.

- **Debugging:**
  Detailed trace data can help diagnose complex issues related to process scheduling, such as deadlocks or race conditions.

- **Capacity Planning:**
  Understanding scheduling dynamics at a granular level aids in better predicting how a system will perform under different loads.

#### Summary

In this subchapter, we have thoroughly explored the use of `perf` and `ftrace` for scheduling analysis in Linux. `perf` provides a robust framework for performance monitoring and event tracing, offering statistical summaries and real-time analysis capabilities. `ftrace`, with its detailed and granular tracing capabilities, allows users to capture and analyze specific kernel-level events. By mastering these tools, users can gain invaluable insights into the performance characteristics and scheduling behavior of Linux systems, enabling more effective troubleshooting, optimization, and capacity planning.

### Case Studies and Examples

#### Introduction

To truly understand and appreciate the power of scheduling analysis tools such as `top`, `htop`, `ps`, `perf`, and `ftrace`, nothing beats real-world examples and case studies. In this subchapter, we will go through detailed scenarios that demonstrate how these tools can be used to diagnose and resolve performance problems, optimize system resources, and achieve better system stability. By examining these cases, you will gain a thorough understanding of applying theoretical knowledge to practical, real-world problems.

#### Case Study 1: High CPU Usage

##### Scenario

A server running multiple applications starts to exhibit high CPU usage, leading to sluggish performance and delayed response times. Our goal is to identify which process or processes are responsible and why.

##### Step-by-Step Analysis

1. **Initial Diagnosis with `top`**

   Start by running `top` to get a real-time view of CPU usage. 
   ```bash
   top
   ```

   Observe the %CPU column and take note of the processes with the highest CPU usage. In this case, let's assume we find a process named `data_analyzer` occupying over 90% of CPU resources.

2. **Detailed Analysis with `htop`**

   Switch to `htop` for a more user-friendly interface.
   ```bash
   htop
   ```

   Using `htop`, we can further filter by the `data_analyzer` process and explore its threads by pressing `F5` for tree mode. This displays all child processes and threads, helping us to narrow down the specific thread that might be causing the issue.

3. **Event Sampling with `perf`**

   Once `data_analyzer` is identified, use `perf` to collect data about CPU cycles and context switches.
   ```bash
   sudo perf record -e cycles -p <PID_of_data_analyzer> sleep 10
   sudo perf report
   ```

   By analyzing the `perf` report, we can see which functions within the `data_analyzer` process are consuming the most CPU cycles. Suppose we find that a function responsible for data sorting is consuming an inordinate amount of CPU.

4. **Detailed Tracing with `ftrace`**

   Enable detailed tracing for the problematic function using `ftrace`.
   ```bash
   echo function_graph > /sys/kernel/debug/tracing/current_tracer
   echo 'data_analyzer:sort_function' > /sys/kernel/debug/tracing/set_ftrace_filter
   echo 1 > /sys/kernel/debug/tracing/tracing_on
   ```

   The trace data will provide insights into why this particular function is consuming so many CPU cycles, revealing perhaps that inefficient sorting algorithms or large data sets are at play.

##### Conclusion

The root cause of high CPU usage was an inefficient sorting algorithm in the `data_analyzer` application. By replacing this with a more optimized sorting algorithm, or by dividing the data into smaller chunks, we resolved the high CPU usage issue.

#### Case Study 2: Scheduling Latency

##### Scenario

A real-time application on an embedded system is experiencing intermittent latency, causing it to fail occasionally. Our objective is to identify the source of latency.

##### Step-by-Step Analysis

1. **Initial Check with `ps`**

   Use `ps` to get a snapshot of currently running processes and their priorities.
   ```bash
   ps -eo pid,ppid,cmd,pri,rtprio,%cpu --sort=-%cpu
   ```

   Check if the real-time application is running with appropriate priorities. If not, set the process to have a higher real-time priority using the `chrt` command.

   ```bash
   sudo chrt -f -p 99 <PID_of_realtime_app>
   ```

2. **Tracing Latency with `ftrace`**

   Utilize `ftrace` to specifically trace scheduling latency.
   ```bash
   echo latency > /sys/kernel/debug/tracing/current_tracer
   echo 1 > /sys/kernel/debug/tracing/tracing_on
   ```

   The trace log will highlight instances of scheduling latency. Examine the `<trace>` file to find delays between when the process was ready to run and when it was actually scheduled.

3. **Analyzing with `perf sched`**

   Use `perf` to collect scheduling latency stats.
   ```bash
   sudo perf sched record -a
   sudo perf sched latency
   ```

   This command will pinpoint tasks with the longest latencies and show how often the real-time application faced significant scheduling delays.

##### Conclusion

By adjusting the real-time application's priority and identifying background processes with lower priority preempting it, we managed to reduce the scheduling latency. Adjustments to other system processes and the real-time application's configuration ensured more predictable scheduling behavior.

#### Case Study 3: Memory Bottlenecks

##### Scenario

A database application is experiencing performance degradation. Initial indications suggest it may be related to memory management issues. Our goal is to identify and rectify the memory bottleneck.

##### Step-by-Step Analysis

1. **Identifying Memory Usage with `htop`**

   Start by launching `htop` to get an overall view of memory usage.
   ```bash
   htop
   ```

   Look for processes consuming the most memory and investigate if the database application is one of them. Note the total memory and swap space usage, and see if the system is heavily relying on swap.

2. **Detailed Statistics with `ps`**

   Use `ps` to get a detailed view of memory usage by the database application.
   ```bash
   ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem
   ```

   This helps quantify the memory consumption in percentage terms and identify if there are any memory leaks or unusually high memory consumption patterns.

3. **Profiling Memory Usage with `perf`**

   To understand the memory behavior, use `perf` to profile memory access events.
   ```bash
   sudo perf record -e mem_load_uops_retired.l2_miss -e mem_load_uops_retired.l3_miss -p <PID_of_database_app> sleep 10
   sudo perf report
   ```

   This will help identify if the database application is encountering significant cache misses, which could be impacting performance.

4. **Tracing Page Faults with `ftrace`**

   Enable `ftrace` to trace page fault events.
   ```bash
   echo pagefaults > /sys/kernel/debug/tracing/set_event
   echo 1 > /sys/kernel/debug/tracing/tracing_on
   ```

   Analyze the generated trace file to determine if high rates of page faults are causing the database to frequently access slower disk storage.

##### Conclusion

The analysis revealed that the database application was experiencing significant cache misses and page faults, leading to performance degradation. Optimizing the database indexing, increasing the system's physical memory, and fine-tuning the database configuration parameters for better cache usage addressed the memory bottleneck.

#### Advanced Example: End-to-End Scheduling and Resource Management Optimization

##### Scenario

A multi-tier application comprising web servers, application servers, and database servers is observed to have inconsistent performance under high load. Our objective is to perform an end-to-end analysis to optimize scheduling and resource management.

##### Step-by-Step Analysis

1. **System-Wide Profiling with `perf`**

   Begin with a system-wide profiling to capture a holistic view of resource usage and bottlenecks.
   ```bash
   sudo perf top
   ```

   This gives a high-level overview of the most CPU-intensive functions across the entire system, helping to identify where to focus detailed analysis.

2. **Component-Specific Analysis with `htop`**

   Using `htop`, analyze each component (web server, application server, and database server) separately.
   ```bash
   htop
   ```

   Drill down into the processes and threads of each tier, identifying resource hogs or inefficient processes.

3. **Collecting Detailed Metrics with `perf` and `ftrace`**

   For the web server:
   ```bash
   sudo perf record -e cache-misses,cs -p <PID_of_web_server> sleep 10
   sudo perf report
   ```

   For the application server:
   ```bash
   echo function_graph > /sys/kernel/debug/tracing/current_tracer
   echo 'app_server:*' > /sys/kernel/debug/tracing/set_ftrace_filter
   echo 1 > /sys/kernel/debug/tracing/tracing_on
   ```

   Analyze the function graph for inefficient code paths or excessive context switches.

   For the database server:
   ```bash
   sudo perf record -e mem_load_uops_retired.l3_miss -p <PID_of_database_server> sleep 10
   sudo perf report
   ```

   Combine these detailed insights to identify cross-tier bottlenecks such as network delays, inefficient API calls, or database query performance issues.

4. **Implementing Optimization Strategies**

   Based on the collected data:

   - **Web Server:** Optimize caching mechanisms to reduce CPU load and response time.
   - **Application Server:** Refactor inefficient code paths identified through function tracing.
   - **Database Server:** Index frequently accessed tables and queries, and increase physical RAM to reduce page faults.

5. **Validating Optimizations**

   Perform a second round of profiling using `perf` and `ftrace` to validate the applied optimizations.
   ```bash
   sudo perf stat -a 
   ```

   Re-run the application under high load and compare the performance metrics before and after optimization.

##### Conclusion

By conducting an end-to-end analysis using `perf` and `ftrace`, we achieved significant performance improvements across the multi-tier application. Web server response times improved due to better caching, application server latency reduced thanks to optimized code paths, and database performance stabilized through better indexing and memory management.

#### Summary

This subchapter provided detailed case studies and examples to illustrate how process scheduling and resource management tools can be used to diagnose and resolve real-world performance issues. Through step-by-step analysis and problem resolution, we've demonstrated the practical applications of `top`, `htop`, `ps`, `perf`, and `ftrace`. Mastery of these tools enables system administrators and developers to maintain high-performance and stable Linux systems, capable of handling diverse workloads and unexpected challenges.

