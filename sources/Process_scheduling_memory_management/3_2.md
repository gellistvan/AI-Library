\newpage

## 10. Memory Allocation

Chapter 10 of this book dives into the intricacies of memory allocation in Linux, a critical aspect of memory management that ensures efficient use of hardware resources and guarantees system stability and performance. At the heart of this process are several sophisticated allocation strategies, each designed to meet the specific needs of different scenarios and workloads. We begin by exploring the Buddy System Allocator, a fundamental algorithm that balances simplicity and fragmentation control. Next, we delve into the more specialized Slab, SLUB, and SLOB allocators, which provide optimized solutions for kernel object caching, catering to diverse use cases from high-performance systems to small embedded devices. Finally, we will examine user-space memory allocation with functions like `malloc` and `free`, demystifying how user applications interact with the underlying operating system to manage memory dynamically. This chapter aims to provide a comprehensive understanding of these allocation mechanisms, their design principles, and their impact on the Linux operating system's performance and reliability.

### Buddy System Allocator

The Buddy System Allocator is a memory allocation and management algorithm designed for efficient and quick allocation and deallocation of memory. Its simplicity in addressing memory fragmentation and its relatively low overhead make it a popular choice for memory management in both operating system kernels and user-space libraries. In this subchapter, we will explore the architecture, operational principles, advantages, disadvantages, and practical implementation details of the Buddy System Allocator in Linux.

#### Historical Context and Development

The Buddy System Allocator was first introduced by Donald Knuth in "The Art of Computer Programming," and later refined by Knowlton in 1965. The allocation strategy is inspired by binary tree structures where each node can be divided or merged based on allocation requests, ensuring that memory blocks are always power-of-two sizes. This characteristic is pivotal in maintaining the efficiency of the algorithm.

#### Basic Principles

The Buddy System works on the principle of dividing and coalescing memory blocks to satisfy dynamic memory requests. The core idea is to maintain multiple lists of free blocks, each of a size that is a power of two. When an allocation request is made, the system searches for the smallest available block that can accommodate the request. If no such block exists, a larger block is divided ("split") into two smaller "buddy" blocks recursively until the required size is obtained. The reverse process happens during deallocation, where freed blocks are potentially merged ("coalesced") with their buddies to form larger blocks.

##### Key Concepts

1. **Memory Block**: A contiguous segment of memory.
2. **Buddy**: Two memory blocks of the same size that have a specific relationship based on their addresses.
3. **Splitting**: Dividing a larger memory block into two smaller buddy blocks.
4. **Coalescing**: Combining two buddy blocks to form a larger block.

#### Data Structures

The Buddy System utilizes several fundamental data structures:

1. **Free Lists**: An array of linked lists, each corresponding to a power-of-two size class. Each linked list contains memory blocks of a specific size.
2. **Bitmaps**: Sometimes used to manage the status (free or allocated) of each block and facilitate quick searches and merges.

In a typical Linux implementation, the free lists are organized as arrays where the index represents the order (size class) of blocks (e.g., index 0 for 2^0 bytes, index 1 for 2^1 bytes, and so on).

#### Allocation Process

The allocation process in the Buddy System involves the following steps:

1. **Determine the Block Size**: Identify the size class that can accommodate the requested memory size (usually rounded up to the nearest power of two).
2. **Search for a Free Block**: Traverse the free list corresponding to the identified size class. If a free block is found, it is removed from the list and allocated.
3. **Split Larger Blocks**: If no free block of the required size is available, move to the next higher size class, split a block from that class, and add the resulting buddies to the appropriate lower size class lists. This process repeats until a suitable block is obtained.
4. **Return the Block**: Return the allocated block to the requester.

The efficiency of this process relies heavily on the speed of splitting blocks, which is relatively quick due to the binary nature of the operation.

#### Deallocation Process

The deallocation process involves:

1. **Identify the Address and Size**: Determine the starting address and size class of the block being freed.
2. **Locate the Buddy**: Calculate the address of the buddy block using the formula: 
   
   $$
   \text{Buddy Address} = \text{Block Address} \oplus \text{Block Size}
   $$

   The XOR operation ensures that the buddy address is found based on the block size.

3. **Coalesce with the Buddy**: Check if the buddy block is free. If it is, remove the buddy block from its free list, merge the buddies to form a larger block, and repeat the process with the new block size. If the buddy is not free, add the block to its appropriate free list.

4. **Update Free Lists**: Ensure that the free lists are consistently updated to reflect the state of memory blocks.

#### Advantages and Disadvantages

##### Advantages

1. **Simplicity**: The algorithm is relatively straightforward to implement and understand.
2. **Efficiency**: Operations of allocation and deallocation are efficient, with time complexity typically being O(log N), where N is the total number of blocks.
3. **Reduced Fragmentation**: Internal fragmentation is minimized due to the power-of-two allocation strategy, but external fragmentation can still occur.

##### Disadvantages

1. **Memory Waste**: The power-of-two block sizes can lead to over-allocation if the actual request size is not a power of two, causing internal fragmentation.
2. **Complex Coalescing**: The merge process can become complex and time-consuming, especially in systems with frequent allocation and deallocation.
3. **Limited Flexibility**: The rigid block size can be less flexible for certain types of workloads requiring very large or very small memory blocks.

#### Practical Considerations

In practice, Linux implements the Buddy System within its kernel memory management subsystem to manage physical pages of memory. It works alongside other allocators like Slab, SLUB, and SLOB to handle different memory allocation scenarios.

##### Code Example in C

Here is a simplified example of a Buddy System Allocator in C:

```c
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

#define MAX_ORDER 10 // Define maximum order (2^10 is 1024)

typedef struct Block {
    struct Block* next;
} Block;

Block* freeLists[MAX_ORDER + 1];

void initializeBuddySystem() {
    for (int i = 0; i <= MAX_ORDER; i++) {
        freeLists[i] = NULL;
    }
}

void* allocateBlock(int order) {
    if (order > MAX_ORDER) {
        return NULL;
    }

    if (!freeLists[order]) {
        void* higherOrderBlock = allocateBlock(order + 1);
        if (!higherOrderBlock) {
            return NULL;
        }

        Block* buddy = (Block*)((char*)higherOrderBlock + (1 << order));
        freeLists[order] = buddy;
    }

    Block* block = freeLists[order];
    freeLists[order] = block->next;
    return block;
}

void freeBlock(void* block, int order) {
    Block* buddy = (Block*)((unsigned long)block ^ (1 << order));
    bool foundBuddy = false;

    Block** curr = &freeLists[order];
    while (*curr) {
        if (*curr == buddy) {
            foundBuddy = true;
            *curr = buddy->next;
            break;
        }
        curr = &(*curr)->next;
    }

    if (foundBuddy) {
        freeBlock((void*)((unsigned long)block & buddy), order + 1);
    } else {
        Block* newBlock = (Block*)block;
        newBlock->next = freeLists[order];
        freeLists[order] = newBlock;
    }
}

int main() {
    initializeBuddySystem();
    void* block = allocateBlock(3);
    freeBlock(block, 3);
    return 0;
}
```

This code provides a rudimentary implementation of the Buddy System Allocator. The `Block` structure represents a memory block, and the `freeLists` array manages the free blocks by order. The `initializeBuddySystem` function initializes the free lists, and the `allocateBlock` and `freeBlock` functions handle allocation and deallocation, respectively.

#### Conclusion

The Buddy System Allocator is a foundational memory management technique that balances efficiency with simplicity. Its ability to quickly allocate and deallocate memory blocks while minimizing fragmentation makes it a valuable tool in both operating system kernels and other critical software systems. However, its limitations suggest the need for complementary allocators to address specific memory management challenges. Understanding the Buddy Systemâ€™s principles and implementation provides a solid foundation for grasping more advanced memory management concepts in Linux.

### Slab, SLUB, and SLOB Allocators

Memory management within the Linux kernel is a complex affair, given the diverse and often rigorous requirements of system and application processes. Beyond the fundamental Buddy System, Linux employs specialized memory allocators designed for more efficient and targeted allocation of memory. These are the Slab, SLUB (Slab Unifying Layer), and SLOB (Simple List of Blocks) allocators. Each of these allocators addresses specific operational requirements and usage scenarios in the Linux kernel. In this chapter, we will delve into the intricacies of these allocators, examining their architecture, operational principles, advantages, disadvantages, and real-world implementations.

#### Historical Context and Development

The necessity for specialized memory allocators arose from the need to handle frequent and small-sized memory allocations and deallocations efficiently. While the Buddy System provides a generalized framework, it is not well-suited for managing numerous small objects, which can result in significant fragmentation and inefficiency.

1. **Slab Allocator**: Introduced by Jeff Bonwick for the Solaris operating system, the Slab Allocator was later adapted into Linux to manage kernel objects efficiently.
2. **SLUB Allocator**: SLUB, introduced by Christoph Lameter, aimed to improve upon the Slab Allocator by streamlining the allocation process and reducing fragmentation.
3. **SLOB Allocator**: Designed by Matt Mackall, SLOB is a minimalist allocator tailored for small embedded systems requiring a minimal memory footprint.

#### Slab Allocator

The Slab Allocator is designed to serve memory requests quickly, minimize fragmentation, and efficiently manage small, frequently-used objects in the kernel. Its key features are based on caching techniques to keep pre-initialized memory objects readily available.

##### Architectural Components

1. **Caches**: The Slab Allocator organizes memory into caches, each designed to store objects of a specific type and size. Caches are pre-initialized to reduce allocation latency.
2. **Slabs**: Each cache is divided into slabs. A slab is a contiguous block of memory that contains multiple objects, often with additional metadata for efficient management.
3. **Object States**: Objects within a slab can be in three states: free, in-use, and full. Free objects are available for allocation, in-use objects are currently allocated, and full objects fill the slab entirely, leaving no free space.

##### Allocation and Deallocation

- **Allocation**: When a request for a specific object type is made, the allocator searches the corresponding cache. If no free objects are available, a new slab is allocated from the Buddy System, initialized, and added to the cache. The allocator then returns an object from the slab.
- **Deallocation**: Freed objects are marked as free and often stored in a freelist within the slab. If all objects in a slab are freed, the slab can be returned to the Buddy System.

##### Advantages and Disadvantages

- **Advantages**: Fast allocation and deallocation, reduction in fragmentation through object reuse, and reduced initialization times due to pre-initialized objects.
- **Disadvantages**: Higher memory overhead due to metadata and slab management structures, which can lead to inefficiency for larger allocations.

#### SLUB Allocator

The SLUB Allocator was developed to address the limitations of the Slab Allocator, particularly in terms of complexity and fragmentation. SLUB aims to simplify the allocation process and reduce the overhead associated with slab management.

##### Architectural Components

1. **Single Cache**: Unlike the Slab Allocator, SLUB employs a single central freelist for each object size, simplifying memory management.
2. **Slabs and Pages**: SLUB uses pages to create slabs, but avoids the complex metadata structures of the Slab Allocator, instead opting for direct freelists and pointers.
3. **Deferred Coalescing**: SLUB can defer the coalescing of free objects to optimize performance.

##### Allocation and Deallocation

- **Allocation**: SLUB searches the central freelist for a free object. If none are available, it allocates a new page from the Buddy System, divides it into objects, and updates the freelist.
- **Deallocation**: Freed objects are added back to the freelist. SLUB employs a less aggressive coalescing strategy compared to Slab, focusing on reducing fragmentation over time.

##### Advantages and Disadvantages

- **Advantages**: Lower memory overhead due to reduced metadata, simpler and faster allocation and deallocation, and better scalability in high-load scenarios.
- **Disadvantages**: Potential for longer allocation times in some cases due to deferred coalescing, and more complexity in freelist management compared to Slab.

#### SLOB Allocator

The SLOB Allocator is a minimalist memory allocator designed for small, embedded systems with limited resources. Its primary goal is to minimize memory overhead and complexity.

##### Architectural Components

1. **Single Linked List**: SLOB uses a single linked list to manage free memory blocks, maintaining simplicity.
2. **Minimal Metadata**: To reduce overhead, SLOB employs minimal metadata, often embedding it within the allocated blocks themselves.
3. **Exact Fit Allocation**: SLOB attempts to find the best-fitting free block to fulfill allocation requests, reducing memory waste.

##### Allocation and Deallocation

- **Allocation**: SLOB traverses the free list to find a suitable block that matches the size of the allocation request. It splits the block if necessary and returns the address to the requester.
- **Deallocation**: Freed blocks are added back to the free list. SLOB merges adjacent free blocks to reduce fragmentation.

##### Advantages and Disadvantages

- **Advantages**: Extremely low memory overhead, simple implementation, and ideal for small systems with limited resources.
- **Disadvantages**: Potential inefficiency for larger systems due to linear free list traversal, and higher fragmentation compared to Slab and SLUB.

#### Comparative Analysis

To understand the trade-offs between these allocators, it is useful to compare them across various dimensions:

1. **Performance**: SLUB offers the best performance in high-load scenarios due to its streamlined approach. Slab provides good performance but can introduce overhead. SLOB, while slower, excels in minimal overhead environments.
2. **Fragmentation**: Both Slab and SLUB manage fragmentation effectively through object reuse and deferred coalescing, respectively. SLOB can suffer from fragmentation due to its linear free list traversal.
3. **Memory Overhead**: SLOB has the lowest overhead, making it suitable for embedded systems. Slab and SLUB have higher overhead due to metadata, but SLUB's simplified structures offer advantages over Slab.
4. **Simplicity**: SLOB wins in simplicity, followed by SLUB, and then Slab which has the most complex structures.

#### Real-World Implementations

In the Linux kernel, each allocator serves a specific purpose based on system requirements:

- **Slab**: Predominantly used in scenarios where quick allocation and deallocation of small objects are crucial.
- **SLUB**: Adopted in modern Linux kernels as the default allocator due to its balanced approach, scalability, and reduced complexity.
- **SLOB**: Utilized in small and embedded devices where memory resources are limited.

#### Conclusion

The Slab, SLUB, and SLOB allocators represent the evolution of memory management strategies in the Linux kernel. Each allocator is tailored to optimize performance, reduce fragmentation, and minimize overhead based on specific usage scenarios. Understanding these allocators' operational principles and trade-offs is crucial for kernel developers and system architects aiming to fine-tune system performance and reliability. Through detailed architectural and functional analyses, this chapter has provided a comprehensive overview of these critical components in Linux memory management, equipping readers with the knowledge needed to make informed decisions about their use and optimization.

### User-Space Memory Allocation (malloc, free)

Memory management in user-space processes involves several sophisticated techniques and algorithms to ensure efficient allocation and deallocation of memory. In the realm of user-space programming, the `malloc` and `free` functions are the cornerstone of dynamic memory management. These functions provide a high-level interface for allocating and freeing memory, abstracting the complexities of underlying memory management and operating system interactions.

This chapter delves into the intricate details of user-space memory allocation, discussing the architecture, algorithms, challenges, and optimizations involved. We will explore the internal workings of `malloc` and `free`, examining how these functions manage memory at a granular level, and how they interact with the operating system to handle memory requests efficiently.

#### Historical Context and Background

The history of dynamic memory allocation dates back to the early days of computing when developers needed a mechanism to allocate memory dynamically during the execution of programs. The `malloc` (memory allocation) function was introduced in the C programming language as part of the standard library (stdlib.h) to fulfill this need.

With the development of more complex software systems, efficient memory management became increasingly critical. Over time, various algorithms and data structures were introduced to optimize `malloc` and `free` operations, leading to the sophisticated implementations found in modern systems.

#### Allocation Algorithms

The core functionality of `malloc` involves several complex algorithms designed to allocate memory efficiently while minimizing fragmentation and overhead. Some of the most common algorithms include:

1. **First-Fit Allocation**: This algorithm searches for the first available block of memory that is large enough to satisfy the allocation request. While simple, it can lead to fragmentation over time as small holes are left behind.

2. **Best-Fit Allocation**: This algorithm searches for the smallest block of memory that is sufficient for the request. While it can reduce fragmentation, it is computationally expensive due to the need for a complete search.

3. **Next-Fit Allocation**: This is a variation of the first-fit algorithm where the search continues from the point of the last allocation. It aims to distribute free space more evenly but can still lead to fragmentation.

4. **Buddy System Allocation**: As discussed in previous chapters, the Buddy System can also be used in user-space allocation. It involves dividing memory into blocks of power-of-two sizes and efficiently merging and splitting blocks to meet allocation requests.

5. **Segregated Free Lists**: This algorithm involves maintaining separate free lists for different size classes of memory blocks. It allows for quick allocation and deallocation by restricting searches to relevant lists.

6. **Memory Pools**: This technique involves pre-allocating a large block of memory and sub-allocating from it as needed. It is particularly useful for managing small, frequently used objects.

#### The `malloc` Function

The `malloc` function is responsible for allocating a specified amount of memory and returning a pointer to the allocated block. Internally, it involves several key steps:

1. **Size Alignment**: The requested size is often rounded up to a multiple of a specific alignment boundary to ensure proper alignment.

2. **Search for Free Block**: The allocator searches for a free block that can accommodate the request. Depending on the algorithm used, this may involve searching a free list, checking the Buddy System, or consulting a segregated list.

3. **Split Block**: If a larger block is found, it may be split into two smaller blocks to fulfill the request, with the remaining block added back to the free list.

4. **Update Metadata**: The allocator updates metadata to track allocated and free blocks. This may involve setting headers and footers or updating bitmaps.

5. **Return Pointer**: The allocator returns a pointer to the allocated block, ready for use by the application.

#### The `free` Function

The `free` function is responsible for deallocating a previously allocated block of memory, making it available for future allocations. The process involves several steps:

1. **Locate Block**: The allocator identifies the block to be freed using the pointer provided.

2. **Verify Validity**: To prevent errors and security vulnerabilities, the allocator verifies that the block was indeed allocated and is not already freed.

3. **Coalesce Blocks**: The allocator attempts to merge the freed block with adjacent free blocks to form a larger block, reducing fragmentation.

4. **Update Metadata**: The allocator updates metadata to reflect the deallocation, marking the block as free and adding it back to the appropriate free list or pool.

#### Memory Fragmentation

Memory fragmentation is a significant challenge in dynamic memory allocation. It occurs when free memory is split into small, non-contiguous blocks, making it difficult to satisfy larger allocation requests. Fragmentation can be categorized into two types:

1. **External Fragmentation**: Occurs when the total free memory is sufficient to satisfy an allocation request, but it is split into non-contiguous blocks. This makes it impossible to allocate a single large block of memory.

2. **Internal Fragmentation**: Occurs when allocated memory blocks are larger than the requested size, leading to wasted memory within the allocated blocks. This is often due to size alignment and rounding.

#### Optimizations and Enhancements

Various techniques have been implemented to optimize memory allocation and reduce fragmentation. Some notable techniques include:

1. **Garbage Collection**: In certain user-space environments like managed languages (e.g., Java, Python), garbage collection automatically reclaims memory that is no longer in use, reducing manual `free` operations and minimizing fragmentation.

2. **Deferred Coalescing**: Instead of coalescing freed blocks immediately, deferred coalescing delays the merge process to reduce computational overhead and improve allocation speed.

3. **Memory Compaction**: This technique involves moving allocated objects to consolidate free space, reducing fragmentation. It is commonly used in garbage-collected environments.

4. **Mmap-based Allocation**: For large allocations, `malloc` may use `mmap` system calls to allocate memory directly from the operating system, bypassing the heap and reducing fragmentation in the main heap.

5. **Custom Allocators**: Applications with specific memory allocation patterns can implement custom allocators optimized for their requirements. Custom allocators can improve performance by tailoring allocation strategies to the application's needs.

#### Practical Implementation

In modern systems, the implementation of `malloc` and `free` is often contained within the C standard library (e.g., GNU C Library or glibc). Here, we provide a simplified overview of how `malloc` and `free` might be implemented in user-space.

##### Code Example in C

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/mman.h>

#define ALIGNMENT 8
#define PAGE_SIZE 4096

typedef struct Block {
    size_t size;
    struct Block* next;
} Block;

Block* freeList = NULL;

void* align(size_t size) {
    return (void*)((size + (ALIGNMENT - 1)) & ~(ALIGNMENT - 1));
}

void splitBlock(Block* block, size_t size) {
    Block* newBlock = (Block*)((char*)block + size + sizeof(Block));
    newBlock->size = block->size - size - sizeof(Block);
    newBlock->next = block->next;
    block->size = size;
    block->next = newBlock;
}

void* malloc(size_t size) {
    size = (size_t)align(size);
    Block* prev = NULL;
    Block* curr = freeList;
    
    while (curr && curr->size < size) {
        prev = curr;
        curr = curr->next;
    }
    
    if (!curr) {
        size_t totalSize = size + sizeof(Block);
        size_t pages = (totalSize + PAGE_SIZE - 1) / PAGE_SIZE;
        curr = mmap(0, pages * PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
        
        if (curr == MAP_FAILED) {
            return NULL;
        }
        
        curr->size = pages * PAGE_SIZE - sizeof(Block);
        curr->next = NULL;
    }
    
    if (curr->size > size + sizeof(Block)) {
        splitBlock(curr, size);
    }
    
    if (prev) {
        prev->next = curr->next;
    } else {
        freeList = curr->next;
    }
    
    return (void*)((char*)curr + sizeof(Block));
}

void free(void* ptr) {
    if (!ptr) {
        return;
    }
    
    Block* block = (Block*)((char*)ptr - sizeof(Block));
    block->next = freeList;
    freeList = block;
}

int main() {
    void* block1 = malloc(100);
    void* block2 = malloc(200);
    free(block1);
    void* block3 = malloc(50);
    free(block2);
    free(block3);
    return 0;
}
```

This example demonstrates a basic implementation of `malloc` and `free` using a linked list and `mmap` for large allocations. While it captures the essence of dynamic memory allocation, real-world implementations are far more sophisticated, incorporating additional optimizations and safety checks.

#### Conclusion

Understanding user-space memory allocation through `malloc` and `free` is essential for developing efficient and robust applications. This chapter examined the internal workings, allocation algorithms, common challenges, and optimizations associated with these functions. By exploring the intricacies of dynamic memory allocation, memory fragmentation, and various optimization techniques, we gain valuable insights into the fundamental principles of memory management in user-space. This knowledge equips developers with the tools and understanding necessary to create applications that are both efficient and reliable, enhancing overall system performance and stability.

