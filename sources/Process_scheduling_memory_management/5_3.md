\newpage

## 21. Appendix C: Example Code and Exercises 

### Sample Programs Demonstrating Key Concepts
### Exercises for Practice

In this appendix, we provide practical examples and hands-on exercises to reinforce the theoretical concepts discussed in earlier chapters. Through carefully constructed sample programs, you will gain a deeper understanding of process scheduling and memory management in Linux. These examples illustrate key principles and offer a glimpse into real-world applications. Following the sample code, we present a series of exercises designed to challenge your comprehension and enhance your problem-solving skills. Whether you are a novice looking to solidify your foundational knowledge or an experienced developer seeking to refine your expertise, this appendix offers valuable resources to aid in your learning journey.

### Sample Programs Demonstrating Key Concepts

In this subchapter, we delve into practical examples that elucidate key concepts in process scheduling and memory management in Linux. By examining real-world scenarios and implementing sample programs in C++, Python, and Bash, you will gain a comprehensive understanding of these vital components. Each example is meticulously explained to ensure clarity, providing you with the knowledge to apply these principles in your projects.

#### Process Scheduling

Process scheduling is a fundamental aspect of any operating system, responsible for determining which process runs at any given time. Linux uses various scheduling algorithms to manage process priorities, CPU time allocation, and system responsiveness. We will explore these concepts through examples and provide detailed explanations.

##### First-Come, First-Served (FCFS) Scheduling

The FCFS scheduling algorithm is the simplest form of process scheduling. It queues processes in the order they arrive and executes them sequentially until completion. This non-preemptive approach can lead to the "convoy effect," where shorter processes are delayed by longer ones.

**C++ Example:**

```cpp
#include <iostream>
#include <queue>
using namespace std;

struct Process {
    int id;
    int burst_time;
};

int main() {
    queue<Process> process_queue;
    process_queue.push({1, 5});
    process_queue.push({2, 3});
    process_queue.push({3, 8});

    int current_time = 0;

    while (!process_queue.empty()) {
        Process current_process = process_queue.front();
        process_queue.pop();

        cout << "Process " << current_process.id << " is running from "
             << current_time << " to " << current_time + current_process.burst_time << endl;
        current_time += current_process.burst_time;
    }

    return 0;
}
```

##### Round Robin Scheduling

Round Robin (RR) scheduling is a preemptive algorithm that assigns a fixed time slice, or quantum, to each process in the queue. It cycles through the processes, allowing for a more responsive system by ensuring no single process monopolizes the CPU.

**Python Example:**

```python
class Process:
    def __init__(self, id, burst_time):
        self.id = id
        self.burst_time = burst_time
        self.remaining_time = burst_time

def round_robin_scheduling(process_list, time_quantum):
    time = 0
    queue = process_list[:]
    
    while queue:
        for process in list(queue):
            if process.remaining_time > 0:
                if process.remaining_time > time_quantum:
                    print(f"Process {process.id} runs from {time} to {time + time_quantum}")
                    time += time_quantum
                    process.remaining_time -= time_quantum
                else:
                    print(f"Process {process.id} runs from {time} to {time + process.remaining_time}")
                    time += process.remaining_time
                    queue.remove(process)
                    process.remaining_time = 0

process_list = [Process(1, 5), Process(2, 3), Process(3, 8)]
time_quantum = 2
round_robin_scheduling(process_list, time_quantum)
```

#### Memory Management

Memory management in Linux involves the allocation, utilization, and management of system memory. It includes concepts such as paging, segmentation, and virtual memory, which are critical for efficient system performance.

##### Paging

Paging is a memory management scheme that eliminates the need for contiguous allocation of physical memory. It divides the virtual memory into fixed-size blocks called pages and the physical memory into blocks of the same size called frames. The operating system keeps track of all free frames and maintains a page table for each process.

**C++ Example:**

```cpp
#include <iostream>
#include <vector>
using namespace std;

const int PAGE_SIZE = 4;
const int MEMORY_SIZE = 16;

struct Page {
    int page_id;
    int frame_id;
};

int main() {
    vector<Page> page_table;
    vector<int> memory(MEMORY_SIZE, -1);
    int page_count = 0;

    // Simulating process with 5 pages
    for (int i = 0; i < 5; i++) {
        if (page_count < MEMORY_SIZE / PAGE_SIZE) {
            Page page = {i, page_count};
            page_table.push_back(page);
            for (int j = 0; j < PAGE_SIZE; j++) {
                memory[page_count * PAGE_SIZE + j] = i * PAGE_SIZE + j;
            }
            page_count++;
        } else {
            cout << "Memory is full. Unable to allocate page " << i << endl;
        }
    }

    cout << "Page Table:" << endl;
    for (auto &page : page_table) {
        cout << "Page " << page.page_id << " -> Frame " << page.frame_id << endl;
    }

    cout << "Memory Content:" << endl;
    for (int i = 0; i < MEMORY_SIZE; i++) {
        if (memory[i] != -1)
            cout << "Memory[" << i << "] = " << memory[i] << endl;
        else
            cout << "Memory[" << i << "] is empty" << endl;
    }

    return 0;
}
```

##### Virtual Memory

Virtual memory allows the execution of processes that may not be completely loaded into the physical memory. It utilizes disk space to extend the available memory, enabling the concurrent execution of larger processes.

**Bash Script Example:**

```bash
#!/bin/bash

echo "Virtual Memory Example"

# Create a large file to simulate a process requiring more memory than available
dd if=/dev/zero of=largefile bs=1M count=1024

echo "Created a large file to simulate virtual memory usage"

# Display memory usage
free -h

# Remove the large file to free up space
rm largefile

echo "Cleaned up the large file"
```

##### Demand Paging

Demand paging is a lazy loading mechanism where pages are loaded into memory only when they are accessed. This technique reduces the memory footprint and improves overall system efficiency.

**C++ Example:**

```cpp
#include <iostream>
#include <vector>
using namespace std;

const int PAGE_SIZE = 4;
const int MEMORY_SIZE = 16;

struct Page {
    int page_id;
    int frame_id;
    bool in_memory;
};

int main() {
    vector<Page> page_table(5, {0, 0, false});
    vector<int> memory(MEMORY_SIZE, -1);
    int page_count = 0;

    // Simulate demand paging
    auto access_page = [&](int page_id) {
        if (!page_table[page_id].in_memory) {
            if (page_count < MEMORY_SIZE / PAGE_SIZE) {
                page_table[page_id] = {page_id, page_count, true};
                for (int j = 0; j < PAGE_SIZE; j++) {
                    memory[page_count * PAGE_SIZE + j] = page_id * PAGE_SIZE + j;
                }
                page_count++;
            } else {
                cout << "Memory is full. Unable to load page " << page_id << " into memory" << endl;
                return;
            }
        }
        cout << "Accessing Page " << page_id << " in Frame " << page_table[page_id].frame_id << endl;
    };

    access_page(1);
    access_page(2);
    access_page(4);
    access_page(3);
    access_page(0);

    cout << "Page Table:" << endl;
    for (auto &page : page_table) {
        cout << "Page " << page.page_id << " -> Frame " << page.frame_id
             << (page.in_memory ? " (in memory)" : " (not in memory)") << endl;
    }

    cout << "Memory Content:" << endl;
    for (int i = 0; i < MEMORY_SIZE; i++) {
        if (memory[i] != -1)
            cout << "Memory[" << i << "] = " << memory[i] << endl;
        else
            cout << "Memory[" << i << "] is empty" << endl;
    }

    return 0;
}
```

#### Summary

Through these examples in C++, Python, and Bash, we have demonstrated fundamental concepts in process scheduling and memory management. Each example was crafted to illustrate the principles and challenges associated with these topics. By analyzing the sample programs, you gain insights into efficient process management and memory utilization, which are crucial for developing robust and high-performance systems.

By incorporating these practical examples into your study, you can bridge the gap between theoretical knowledge and real-world application. This foundational understanding will empower you to tackle more complex problems and optimize your systems effectively.

### Exercises for Practice

In this subchapter, we present a series of exercises designed to deepen your understanding of process scheduling and memory management in Linux. These exercises cover a wide range of topics and difficulty levels, providing opportunities to apply theoretical concepts to practical problems. Each exercise includes a detailed explanation of its objectives and expected outcomes. Where applicable, solutions or hints are provided to guide you. These exercises will not only test your knowledge but also enhance your problem-solving skills.

#### Exercise 1: Implementing FCFS Scheduling

**Objective:** Write a program to simulate the First-Come, First-Served (FCFS) scheduling algorithm.

**Task Description:**

1. Create a list of processes with their respective burst times and arrival times.
2. Sort the processes based on their arrival times.
3. Implement the FCFS algorithm to calculate the waiting time and turnaround time for each process.
4. Output the waiting time and turnaround time for each process, along with the average waiting time and average turnaround time.

**Expected Outcome:**
- Understanding how the FCFS algorithm schedules processes.
- Ability to calculate waiting and turnaround times.

**Example Code:**

```python
class Process:
    def __init__(self, id, burst_time, arrival_time):
        self.id = id
        self.burst_time = burst_time
        self.arrival_time = arrival_time
        self.waiting_time = 0
        self.turnaround_time = 0

def fcfs_scheduling(processes):
    processes.sort(key=lambda x: x.arrival_time)
    current_time = 0

    for process in processes:
        if current_time < process.arrival_time:
            current_time = process.arrival_time
        process.waiting_time = current_time - process.arrival_time
        current_time += process.burst_time
        process.turnaround_time = process.waiting_time + process.burst_time

processes = [
    Process(1, 5, 0),
    Process(2, 3, 1),
    Process(3, 8, 2)
]

fcfs_scheduling(processes)

for process in processes:
    print(f"Process {process.id}: Waiting Time = {process.waiting_time}, Turnaround Time = {process.turnaround_time}")
```

#### Exercise 2: Simulating Round Robin Scheduling

**Objective:** Write a program to simulate the Round Robin (RR) scheduling algorithm with a given time quantum.

**Task Description:**

1. Create a list of processes with their respective burst times and arrival times.
2. Implement the Round Robin scheduling algorithm with a specified time quantum.
3. Calculate the waiting time and turnaround time for each process.
4. Output the waiting time and turnaround time for each process, along with the average waiting time and average turnaround time.

**Expected Outcome:**
- Understanding how the Round Robin algorithm schedules processes.
- Familiarity with the concept of time quantum and context switching.

**Example Code:**

```python
class Process:
    def __init__(self, id, burst_time, arrival_time):
        self.id = id
        self.burst_time = burst_time
        self.remaining_time = burst_time
        self.arrival_time = arrival_time
        self.waiting_time = 0
        self.turnaround_time = 0

def round_robin_scheduling(processes, time_quantum):
    processes.sort(key=lambda x: x.arrival_time)
    time = 0
    queue = processes[:]
    completed = []

    while queue:
        for process in list(queue):
            if process.remaining_time > 0:
                if process.remaining_time > time_quantum:
                    time += time_quantum
                    process.remaining_time -= time_quantum
                else:
                    time += process.remaining_time
                    process.remaining_time = 0
                    process.turnaround_time = time - process.arrival_time
                    completed.append(process)
                    queue.remove(process)
            
    for process in completed:
        process.waiting_time = process.turnaround_time - process.burst_time

processes = [
    Process(1, 5, 0),
    Process(2, 3, 1),
    Process(3, 8, 2)
]

round_robin_scheduling(processes, 2)

for process in processes:
    print(f"Process {process.id}: Waiting Time = {process.waiting_time}, Turnaround Time = {process.turnaround_time}")
```

#### Exercise 3: Implementing Paging and Page Replacement Algorithms

**Objective:** Write a program to simulate paging and implement a page replacement algorithm such as Least Recently Used (LRU).

**Task Description:**

1. Simulate a process that generates a sequence of page references.
2. Implement a page table to keep track of page frames.
3. Implement the Least Recently Used (LRU) page replacement algorithm.
4. Calculate the number of page faults that occur during the simulation.
5. Output the total number of page faults.

**Expected Outcome:**
- Understanding of the paging mechanism.
- Familiarity with the LRU page replacement algorithm and its implementation.

**Example Code:**

```cpp
#include <iostream>
#include <vector>
#include <deque>
#include <unordered_map>
using namespace std;

const int PAGE_SIZE = 4;
const int MEMORY_FRAMES = 3;

struct Page {
    int page_id;
    int frame_id;
};

void simulate_lru(vector<int> page_references) {
    unordered_map<int, int> page_table;
    deque<int> lru_queue;
    int page_faults = 0;
    int current_frame = 0;

    for (int page_id : page_references) {
        if (page_table.find(page_id) == page_table.end()) {
            page_faults++;
            if (lru_queue.size() == MEMORY_FRAMES) {
                int oldest_page = lru_queue.back();
                lru_queue.pop_back();
                page_table.erase(oldest_page);
            }
            page_table[page_id] = current_frame++;
            lru_queue.push_front(page_id);
        } else {
            lru_queue.erase(remove(lru_queue.begin(), lru_queue.end(), page_id), lru_queue.end());
            lru_queue.push_front(page_id);
        }
    }

    cout << "Total Page Faults: " << page_faults << endl;
}

int main() {
    vector<int> page_references = {1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5};
    simulate_lru(page_references);
    return 0;
}
```

#### Exercise 4: Implementing Virtual Memory with Demand Paging

**Objective:** Write a program to simulate virtual memory management using demand paging.

**Task Description:**

1. Simulate a process with a large address space.
2. Implement page tables to manage virtual to physical address translation.
3. Use demand paging to load pages into memory only when they are accessed.
4. Count the number of page faults that occur during the simulation.
5. Output the total number of page faults and the state of memory after the simulation.

**Expected Outcome:**
- Understanding of virtual memory and demand paging.
- Ability to implement address translation using page tables.

**Example Code:**

```cpp
#include <iostream>
#include <unordered_map>
#include <vector>
using namespace std;

const int PAGE_SIZE = 4;
const int MEMORY_SIZE = 16;

struct Page {
    int page_id;
    int frame_id;
    bool in_memory;
};

void simulate_demand_paging(vector<int> page_references) {
    unordered_map<int, Page> page_table;
    vector<int> memory(MEMORY_SIZE, -1);
    int page_faults = 0;
    int current_frame = 0;

    for (int page_id : page_references) {
        if (page_table.find(page_id) == page_table.end() || !page_table[page_id].in_memory) {
            page_faults++;
            if (current_frame < MEMORY_SIZE / PAGE_SIZE) {
                page_table[page_id] = {page_id, current_frame, true};
                current_frame++;
            } else {
                cout << "Memory is full. Unable to load page " << page_id << " into memory" << endl;
                continue;
            }
        }
        cout << "Accessing Page " << page_id << " in Frame " << page_table[page_id].frame_id << endl;
    }

    cout << "Total Page Faults: " << page_faults << endl;
}

int main() {
    vector<int> page_references = {1, 2, 3, 1, 4, 5, 6, 2, 1, 3, 7, 8};
    simulate_demand_paging(page_references);
    return 0;
}
```

#### Exercise 5: Analyzing Inter-process Communication (IPC) Mechanisms

**Objective:** Explore and implement various IPC mechanisms in Linux, such as pipes, shared memory, and message queues.

**Task Description:**

1. Write programs to demonstrate the use of pipes, shared memory, and message queues for inter-process communication.
2. Compare the performance and use cases of each IPC mechanism.
3. Analyze the advantages and disadvantages of each method.
4. Implement a sample problem using each IPC mechanism and measure the time taken for communication.

**Expected Outcome:**
- In-depth understanding of different IPC mechanisms available in Linux.
- Ability to choose the appropriate IPC method based on specific requirements and constraints.

**Example Code (Pipes in C++):**

```cpp
#include <iostream>
#include <unistd.h>
#include <cstring>
using namespace std;

int main() {
    int pipe_fd[2];
    pid_t pid;
    char buffer[20];

    if (pipe(pipe_fd) == -1) {
        cerr << "Pipe failed" << endl;
        return 1;
    }

    pid = fork();

    if (pid < 0) {
        cerr << "Fork failed" << endl;
        return 1;
    }

    if (pid > 0) {
        close(pipe_fd[0]);
        char message[] = "Hello from parent";
        write(pipe_fd[1], message, strlen(message) + 1);
        close(pipe_fd[1]);
    } else {
        close(pipe_fd[1]);
        read(pipe_fd[0], buffer, sizeof(buffer));
        close(pipe_fd[0]);
        cout << "Child received: " << buffer << endl;
    }

    return 0;
}
```

#### Exercise 6: Memory Allocation Strategies

**Objective:** Implement and analyze different memory allocation strategies, including first fit, best fit, and worst fit.

**Task Description:**

1. Create a memory pool management system.
2. Implement first fit, best fit, and worst fit memory allocation strategies.
3. Compare the strategies based on allocation success, memory fragmentation, and performance.
4. Simulate a series of memory allocation and deallocation requests to analyze the performance.

**Expected Outcome:**
- Understanding and implementation of various memory allocation strategies.
- Ability to analyze and compare different memory allocation techniques.

**Example Code (First Fit in Python):**

```python
class MemoryBlock:
    def __init__(self, size):
        self.size = size
        self.free = True

class MemoryPool:
    def __init__(self, size):
        self.pool = [MemoryBlock(size)]

    def first_fit_allocate(self, request_size):
        for block in self.pool:
            if block.free and block.size >= request_size:
                if block.size > request_size:
                    remaining_size = block.size - request_size
                    self.pool.insert(self.pool.index(block) + 1, MemoryBlock(remaining_size))
                block.size = request_size
                block.free = False
                return True
        return False

    def deallocate(self, request_size):
        for block in self.pool:
            if not block.free and block.size == request_size:
                block.free = True
                return True
        return False

memory_pool = MemoryPool(100)
requests = [10, 20, 5, 30, 25]
allocations = [memory_pool.first_fit_allocate(request) for request in requests]

for idx, request in enumerate(requests):
    print(f"Request {request}: {'Allocated' if allocations[idx] else 'Failed to allocate'}")

# Deallocate
memory_pool.deallocate(20)
memory_pool.deallocate(10)

# New allocation after deallocation
print("New request after deallocation: ", memory_pool.first_fit_allocate(15))
```

Through these exercises, you will gain hands-on experience and a deeper understanding of complex concepts in process scheduling and memory management. Each task is designed to challenge your knowledge, reinforce theoretical understanding, and enhance your practical skills, preparing you to tackle real-world problems in systems programming and operating systems development.

